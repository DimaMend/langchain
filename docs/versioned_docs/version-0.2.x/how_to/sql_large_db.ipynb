{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6751831d-9b08-434f-829b-d0052a3b119f",
   "metadata": {},
   "source": [
    "# How to deal with large databases when doing SQL question-answering\n",
    "\n",
    "In order to write valid queries against a database, we need to feed the model the table names, table schemas, and feature values for it to query over. When there are many tables, columns, and/or high-cardinality columns, it becomes impossible for us to dump the full information about our database in every prompt. Instead, we must find ways to dynamically insert into the prompt only the most relevant information. Let's take a look at some techniques for doing this.\n",
    "\n",
    "\n",
    "## Setup\n",
    "\n",
    "First, get required packages and set environment variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd5c20e-c705-4ef4-b33b-71fa819215ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade --quiet  langchain langchain-community langchain-openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f56ff5d-b2e4-49e3-a0b4-fb99466cfedc",
   "metadata": {},
   "source": [
    "We default to OpenAI models in this guide, but you can swap them out for the model provider of your choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592e0c93-5396-44ec-92f0-1635ddd59a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the below to use LangSmith. Not required.\n",
    "# import os\n",
    "# os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass()\n",
    "# os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590ee096-db88-42af-90d4-99b8149df753",
   "metadata": {},
   "source": [
    "The below example will use a SQLite connection with Chinook database. Follow [these installation steps](https://database.guide/2-sample-databases-sqlite/) to create `Chinook.db` in the same directory as this notebook:\n",
    "\n",
    "* Save [this file](https://raw.githubusercontent.com/lerocha/chinook-database/master/ChinookDatabase/DataSources/Chinook_Sqlite.sql) as `Chinook_Sqlite.sql`\n",
    "* Run `sqlite3 Chinook.db`\n",
    "* Run `.read Chinook_Sqlite.sql`\n",
    "* Test `SELECT * FROM Artist LIMIT 10;`\n",
    "\n",
    "Now, `Chinhook.db` is in our directory and we can interface with it using the SQLAlchemy-driven [SQLDatabase](https://api.python.langchain.com/en/latest/utilities/langchain_community.utilities.sql_database.SQLDatabase.html) class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cebd3915-f58f-4e73-8459-265630ae8cd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sqlite\n",
      "['Album', 'Artist', 'Customer', 'Employee', 'Genre', 'Invoice', 'InvoiceLine', 'MediaType', 'Playlist', 'PlaylistTrack', 'Track']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"[(1, 'AC/DC'), (2, 'Accept'), (3, 'Aerosmith'), (4, 'Alanis Morissette'), (5, 'Alice In Chains'), (6, 'Ant√¥nio Carlos Jobim'), (7, 'Apocalyptica'), (8, 'Audioslave'), (9, 'BackBeat'), (10, 'Billy Cobham')]\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.utilities import SQLDatabase\n",
    "\n",
    "db = SQLDatabase.from_uri(\"sqlite:///Chinook.db\")\n",
    "print(db.dialect)\n",
    "print(db.get_usable_table_names())\n",
    "db.run(\"SELECT * FROM Artist LIMIT 10;\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e572e1f-99b5-46a2-9023-76d1e6256c0a",
   "metadata": {},
   "source": [
    "## Many tables\n",
    "\n",
    "One of the main pieces of information we need to include in our prompt is the schemas of the relevant tables. When we have very many tables, we can't fit all of the schemas in a single prompt. What we can do in such cases is first extract the names of the tables related to the user input, and then include only their schemas.\n",
    "\n",
    "One easy and reliable way to do this is using OpenAI function-calling and Pydantic models. LangChain comes with a built-in [create_extraction_chain_pydantic](https://api.python.langchain.com/en/latest/chains/langchain.chains.openai_tools.extraction.create_extraction_chain_pydantic.html) chain that lets us do just this.\n",
    "\n",
    "```{=mdx}\n",
    "import ChatModelTabs from \"@theme/ChatModelTabs\";\n",
    "\n",
    "<ChatModelTabs customVarName=\"llm\" />\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d278de7e-9228-4265-abf2-7a5e214a7dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | output: false\n",
    "# | echo: false\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dccf57ad-5e6d-4050-b52d-c1d8a7886ac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chestercurme/repos/langchain/libs/core/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: LangChain has introduced a method called `with_structured_output` that is available on ChatModels capable of tool calling. You can read more about the method here: https://python.langchain.com/docs/modules/model_io/chat/structured_output/ Please follow our extraction use case documentation for more guidelines on how to do information extraction with LLMs. https://python.langchain.com/docs/use_cases/extraction/. If you notice other issues, please provide feedback here: https://github.com/langchain-ai/langchain/discussions/18154\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Need to pass in at least one function. Received zero.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchains\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstructured_output\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m create_openai_fn_runnable\n\u001b[0;32m----> 3\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_openai_fn_runnable\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/repos/langchain/libs/core/langchain_core/_api/deprecation.py:148\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    146\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    147\u001b[0m     emit_warning()\n\u001b[0;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/repos/langchain/libs/langchain/langchain/chains/structured_output/base.py:135\u001b[0m, in \u001b[0;36mcreate_openai_fn_runnable\u001b[0;34m(functions, llm, prompt, enforce_single_function_usage, output_parser, **llm_kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Create a runnable sequence that uses OpenAI functions.\u001b[39;00m\n\u001b[1;32m     74\u001b[0m \n\u001b[1;32m     75\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;124;03m            # -> RecordDog(name=\"Harry\", color=\"brown\", fav_food=\"chicken\")\u001b[39;00m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: E501\u001b[39;00m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m functions:\n\u001b[0;32m--> 135\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNeed to pass in at least one function. Received zero.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    136\u001b[0m openai_functions \u001b[38;5;241m=\u001b[39m [convert_to_openai_function(f) \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m functions]\n\u001b[1;32m    137\u001b[0m llm_kwargs_: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunctions\u001b[39m\u001b[38;5;124m\"\u001b[39m: openai_functions, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mllm_kwargs}\n",
      "\u001b[0;31mValueError\u001b[0m: Need to pass in at least one function. Received zero."
     ]
    }
   ],
   "source": [
    "from langchain.chains.structured_output.base import create_openai_fn_runnable\n",
    "\n",
    "x = create_openai_fn_runnable(None, None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8236886-c54f-4bdb-ad74-2514888628fd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "A pending deprecation cannot have a scheduled removal",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 18\u001b[0m\n\u001b[1;32m     11\u001b[0m table_names \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(db\u001b[38;5;241m.\u001b[39mget_usable_table_names())\n\u001b[1;32m     12\u001b[0m system \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mReturn the names of ALL the SQL tables that MIGHT be relevant to the user question. \u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;124mThe tables are:\u001b[39m\n\u001b[1;32m     14\u001b[0m \n\u001b[1;32m     15\u001b[0m \u001b[38;5;132;01m{\u001b[39;00mtable_names\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \n\u001b[1;32m     17\u001b[0m \u001b[38;5;124mRemember to include ALL POTENTIALLY RELEVANT tables, even if you\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mre not sure that they\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mre needed.\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m---> 18\u001b[0m table_chain \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_extraction_chain_pydantic\u001b[49m\u001b[43m(\u001b[49m\u001b[43mTable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mllm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msystem_message\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msystem\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m table_chain\u001b[38;5;241m.\u001b[39minvoke({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat are all the genres of Alanis Morisette songs\u001b[39m\u001b[38;5;124m\"\u001b[39m})\n",
      "File \u001b[0;32m~/repos/langchain/libs/core/langchain_core/_api/deprecation.py:147\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m warned \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_caller_internal():\n\u001b[1;32m    146\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 147\u001b[0m     \u001b[43memit_warning\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/repos/langchain/libs/core/langchain_core/_api/deprecation.py:119\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.emit_warning\u001b[0;34m()\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21memit_warning\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    118\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Emit the warning.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 119\u001b[0m     \u001b[43mwarn_deprecated\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m        \u001b[49m\u001b[43msince\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_message\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[43m        \u001b[49m\u001b[43malternative\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_alternative\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[43m        \u001b[49m\u001b[43malternative_import\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_alternative_import\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpending\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_pending\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobj_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_obj_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m        \u001b[49m\u001b[43maddendum\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_addendum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m        \u001b[49m\u001b[43mremoval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremoval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpackage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_package\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/repos/langchain/libs/core/langchain_core/_api/deprecation.py:341\u001b[0m, in \u001b[0;36mwarn_deprecated\u001b[0;34m(since, message, name, alternative, alternative_import, pending, obj_type, addendum, removal, package)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Display a standardized deprecation.\u001b[39;00m\n\u001b[1;32m    312\u001b[0m \n\u001b[1;32m    313\u001b[0m \u001b[38;5;124;03mArguments:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;124;03m        date. Cannot be used together with pending.\u001b[39;00m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pending \u001b[38;5;129;01mand\u001b[39;00m removal:\n\u001b[0;32m--> 341\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA pending deprecation cannot have a scheduled removal\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m alternative \u001b[38;5;129;01mand\u001b[39;00m alternative_import:\n\u001b[1;32m    343\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot specify both alternative and alternative_import\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: A pending deprecation cannot have a scheduled removal"
     ]
    }
   ],
   "source": [
    "from langchain.chains.openai_tools import create_extraction_chain_pydantic\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "\n",
    "class Table(BaseModel):\n",
    "    \"\"\"Table in SQL database.\"\"\"\n",
    "\n",
    "    name: str = Field(description=\"Name of table in SQL database.\")\n",
    "\n",
    "\n",
    "table_names = \"\\n\".join(db.get_usable_table_names())\n",
    "system = f\"\"\"Return the names of ALL the SQL tables that MIGHT be relevant to the user question. \\\n",
    "The tables are:\n",
    "\n",
    "{table_names}\n",
    "\n",
    "Remember to include ALL POTENTIALLY RELEVANT tables, even if you're not sure that they're needed.\"\"\"\n",
    "table_chain = create_extraction_chain_pydantic(Table, llm, system_message=system)\n",
    "table_chain.invoke({\"input\": \"What are all the genres of Alanis Morisette songs\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1641dbba-d359-4cb2-ac52-82dfae99f392",
   "metadata": {},
   "source": [
    "This works pretty well! Except, as we'll see below, we actually need a few other tables as well. This would be pretty difficult for the model to know based just on the user question. In this case, we might think to simplify our model's job by grouping the tables together. We'll just ask the model to choose between categories \"Music\" and \"Business\", and then take care of selecting all the relevant tables from there:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0ccb0bf5-c580-428f-9cde-a58772ae784e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Table(name='Music')]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system = \"\"\"Return the names of the SQL tables that are relevant to the user question. \\\n",
    "The tables are:\n",
    "\n",
    "Music\n",
    "Business\"\"\"\n",
    "category_chain = create_extraction_chain_pydantic(Table, llm, system_message=system)\n",
    "category_chain.invoke({\"input\": \"What are all the genres of Alanis Morisette songs\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ae4899fc-6f8a-4b10-983c-9e3fef4a7bb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Album', 'Artist', 'Genre', 'MediaType', 'Playlist', 'PlaylistTrack', 'Track']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import List\n",
    "\n",
    "\n",
    "def get_tables(categories: List[Table]) -> List[str]:\n",
    "    tables = []\n",
    "    for category in categories:\n",
    "        if category.name == \"Music\":\n",
    "            tables.extend(\n",
    "                [\n",
    "                    \"Album\",\n",
    "                    \"Artist\",\n",
    "                    \"Genre\",\n",
    "                    \"MediaType\",\n",
    "                    \"Playlist\",\n",
    "                    \"PlaylistTrack\",\n",
    "                    \"Track\",\n",
    "                ]\n",
    "            )\n",
    "        elif category.name == \"Business\":\n",
    "            tables.extend([\"Customer\", \"Employee\", \"Invoice\", \"InvoiceLine\"])\n",
    "    return tables\n",
    "\n",
    "\n",
    "table_chain = category_chain | get_tables  # noqa\n",
    "table_chain.invoke({\"input\": \"What are all the genres of Alanis Morisette songs\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d52d01-1ccf-4753-b34a-0dcbc4921f78",
   "metadata": {},
   "source": [
    "Now that we've got a chain that can output the relevant tables for any query we can combine this with our [create_sql_query_chain](https://api.python.langchain.com/en/latest/chains/langchain.chains.sql_database.query.create_sql_query_chain.html), which can accept a list of `table_names_to_use` to determine which table schemas are included in the prompt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "79f2a5a2-eb99-47e3-9c2b-e5751a800174",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from langchain.chains import create_sql_query_chain\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "query_chain = create_sql_query_chain(llm, db)\n",
    "# Convert \"question\" key to the \"input\" key expected by current table_chain.\n",
    "table_chain = {\"input\": itemgetter(\"question\")} | table_chain\n",
    "# Set table_names_to_use using table_chain.\n",
    "full_chain = RunnablePassthrough.assign(table_names_to_use=table_chain) | query_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "424a7564-f63c-4584-b734-88021926486d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT \"Genre\".\"Name\"\n",
      "FROM \"Genre\"\n",
      "JOIN \"Track\" ON \"Genre\".\"GenreId\" = \"Track\".\"GenreId\"\n",
      "JOIN \"Album\" ON \"Track\".\"AlbumId\" = \"Album\".\"AlbumId\"\n",
      "JOIN \"Artist\" ON \"Album\".\"ArtistId\" = \"Artist\".\"ArtistId\"\n",
      "WHERE \"Artist\".\"Name\" = 'Alanis Morissette'\n"
     ]
    }
   ],
   "source": [
    "query = full_chain.invoke(\n",
    "    {\"question\": \"What are all the genres of Alanis Morisette songs\"}\n",
    ")\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3fb715cf-69d1-46a6-a1a7-9715ee550a0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[('Rock',), ('Rock',), ('Rock',), ('Rock',), ('Rock',), ('Rock',), ('Rock',), ('Rock',), ('Rock',), ('Rock',), ('Rock',), ('Rock',), ('Rock',)]\""
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.run(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3d12b0-81a6-4250-8bc4-d58fe762c4cc",
   "metadata": {},
   "source": [
    "We might rephrase our question slightly to remove redundancy in the answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "010b5c3c-d55b-461a-8de5-8f1a8b2c56ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT DISTINCT g.Name\n",
      "FROM Genre g\n",
      "JOIN Track t ON g.GenreId = t.GenreId\n",
      "JOIN Album a ON t.AlbumId = a.AlbumId\n",
      "JOIN Artist ar ON a.ArtistId = ar.ArtistId\n",
      "WHERE ar.Name = 'Alanis Morissette'\n"
     ]
    }
   ],
   "source": [
    "query = full_chain.invoke(\n",
    "    {\"question\": \"What is the set of all unique genres of Alanis Morisette songs\"}\n",
    ")\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d21c0563-1f55-4577-8222-b0e9802f1c4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[('Rock',)]\""
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.run(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a717020-84c2-40f3-ba84-6624138d8e0c",
   "metadata": {},
   "source": [
    "We can see the [LangSmith trace](https://smith.langchain.com/public/20b8ef90-1dac-4754-90f0-6bc11203c50a/r) for this run here.\n",
    "\n",
    "We've seen how to dynamically include a subset of table schemas in a prompt within a chain. Another possible approach to this problem is to let an Agent decide for itself when to look up tables by giving it a Tool to do so. You can see an example of this in the [SQL: Agents](/docs/tutorials/agents) guide."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb9e54fd-64ca-4ed5-847c-afc635aae4f5",
   "metadata": {},
   "source": [
    "## High-cardinality columns\n",
    "\n",
    "In order to filter columns that contain proper nouns such as addresses, song names or artists, we first need to double-check the spelling in order to filter the data correctly. \n",
    "\n",
    "One naive strategy it to create a vector store with all the distinct proper nouns that exist in the database. We can then query that vector store each user input and inject the most relevant proper nouns into the prompt.\n",
    "\n",
    "First we need the unique values for each entity we want, for which we define a function that parses the result into a list of elements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dee1b9e1-36b0-4cc1-ab78-7a872ad87e29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AC/DC', 'Accept', 'Aerosmith', 'Alanis Morissette', 'Alice In Chains']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ast\n",
    "import re\n",
    "\n",
    "\n",
    "def query_as_list(db, query):\n",
    "    res = db.run(query)\n",
    "    res = [el for sub in ast.literal_eval(res) for el in sub if el]\n",
    "    res = [re.sub(r\"\\b\\d+\\b\", \"\", string).strip() for string in res]\n",
    "    return res\n",
    "\n",
    "\n",
    "proper_nouns = query_as_list(db, \"SELECT Name FROM Artist\")\n",
    "proper_nouns += query_as_list(db, \"SELECT Title FROM Album\")\n",
    "proper_nouns += query_as_list(db, \"SELECT Name FROM Genre\")\n",
    "len(proper_nouns)\n",
    "proper_nouns[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22efa968-1879-4d7a-858f-7899dfa57454",
   "metadata": {},
   "source": [
    "Now we can embed and store all of our values in a vector database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea50abce-545a-4dc3-8795-8d364f7d142a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "vector_db = FAISS.from_texts(proper_nouns, OpenAIEmbeddings())\n",
    "retriever = vector_db.as_retriever(search_kwargs={\"k\": 15})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d1d5c0-0928-40a4-b961-f1afe03cd5d3",
   "metadata": {},
   "source": [
    "And put together a query construction chain that first retrieves values from the database and inserts them into the prompt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aea123ae-d809-44a0-be5d-d883c60d6a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "system = \"\"\"You are a SQLite expert. Given an input question, create a syntactically \\\n",
    "correct SQLite query to run. Unless otherwise specificed, do not return more than \\\n",
    "{top_k} rows.\\n\\nHere is the relevant table info: {table_info}\\n\\nHere is a non-exhaustive \\\n",
    "list of possible feature values. If filtering on a feature value make sure to check its spelling \\\n",
    "against this list first:\\n\\n{proper_nouns}\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([(\"system\", system), (\"human\", \"{input}\")])\n",
    "\n",
    "query_chain = create_sql_query_chain(llm, db, prompt=prompt)\n",
    "retriever_chain = (\n",
    "    itemgetter(\"question\")\n",
    "    | retriever\n",
    "    | (lambda docs: \"\\n\".join(doc.page_content for doc in docs))\n",
    ")\n",
    "chain = RunnablePassthrough.assign(proper_nouns=retriever_chain) | query_chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b0ed60-2536-4f82-85df-e096a272072a",
   "metadata": {},
   "source": [
    "To try out our chain, let's see what happens when we try filtering on \"elenis moriset\", a mispelling of Alanis Morissette, without and with retrieval:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fcdd8432-07a4-4609-8214-b1591dd94950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT DISTINCT Genre.Name\n",
      "FROM Genre\n",
      "JOIN Track ON Genre.GenreId = Track.GenreId\n",
      "JOIN Album ON Track.AlbumId = Album.AlbumId\n",
      "JOIN Artist ON Album.ArtistId = Artist.ArtistId\n",
      "WHERE Artist.Name = 'Elenis Moriset'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Without retrieval\n",
    "query = query_chain.invoke(\n",
    "    {\"question\": \"What are all the genres of elenis moriset songs\", \"proper_nouns\": \"\"}\n",
    ")\n",
    "print(query)\n",
    "db.run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e8a3231a-8590-46f5-a954-da06829ee6df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT DISTINCT Genre.Name\n",
      "FROM Genre\n",
      "JOIN Track ON Genre.GenreId = Track.GenreId\n",
      "JOIN Album ON Track.AlbumId = Album.AlbumId\n",
      "JOIN Artist ON Album.ArtistId = Artist.ArtistId\n",
      "WHERE Artist.Name = 'Alanis Morissette'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"[('Rock',)]\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# With retrieval\n",
    "query = chain.invoke({\"question\": \"What are all the genres of elenis moriset songs\"})\n",
    "print(query)\n",
    "db.run(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f99181b-a75c-4ff3-b37b-33f99a506581",
   "metadata": {},
   "source": [
    "We can see that with retrieval we're able to correct the spelling and get back a valid result.\n",
    "\n",
    "Another possible approach to this problem is to let an Agent decide for itself when to look up proper nouns. You can see an example of this in the [SQL: Agents](/docs/tutorials/agents) guide."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
