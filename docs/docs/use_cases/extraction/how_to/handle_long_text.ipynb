{
 "cells": [
  {
   "cell_type": "raw",
   "id": "913dd5a2-24d1-4f8e-bc15-ab518483eef9",
   "metadata": {},
   "source": [
    "---\n",
    "title: Handle Long Text\n",
    "sidebar_position: 2\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e161a8a-fcf0-4d55-933e-da271ce28d7e",
   "metadata": {},
   "source": [
    "When working with files, like PDFs, you're likely to encounter text that exceeds your language model's context window. To process this text, consider these strategies:\n",
    "\n",
    "1. **Change LLM** Choose a different LLM that supports a larger context window.\n",
    "2. **Brute Force** Chunk the document, and extract content from each chunk.\n",
    "3. **RAG** Chunk the document, index the chunks, and only extract content from a subset of chunks that look \"relevant\".\n",
    "\n",
    "Keep in mind that these strategies have different trade off and the best strategy likely depends on the application that you're designing!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57969139-ad0a-487e-97d8-cb30e2af9742",
   "metadata": {},
   "source": [
    "## Set up\n",
    "\n",
    "We need some example data! Let's download an article about [cars from wikipedia](https://en.wikipedia.org/wiki/Car) and load it as a LangChain `Document`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "571aad22-2cec-4b9b-b656-5e4b81a1ec6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import requests\n",
    "from langchain_community.document_loaders import BSHTMLLoader\n",
    "\n",
    "# Download the content\n",
    "response = requests.get(\"https://en.wikipedia.org/wiki/Car\")\n",
    "# Write it to a file\n",
    "with open(\"car.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(response.text)\n",
    "# Load it with an HTML parser\n",
    "loader = BSHTMLLoader(\"car.html\")\n",
    "document = loader.load()[0]\n",
    "# Clean up code\n",
    "# Replace consecutive new lines with a single new line\n",
    "document.page_content = re.sub(\"\\n\\n+\", \"\\n\", document.page_content).replace(\n",
    "    \"\\xa0\", \" \"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85656454-6d5d-4ff6-93ca-690791ac1ec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79251\n"
     ]
    }
   ],
   "source": [
    "print(len(document.page_content))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3ffb8d-587a-4370-886a-e56e617bcb9c",
   "metadata": {},
   "source": [
    "## Define the schema\n",
    "\n",
    "Here, we'll define schema to extract key developments from the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3b288ed-87a6-4af0-aac8-20921dc370d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mikelarg/Projects/gigachain/libs/core/langchain_core/_api/beta_decorator.py:87: LangChainBetaWarning: The function `with_structured_output` is in beta. It is actively being worked on, so the API may change.\n",
      "  warn_beta(\n"
     ]
    }
   ],
   "source": [
    "from typing import List, Optional\n",
    "\n",
    "from langchain_community.chat_models.gigachat import GigaChat\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "class KeyDevelopment(BaseModel):\n",
    "    \"\"\"Важная историческая дата.\"\"\"\n",
    "\n",
    "    # ^ Док-строка выше, подкладывается в описании функции\n",
    "    # и может помочь в улучшении результатов от LLM\n",
    "\n",
    "    # Заметьте:\n",
    "    # 1. Каждое поле имеет поле description — это подкладывается в описание аргументов функции\n",
    "    # и может помочь в улучшении результатов\n",
    "    year: Optional[int] = Field(\n",
    "        ..., description=\"Год исторического события. Не может быть null.\"\n",
    "    )\n",
    "    description: str = Field(\n",
    "        ..., description=\"Описание. Что произошло в этом году? Каково было развитие?\"\n",
    "    )\n",
    "    evidence: str = Field(\n",
    "        ...,\n",
    "        description=\"Повтори дословно предложения из текста, из которых были извлечены год и описание.\",\n",
    "    )\n",
    "\n",
    "\n",
    "class ExtractionData(BaseModel):\n",
    "    \"\"\"Извлеченая информация о ключевых событиях в истории.\"\"\"\n",
    "\n",
    "    key_developments: List[KeyDevelopment]\n",
    "\n",
    "\n",
    "# Define a custom prompt to provide instructions and any additional context.\n",
    "# 1) You can add examples into the prompt template to improve extraction quality\n",
    "# 2) Introduce additional parameters to take context into account (e.g., include metadata\n",
    "#    about the document from which the text was extracted.)\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"Ты эксперт в извлечении важных исторических дат из текста. \"\n",
    "            \"Извлекай только важные исторические события с годами.\"\n",
    "            \"Если ты не можешь извлечь год, не записывай это в историческое событие\",\n",
    "        ),\n",
    "        MessagesPlaceholder(\n",
    "            \"examples\"\n",
    "        ),  # Keep on reading through this use case to see how to use examples to improve performance\n",
    "        (\"human\", \"{text}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "llm = GigaChat(\n",
    "    verify_ssl_certs=False,\n",
    "    timeout=6000,\n",
    "    model=\"GigaChat-Pro\",\n",
    "    temperature=0.01,\n",
    ")\n",
    "\n",
    "extractor = prompt | llm.with_structured_output(\n",
    "    schema=ExtractionData,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13aebafb-26b5-42b2-ae8e-9c05cd56e5c5",
   "metadata": {},
   "source": [
    "## Brute force approach\n",
    "\n",
    "Split the documents into chunks such that each chunk fits into the context window of the LLMs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27b8a373-14b3-45ea-8bf5-9749122ad927",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    # Controls the size of each chunk\n",
    "    chunk_size=2000,\n",
    "    # Controls overlap between chunks\n",
    "    chunk_overlap=20,\n",
    ")\n",
    "\n",
    "texts = text_splitter.split_text(document.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "from typing import List, TypedDict\n",
    "import itertools\n",
    "\n",
    "from langchain_core.messages import (\n",
    "    AIMessage,\n",
    "    BaseMessage,\n",
    "    HumanMessage,\n",
    "    FunctionMessage,\n",
    ")\n",
    "from langchain_core.pydantic_v1 import BaseModel\n",
    "\n",
    "#\n",
    "# В этом блоке мы добавляем примеры работы функций для улучшения качества\n",
    "# подробнее о примерах работы читайте в example.ipynb\n",
    "#\n",
    "\n",
    "class Example(TypedDict):\n",
    "    \"\"\"Пример работы функций.\"\"\"\n",
    "\n",
    "    input: str  # Пример вызова\n",
    "    function_calls: List[BaseModel]  # Pydantic модель, с примером извлечения\n",
    "    function_outputs: List[str]\n",
    "\n",
    "\n",
    "def tool_example_to_messages(example: Example) -> List[BaseMessage]:\n",
    "    \"\"\"Превращаем примеры вызовов функций в историю сообщений\"\"\"\n",
    "    messages: List[BaseMessage] = [HumanMessage(content=example[\"input\"])]\n",
    "    for function_call, function_output in itertools.zip_longest(\n",
    "        example[\"function_calls\"], example.get(\"function_outputs\", [])\n",
    "    ):\n",
    "        messages.append(\n",
    "            AIMessage(\n",
    "                content=\"\",\n",
    "                additional_kwargs={\n",
    "                    \"function_call\": {\n",
    "                        # Названием функции в текущий момент соответствует The name of the function right now corresponds\n",
    "                        # to the name of the pydantic model\n",
    "                        # This is implicit in the API right now,\n",
    "                        # and will be improved over time.\n",
    "                        \"name\": function_call.__class__.__name__,\n",
    "                        \"arguments\": function_call.dict(),\n",
    "                    },\n",
    "                },\n",
    "            )\n",
    "        )\n",
    "        output = \"You have correctly called this tool.\"\n",
    "        if function_output:\n",
    "            output = function_output\n",
    "        messages.append(\n",
    "            FunctionMessage(name=function_call.__class__.__name__, content=output)\n",
    "        )\n",
    "    return messages\n",
    "\n",
    "\n",
    "examples = [\n",
    "    (\n",
    "        \"Техногенная авария «Размыв» Ленинградского-Петербургского метрополитена \"\n",
    "        \"является крупнейшей в мировой практике метростроения[34]; была экранизирована \"\n",
    "        \"в фильме «Прорыв» и послужила вдохновением для фильма «Метро»[35].\",\n",
    "        ExtractionData(\n",
    "            key_developments=[\n",
    "                KeyDevelopment(\n",
    "                    year=None,\n",
    "                    description=\"Техногенная авария 'Размыв' в \"\n",
    "                    \"Ленинградском-Петербургском метрополитене является \"\n",
    "                    \"крупнейшей в мировой практике метростроения\",\n",
    "                    evidence=\"была экранизирована в фильме 'Прорыв' и послужила \"\n",
    "                    \"вдохновением для фильма 'Метро'\",\n",
    "                )\n",
    "            ]\n",
    "        ),\n",
    "        \"\"\"pydantic.v1.error_wrappers.ValidationError: 1 validation error for KeyDevelopment\n",
    "year\n",
    "  none is not an allowed value (type=type_error.none.not_allowed)\"\"\",\n",
    "    ),\n",
    "    (\n",
    "        \"In 1891, Auguste Doriot and his Peugeot colleague Louis Rigoulot completed \"\n",
    "        \"the longest trip by a petrol-driven vehicle when their self-designed and \"\n",
    "        \"built Daimler powered Peugeot Type 3 completed 2,100 kilometres (1,300 mi) \"\n",
    "        \"from Valentigney to Paris and Brest and back again. They were attached to \"\n",
    "        \"the first Paris–Brest–Paris bicycle race, but finished six days \"\n",
    "        \"after the winning cyclist, Charles Terront.\",\n",
    "        ExtractionData(\n",
    "            key_developments=[\n",
    "                KeyDevelopment(\n",
    "                    year=1891,\n",
    "                    description=\"Август Дорио и его коллега Луи Риголу \"\n",
    "                    \"завершают самую длинную поездку на бензиновом автомобиле\",\n",
    "                    evidence=\"In 1891, Auguste Doriot and his Peugeot colleague Louis Rigoulot completed the longest trip by a petrol-driven vehicle\",\n",
    "                )\n",
    "            ]\n",
    "        ),\n",
    "        \"You have correctly called this tool.\",\n",
    "    ),\n",
    "    (\n",
    "        \"I love cats and dogs.\",\n",
    "        ExtractionData(key_developments=[]),\n",
    "        \"You have correctly called this tool.\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "\n",
    "messages = []\n",
    "\n",
    "for text, tool_call, function_output in examples:\n",
    "    messages.extend(\n",
    "        tool_example_to_messages(\n",
    "            {\n",
    "                \"input\": text,\n",
    "                \"function_calls\": [tool_call],\n",
    "                \"function_outputs\": [function_output],\n",
    "            }\n",
    "        )\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "id": "5b43d7e0-3c85-4d97-86c7-e8c984b60b0a",
   "metadata": {},
   "source": [
    "Use `.batch` functionality to run the extraction in **parallel** across each chunk! \n",
    "\n",
    ":::{.callout-tip}\n",
    "You can often use .batch() to parallelize the extractions! `batch` uses a threadpool under the hood to help you parallelize workloads.\n",
    "\n",
    "If your model is exposed via an API, this will likley speed up your extraction flow!\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba766b5-8d6c-48e6-8d69-f391a66b65d2",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Limit just to the first 3 chunks\n",
    "# so the code can be re-run quickly\n",
    "first_few = texts[:10]\n",
    "\n",
    "extractions = extractor.batch(\n",
    "    [{\"text\": text, \"examples\": messages} for text in first_few],\n",
    "    {\"max_concurrency\": 5},  # limit the concurrency by passing max concurrency!\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67da8904-e927-406b-a439-2a16f6087ccf",
   "metadata": {},
   "source": [
    "### Merge results\n",
    "\n",
    "After extracting data from across the chunks, we'll want to merge the extractions together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30b35897-4d94-44ad-80c6-446eff61b76b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[KeyDevelopment(year=None, description='Car, or an automobile, is a motor vehicle with wheels.', evidence='A car, or an automobile, is a motor vehicle with wheels.'),\n KeyDevelopment(year=1769, description='Французский изобретатель Николя-Жозеф Кюньо создал первый паровой автомобиль в 1769 году', evidence='French inventor Nicolas-Joseph Cugnot built the first steam-powered road vehicle in 1769'),\n KeyDevelopment(year=1886, description='Немецкий изобретатель Карл Бенц запатентовал свой Benz Patent-Motorwagen в 1886 году', evidence='The modern car—a practical, marketable automobile for everyday use—was invented in 1886, when German inventor Carl Benz patented his Benz Patent-Motorwagen.'),\n KeyDevelopment(year=1908, description='Модель Т, американский автомобиль, произведенный компанией Ford Motor Company, стал доступным для масс в 1908 году', evidence='One of the first cars affordable by the masses was the 1908 Model T, an American car manufactured by the Ford Motor Company.'),\n KeyDevelopment(year=1897, description=\"Автомобиль - классический композит, полученный из древнегреческого autós (αὐτός) 'сам' и латинского mobilis 'передвижной', вошел в английский язык из французского и был впервые принят Автомобильным клубом Великобритании в 1897 году.\", evidence='\"Automobile\", a classical compound derived from Ancient Greek autós (αὐτός) \"self\" and Latin mobilis \"movable\", entered English from French and was first adopted by the Automobile Club of Great Britain in 1897.[20]'),\n KeyDevelopment(year=1678, description='Первая паровая машина Вербиста, в 1678 году (Фердинанд Вербист)', evidence='Steam machine of Verbiest, in 1678 (Ferdinand Verbiest)'),\n KeyDevelopment(year=1771, description='Фардиер Кюньо 1771 года, сохранившийся в Музее искусств и ремесел в Париже', evidence=\"Cugnot's 1771 fardier à vapeur, as preserved at the Musée des Arts et Métiers, Paris\"),\n KeyDevelopment(year=1885, description='Карл Бенц, изобретатель современного автомобиля', evidence='The original Benz Patent-Motorwagen, the first modern car, built in 1885 and awarded the patent for the concept'),\n KeyDevelopment(year=None, description='Берта Бенц, первый водитель на дальние расстояния', evidence='Bertha Benz, the first long distance driver'),\n KeyDevelopment(year=None, description='Флокен Электроваген был первым четырехколесным электрическим автомобилем', evidence='The Flocken Elektrowagen was the first four-wheeled electric car'),\n KeyDevelopment(year=None, description='Штутгарт, колыбель автомобиля[24][25], где Готтлиб Даймлер и Вильгельм Майбах работали в Даймлер Моторен Гезельшафт, и место современных штаб-квартир Мерседес-Бенц Групп и Порше', evidence='Stuttgart, a cradle of the car[24][25] with Gottlieb Daimler and Wilhelm Maybach working there at the Daimler Motoren Gesellschaft and place of the modern day headquarters of Mercedes-Benz Group and Porsche'),\n KeyDevelopment(year=1769, description='Николя-Жозеф Кюньо создал первый полноразмерный самоходный механический автомобиль в 1769 году.', evidence='Nicolas-Joseph Cugnot is widely credited with building the first full-scale, self-propelled mechanical vehicle in about 1769'),\n KeyDevelopment(year=1801, description=\"Ричард Тревитик построил и продемонстрировал свою дорожную паровую машину 'Дьявол с пыхтением' в 1801 году.\", evidence='In 1801, Richard Trevithick built and demonstrated his Puffing Devil road locomotive'),\n KeyDevelopment(year=1807, description='Ньепс и его брат Клауд создали первый в мире двигатель внутреннего сгорания в 1807 году.', evidence=\"In 1807, Nicéphore Niépce and his brother Claude created what was probably the world's first internal combustion engine\"),\n KeyDevelopment(year=1881, description='Густав Труве демонстрирует трехколесный электромобиль на Международной электротехнической выставке', evidence='В ноябре 1881 года французский изобретатель Густав Труве продемонстрировал трехколесный автомобиль, работающий на электричестве, на Международной электротехнической выставке'),\n KeyDevelopment(year=1886, description='Карл Бенц патентует свой Benz Patent-Motorwagen', evidence='В 1886 году немец Карл Бенц получил патент на свой Benz Patent-Motorwagen'),\n KeyDevelopment(year=1888, description='Берта Бенц совершает первую поездку на автомобиле', evidence='В августе 1888 года Берта Бенц, жена Карла Бенца, совершила первую поездку на автомобиле, чтобы доказать его пригодность для дорог'),\n KeyDevelopment(year=1890, description='Даймлер и Майбах основали Даймлер Моторен Гезельшафт (DMG) в Каннштадте в 1890 году', evidence='Daimler and Maybach founded Daimler Motoren Gesellschaft (DMG) in Cannstatt in 1890'),\n KeyDevelopment(year=1896, description='Бенц разработал и запатентовал первый внутренне-сгораемый плоский двигатель', evidence='In 1896, Benz designed and patented the first internal-combustion flat engine'),\n KeyDevelopment(year=1899, description='Бенц был самым большим автомобильным производителем в мире', evidence='Benz was the largest car company in the world with 572 units produced in 1899')]"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key_developments = []\n",
    "\n",
    "for extraction in extractions:\n",
    "    key_developments.extend(extraction.key_developments)\n",
    "\n",
    "key_developments[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48afd4a7-abcd-48b4-8ff1-6ca485f529e3",
   "metadata": {},
   "source": [
    "## RAG based approach\n",
    "\n",
    "Another simple idea is to chunk up the text, but instead of extracting information from every chunk, just focus on the the most relevant chunks.\n",
    "\n",
    ":::{.callout-caution}\n",
    "It can be difficult to identify which chunks are relevant.\n",
    "\n",
    "For example, in the `car` article we're using here, most of the article contains key development information. So by using\n",
    "**RAG**, we'll likely be throwing out a lot of relevant information.\n",
    "\n",
    "We suggest experimenting with your use case and determining whether this approach works or not.\n",
    ":::\n",
    "\n",
    "Here's a simple example that relies on the `FAISS` vectorstore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "aaf37c82-625b-4fa1-8e88-73303f08ac16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.runnables import RunnableLambda, RunnableParallel\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "texts = text_splitter.split_text(document.page_content)\n",
    "vectorstore = FAISS.from_texts(texts, embedding=OpenAIEmbeddings())\n",
    "\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_kwargs={\"k\": 3}\n",
    ")  # Only extract from first document"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013ecad9-f80f-477c-b954-494b46a02a07",
   "metadata": {},
   "source": [
    "In this case the RAG extractor is only looking at the top document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "47aad00b-7013-4f7f-a1b0-02ef269093bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_docs(docs):\n",
    "    return \"\\n\\n\".join([doc.page_content for doc in docs])\n",
    "\n",
    "rag_extractor = {\n",
    "    \"text\": retriever | combine_docs,  # fetch content of top doc\n",
    "    \"examples\": lambda x : messages\n",
    "} | extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "68f2de01-0cd8-456e-a959-db236189d41b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Giga generation stopped with reason: function_call\n"
     ]
    }
   ],
   "source": [
    "results = rag_extractor.invoke(\"Key developments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "56f434ea-1869-4192-914e-3ccf64e72f75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "year=2018 description='Рост популярности автомобилей и поездок привел к заторам на дорогах.' evidence='Так, Москва, Стамбул, Богота, Мехико и Сан-Паулу были самыми загруженными городами в 2018 году, согласно данным компании INRIX, специализирующейся на анализе данных.'\n",
      "year=1924 description='В Европе происходило то же самое.' evidence='Morris начал производство на конвейере в Ковли в 1924 году и вскоре стал продавать больше автомобилей, чем Ford, а также начал следовать практике вертикальной интеграции Ford, покупая двигатели, коробки передач и радиаторы у других компаний.'\n",
      "year=None description='В Японии производство автомобилей было ограничено до Второй мировой войны.' evidence='Только несколько компаний производили автомобили в ограниченном количестве, и эти автомобили были небольшими, трехколесными для коммерческих целей или были результатом партнерства с европейскими компаниями.'\n",
      "year=None description='Большинство автомобилей, используемых в начале 2020-х годов, работают на бензине, который сжигается в двигателе внутреннего сгорания.' evidence='Международная организация производителей моторных транспортных средств заявляет, что в странах, где требуется низкосернистый бензин, автомобили, работающие на бензине и соответствующие стандартам поздних 2010-х годов, например, Евро-6, выделяют очень мало локальных загрязнителей воздуха.'\n",
      "year=2021 description='Девять процентов всех проданных в 2021 году автомобилей были электрическими.' evidence='К концу 2021 года в мире насчитывалось более 16 миллионов электромобилей.'\n"
     ]
    }
   ],
   "source": [
    "for key_development in results.key_developments:\n",
    "    print(key_development)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf36e626-cf5d-4324-ba29-9bd602be9b97",
   "metadata": {},
   "source": [
    "## Common issues\n",
    "\n",
    "Different methods have their own pros and cons related to cost, speed, and accuracy.\n",
    "\n",
    "Watch out for these issues:\n",
    "\n",
    "* Chunking content means that the LLM can fail to extract information if the information is spread across multiple chunks.\n",
    "* Large chunk overlap may cause the same information to be extracted twice, so be prepared to de-duplicate!\n",
    "* LLMs can make up data. If looking for a single fact across a large text and using a brute force approach, you may end up getting more made up data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
