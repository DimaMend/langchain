{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3ee8d00",
   "metadata": {},
   "source": [
    "# How to split text based on semantic similarity\n",
    "\n",
    "Taken from Greg Kamradt's wonderful notebook:\n",
    "[5_Levels_Of_Text_Splitting](https://github.com/FullStackRetrieval-com/RetrievalTutorials/blob/main/tutorials/LevelsOfTextSplitting/5_Levels_Of_Text_Splitting.ipynb)\n",
    "\n",
    "All credit to him.\n",
    "\n",
    "This guide covers how to split chunks based on their semantic similarity. If embeddings are sufficiently far apart, chunks are split.\n",
    "\n",
    "At a high level, this splits into sentences, then groups into groups of 3\n",
    "sentences, and then merges one that are similar in the embedding space."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542f4427",
   "metadata": {},
   "source": [
    "## Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c58769",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --quiet langchain_experimental langchain_openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20cdf54",
   "metadata": {},
   "source": [
    "## Load Example Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313fb032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a long document we can split up.\n",
    "with open(\"state_of_the_union.txt\") as f:\n",
    "    state_of_the_union = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7436e15",
   "metadata": {},
   "source": [
    "## Create Text Splitter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774a5199-c2ff-43bc-bf07-87573e0b8db4",
   "metadata": {},
   "source": [
    "To instantiate a [SemanticChunker](https://python.langchain.com/api_reference/experimental/text_splitter/langchain_experimental.text_splitter.SemanticChunker.html), we must specify an embedding model. Below we will use [OpenAIEmbeddings](https://python.langchain.com/api_reference/community/embeddings/langchain_community.embeddings.openai.OpenAIEmbeddings.html). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88ff70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "\n",
    "text_splitter = SemanticChunker(OpenAIEmbeddings())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b14834",
   "metadata": {},
   "source": [
    "## Split Text\n",
    "\n",
    "We split text in the usual way, e.g., by invoking `.create_documents` to create LangChain [Document](https://python.langchain.com/api_reference/core/documents/langchain_core.documents.base.Document.html) objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295ec095",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = text_splitter.create_documents([state_of_the_union])\n",
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aed73b2",
   "metadata": {},
   "source": [
    "## Breakpoints\n",
    "\n",
    "This chunker works by determining when to \"break\" apart sentences. This is done by looking for differences in embeddings between any two sentences. When that difference is past some threshold, then they are split.\n",
    "\n",
    "There are a few ways to determine what that threshold is, which are controlled by the `breakpoint_threshold_type` kwarg.\n",
    "\n",
    "### Percentile\n",
    "\n",
    "The default way to split is based on percentile. In this method, all differences between sentences are calculated, and then any difference greater than the X percentile is split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a3b9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = SemanticChunker(\n",
    "    OpenAIEmbeddings(), breakpoint_threshold_type=\"percentile\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f311e67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = text_splitter.create_documents([state_of_the_union])\n",
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5930de",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(docs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b51104",
   "metadata": {},
   "source": [
    "### Standard Deviation\n",
    "\n",
    "In this method, any difference greater than X standard deviations is split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5e005c",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = SemanticChunker(\n",
    "    OpenAIEmbeddings(), breakpoint_threshold_type=\"standard_deviation\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b8ffc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = text_splitter.create_documents([state_of_the_union])\n",
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8938a5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(docs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6897261f",
   "metadata": {},
   "source": [
    "### Interquartile\n",
    "\n",
    "In this method, the interquartile distance is used to split chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8977355b",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = SemanticChunker(\n",
    "    OpenAIEmbeddings(), breakpoint_threshold_type=\"interquartile\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a40364",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = text_splitter.create_documents([state_of_the_union])\n",
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0db107",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(docs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423c6e099e94ca69",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Gradient\n",
    "\n",
    "In this method, the gradient of distance is used to split chunks along with the percentile method.\n",
    "This method is useful when chunks are highly correlated with each other or specific to a domain e.g. legal or medical. The idea is to apply anomaly detection on gradient array so that the distribution become wider and easy to identify boundaries in highly semantic data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f65472",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = SemanticChunker(\n",
    "    OpenAIEmbeddings(), breakpoint_threshold_type=\"gradient\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9f393d316ce1f6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Madam Speaker, Madam Vice President, our First Lady and Second Gentleman.\n"
     ]
    }
   ],
   "source": [
    "docs = text_splitter.create_documents([state_of_the_union])\n",
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a407cd57f02a0db4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n"
     ]
    }
   ],
   "source": [
    "print(len(docs))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
