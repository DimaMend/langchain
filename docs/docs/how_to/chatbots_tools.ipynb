{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# How to add tools to chatbots\n",
                "\n",
                ":::info Prerequisites\n",
                "\n",
                "This guide assumes familiarity with the following concepts:\n",
                "\n",
                "- [Chatbots](/docs/concepts/#messages)\n",
                "- [Agents](/docs/tutorials/agents)\n",
                "- [Chat history](/docs/concepts/#chat-history)\n",
                "\n",
                ":::\n",
                "\n",
                "This section will cover how to create conversational agents: chatbots that can interact with other systems and APIs using tools.\n",
                "\n",
                "## Setup\n",
                "\n",
                "For this guide, we'll be using a [tool calling agent](/docs/how_to/agent_executor) with a single tool for searching the web. The default will be powered by [Tavily](/docs/integrations/tools/tavily_search), but you can switch it out for any similar tool. The rest of this section will assume you're using Tavily.\n",
                "\n",
                "You'll need to [sign up for an account](https://tavily.com/) on the Tavily website, and install the following packages:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "%pip install --upgrade --quiet langchain-community langchain-openai tavily-python\n",
                "\n",
                "# Set env var OPENAI_API_KEY or load from a .env file:\n",
                "import dotenv\n",
                "\n",
                "dotenv.load_dotenv()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "You will also need your OpenAI key set as `OPENAI_API_KEY` and your Tavily API key set as `TAVILY_API_KEY`."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Creating an agent\n",
                "\n",
                "Our end goal is to create an agent that can respond conversationally to user questions while looking up information as needed.\n",
                "\n",
                "First, let's initialize Tavily and an OpenAI chat model capable of tool calling:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from langchain_community.tools.tavily_search import TavilySearchResults\n",
                "from langchain_openai import ChatOpenAI\n",
                "\n",
                "tools = [TavilySearchResults(max_results=1)]\n",
                "\n",
                "# Choose the LLM that will drive the agent\n",
                "# Only certain models support this\n",
                "chat = ChatOpenAI(model=\"gpt-3.5-turbo-1106\", temperature=0)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "To make our agent conversational, we must also choose a prompt with a placeholder for our chat history. Here's an example:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from langchain_core.prompts import ChatPromptTemplate\n",
                "\n",
                "# Adapted from https://smith.langchain.com/hub/jacob/tool-calling-agent\n",
                "prompt = ChatPromptTemplate.from_messages(\n",
                "    [\n",
                "        (\n",
                "            \"system\",\n",
                "            \"You are a helpful assistant. You may not need to use tools for every query - the user may just want to chat!\",\n",
                "        ),\n",
                "        (\"placeholder\", \"{messages}\"),\n",
                "        (\"placeholder\", \"{agent_scratchpad}\"),\n",
                "    ]\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Great! Now let's assemble our agent:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from langchain.agents import AgentExecutor, create_tool_calling_agent\n",
                "\n",
                "agent = create_tool_calling_agent(chat, tools, prompt)\n",
                "\n",
                "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Running the agent\n",
                "\n",
                "Now that we've set up our agent, let's try interacting with it! It can handle both trivial queries that require no lookup:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from langchain_core.messages import HumanMessage\n",
                "\n",
                "agent_executor.invoke({\"messages\": [HumanMessage(content=\"I'm Nemo!\")]})"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Or, it can use of the passed search tool to get up to date information if needed:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "agent_executor.invoke(\n",
                "    {\n",
                "        \"messages\": [\n",
                "            HumanMessage(\n",
                "                content=\"What is the current conservation status of the Great Barrier Reef?\"\n",
                "            )\n",
                "        ],\n",
                "    }\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Conversational responses\n",
                "\n",
                "Because our prompt contains a placeholder for chat history messages, our agent can also take previous interactions into account and respond conversationally like a standard chatbot:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from langchain_core.messages import AIMessage, HumanMessage\n",
                "\n",
                "agent_executor.invoke(\n",
                "    {\n",
                "        \"messages\": [\n",
                "            HumanMessage(content=\"I'm Nemo!\"),\n",
                "            AIMessage(content=\"Hello Nemo! How can I assist you today?\"),\n",
                "            HumanMessage(content=\"What is my name?\"),\n",
                "        ],\n",
                "    }\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "If preferred, you can also wrap the agent executor in a [`RunnableWithMessageHistory`](/docs/how_to/message_history/) class to internally manage history messages. Let's redeclare it this way:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "agent = create_tool_calling_agent(chat, tools, prompt)\n",
                "\n",
                "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Then, because our agent executor has multiple outputs, we also have to set the `output_messages_key` property when initializing the wrapper:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from langchain_community.chat_message_histories import ChatMessageHistory\n",
                "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
                "\n",
                "demo_ephemeral_chat_history_for_chain = ChatMessageHistory()\n",
                "\n",
                "conversational_agent_executor = RunnableWithMessageHistory(\n",
                "    agent_executor,\n",
                "    lambda session_id: demo_ephemeral_chat_history_for_chain,\n",
                "    input_messages_key=\"messages\",\n",
                "    output_messages_key=\"output\",\n",
                ")\n",
                "\n",
                "conversational_agent_executor.invoke(\n",
                "    {\"messages\": [HumanMessage(\"I'm Nemo!\")]},\n",
                "    {\"configurable\": {\"session_id\": \"unused\"}},\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "And then if we rerun our wrapped agent executor:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "conversational_agent_executor.invoke(\n",
                "    {\"messages\": [HumanMessage(\"What is my name?\")]},\n",
                "    {\"configurable\": {\"session_id\": \"unused\"}},\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "This [LangSmith trace](https://smith.langchain.com/public/1a9f712a-7918-4661-b3ff-d979bcc2af42/r) shows what's going on under the hood.\n",
                "\n",
                "## Further reading\n",
                "\n",
                "Other types agents can also support conversational responses too - for more, check out the [agents section](/docs/tutorials/agents).\n",
                "\n",
                "For more on tool usage, you can also check out [this use case section](/docs/how_to#tools)."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.1"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
