# Retrieval

## Conceptual Prerequisites

* [Retrievers](/docs/concepts/retrievers/)
* [Vectorstores](/docs/concepts/vectorstores/)
* [Embeddings](/docs/concepts/embedding_models/)
* [Text splitters](/docs/concepts/text_splitters/)

## Overview 

![Retrieval](/img/retrieval_high_level.png)

Search engines are one of the most widely-used applications of machine learning and AI, enabling search over large collections of documents.  
Retrieval is a core component of search engines.
From a large set of documents, a retrieval system indentifies a much smaller set of documents are that are most *relevant* to the search query.
Retrieval systems are very useful for AI applications, such as [Retrieval Augmented Generation](/docs/concepts/rag/), because they can extend the model's internal knowledge.

## Key concepts 

![Retrieval](/img/retrieval_concept.png)

(1) Search index: A search index enables efficient retrieval of documents based upon the search query.
(2) Query analysis: A model can be used to transform or construct the search query. 

## Search Index 

An search index is a data structure that improves the speed and efficiency of retrieval. 

### Unstructured data 

For indexing unstructured data, LangChain uses the `retriever` abstraction. 
A `retriever` is an interface that returns documents given an unstructured text input (e.g., a natural language user query).
Many retrievers use some kind of index (e.g., an **inverted index** for lexical search or a **vector index** for semantic search) to find documents that are most relevant to the search query.
See our conceptual overview of [retrievers](/docs/concepts/retrievers/) for more details.

### Structured data 

For indexing structured data, many kinds of relational or graph databases can be used.
In relational databases, for example, indexes are typically created on specific columns to speed up query performance. 
They work like a book's table of contents, allowing the database to quickly locate the data without scanning the entire table.

## Query Analysis 

Users typically interact with a retrieval system using natural language.
However, search indexes often require a specific query syntax (e.g., SQL or metadata filters) or can benefit from use of specific keywords (e.g., for semantic or lexical search).
Query analysis is a powerful concept to help bridge the gap between raw, natural language queries and queries optimized for search indexes.
The concept is simply to use a model to transform or construct the search query from a raw user input query.

### Unstructured data

Ideally a retrieval system that indexes unstructured data can handle a wide range of (user) inputs, from poorly worded to complex multi-part queries.
To enable this, a popular approch is to use an LLM to translate a raw user query into a query that is better optimized for the retrieval system. 
For example, this can be as simple as extracting keywords or as complex as generating multiple sub-questions for a complex query.
There are various approaches for achieving this, including:

| Name          | When to use | Description                                                                                                                                                                                                                                                                            |
|---------------|-------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| [Multi-query](/docs/how_to/MultiQueryRetriever/)   | When you need to cover multiple perspectives of a question. | Rewrite the user question from multiple perspectives, retrieve documents for each rewritten question, return the unique documents for all queries. |
| [Decomposition](https://github.com/langchain-ai/rag-from-scratch/blob/main/rag_from_scratch_5_to_9.ipynb) | When a question can be broken down into smaller subproblems. | Decompose a question into a set of subproblems / questions, which can either be solved sequentially (use the answer from first + retrieval to answer the second) or in parallel (consolidate each answer into final answer).                                                           |
| [Step-back](https://github.com/langchain-ai/rag-from-scratch/blob/main/rag_from_scratch_5_to_9.ipynb)     | When a higher-level conceptual understanding is required. | First prompt the LLM to ask a generic step-back question about higher-level concepts or principles, and retrieve relevant facts about them. Use this grounding to help answer the user question. [Paper](https://arxiv.org/pdf/2310.06117).                                            |
| [HyDE](https://github.com/langchain-ai/rag-from-scratch/blob/main/rag_from_scratch_5_to_9.ipynb)          | If you have challenges retrieving relevant documents using the raw user inputs. | Use an LLM to convert questions into hypothetical documents that answer the question. Use the embedded hypothetical documents to retrieve real documents with the premise that doc-doc similarity search can produce more relevant matches. [Paper](https://arxiv.org/abs/2212.10496). |

:::tip

See our RAG from Scratch videos for a few different specific approaches:
- [Multi-query](https://youtu.be/JChPi0CRnDY?feature=shared)
- [Decomposition](https://youtu.be/h0OPWlEOank?feature=shared)
- [Step-back](https://youtu.be/xn1jEjRyJ2U?feature=shared)
- [HyDE](https://youtu.be/SaDzIVkYqyY?feature=shared)

:::

### Semi-structured and structred data

Various DSLs (Domain Specific Languages) have been developed to interact with retrieval systems including SQL, Cypher, and PQL.
A popular approach to interacting with structured data is to use a model to convert natural language queries into a DSL for the relevant retrieval systems.  
For structured data, [text-to-SQL](/docs/tutorials/sql_qa/) and [text-to-Cypher](/docs/tutorials/graph/) are particularly popular. 
For semi-structured data, such as vector stores that utilize metadata, a popular approach is to use an LLM to convert a natural language query into a metadata filter.

| Name                                        | When to Use                                                                                                                                   | Description                                                                                                                                                                                                                                                                                      |
|---------------------------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| [Self Query](/docs/how_to/self_query/)      | If users are asking questions that are better answered by fetching documents based on metadata rather than similarity with the text.          | This uses an LLM to transform user input into two things: (1) a string to look up semantically, (2) a metadata filter to go along with it. This is useful because oftentimes questions are about the METADATA of documents (not the content itself).                                              |
| [Text to SQL](/docs/tutorials/sql_qa/)      | If users are asking questions that require information housed in a relational database, accessible via SQL.                                   | This uses an LLM to transform user input into a SQL query.                                             |
| [Text-to-Cypher](/docs/tutorials/graph/)    | If users are asking questions that require information housed in a graph database, accessible via Cypher.                                     | This uses an LLM to transform user input into a Cypher query.                                              |

See our tutorials on [text-to-SQL](/docs/tutorials/sql_qa/), [text-to-Cypher](/docs/tutorials/graph/), and [query analysis for metadata filters](/docs/tutorials/query_analysis/#query-analysis)for more details.

:::tip

See our [blog post overview](https://blog.langchain.dev/query-construction/) and RAG from Scratch video on [query construction](https://youtu.be/kl6NwWYxvbM?feature=shared).

:::
