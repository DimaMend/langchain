# Tools

:::info Prerequisites
- [Chat models](/docs/concepts/chat_models/)
:::

## What is a Tool?

A **tool** is a lightweight abstraction that links a function (executable code) with a schema that defines its input, output, and name.

Chat models that support native [tool calling](/docs/concepts/tool_calling) can be configured with the



By configuring chat models properly, we can enable them to 


A **tool** is a lightweight abstraction that associates a function (executable code) with a schema that describes the input, output, and the name of the function to be executed. 

Tools are designed to allow a chat model to understand how to request the execution of specific code based on its schema and description. Essentially, tools bridge the gap between a model’s need to control external code and the code itself.

Tools are generally used when you want the model to control parts of your code or to call out to external APIs.

## Interface

LangChain tools implement the [BaseTool](https://python.langchain.com/api_reference/core/tools/langchain_core.tools.base.BaseTool.html#langchain_core.tools.base.BaseTool) interface. A tool consists of:

1. **`name`**: The name of the tool.
2. **`description`**: A description of what the tool does.
3. **`JSON schema`**: Defines the inputs to the tool.
4. **`function`**: The actual code that will be executed, with an optional async variant.

When bound to a model, the tool’s `name`, `description`, and `JSON schema` are provided as context, allowing the model to choose and invoke the tool with specific inputs.

### Example

```python
tools = [...] # Define a list of tools
llm_with_tools = llm.bind_tools(tools)
ai_msg = llm_with_tools.invoke("do xyz...")
# -> AIMessage(tool_calls=[ToolCall(...), ...], ...)
```

If the model determines that a tool is required, it will generate `tool_calls` in its response, which can then be executed by the respective tool.

## Creating a Tool

The recommended way to create tools is using the `@tool` abstraction. This decorator is designed to simplify the process of tool creation and should be used in most cases. Tools created with `@tool` support both synchronous and asynchronous functions.

Here’s a basic example:

```python
from langchain.tools import tool

@tool
def example_tool(input_data: str) -> str:
    # Tool logic here
    return f"Processed {input_data}"
```

Additionally, `@tool` supports injecting arguments that are not controlled by the model. This is useful when runtime information, such as user-specific data, needs to be passed to the function but should not be generated by the model itself.

Other approaches to creating tools exist, but using `@tool` is highly encouraged for most cases.

## Using a Tool

After the model suggests a tool through a `tool_call`, the tool can be invoked with its arguments, and the result will be passed back to the model. There are two common approaches:

1. **Invoke with just the arguments**: This allows for the raw tool output to be passed to the model.

   Example:

   ```python
   tool_call = ai_msg.tool_calls[0]
   tool_output = tool.invoke(tool_call["args"])
   tool_message = ToolMessage(
       content=tool_output,
       tool_call_id=tool_call["id"],
       name=tool_call["name"]
   )
   ```

2. **Invoke with `ToolCall`**: This provides the tool with the full `ToolCall`, which returns a `ToolMessage` automatically.

   Example:

   ```python
   tool_call = ai_msg.tool_calls[0]
   tool_message = tool.invoke(tool_call)
   ```

This allows you to efficiently manage tool invocations and responses.

## Best Practices

When designing tools to be used by models, keep the following in mind:

- Chat models with explicit [tool-calling APIs](https://docs.langchain.com/docs/concepts/#functiontool-calling) are more proficient at calling tools than models that are not fine-tuned for this.
- Carefully select the `name`, `description`, and `JSON schema` of the tool for better performance. These attributes form part of the prompt engineering.
- Design simple and narrowly scoped tools, as they are easier for models to invoke correctly.
- Where possible, use the `@tool` abstraction for creating tools. It supports both sync and async methods and simplifies the process of defining a tool.

## Injected Tool Arguments

There are cases where certain arguments need to be passed to a tool at runtime but should not be generated by the model itself. For this, we use the `InjectedToolArg` annotation, which allows certain parameters to be injected during execution.

For example, if a tool requires a `user_id` to be injected dynamically at runtime, it can be structured in this way:

```python
@tool
def user_specific_tool(input_data: str, user_id: InjectedToolArg) -> str:
    return f"User {user_id} processed {input_data}"
```

The `user_id` is injected into the function when the tool is invoked, but the model doesn’t control or generate this argument.

## Related

For more information on:

- Using tools, see the [tools how-to guides](https://docs.langchain.com/docs/how_to/#tools).
- Tool integrations, see the [tool integration docs](https://docs.langchain.com/docs/integrations/tools/).
- Defining tools that return artifacts, see the [tool artifact documentation](https://docs.langchain.com/docs/how_to/tool_artifacts/).

