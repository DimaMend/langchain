# Chat Models

PLACE HOLDER TO BE REPLACED BY ACTUAL DOCUMENTATION
USED TO MAKE SURE THAT WE DO NOT FORGET TO ADD LINKS LATER

* Follows the Runnable Interface: efficient batching, async, streaming etc.

## System Message

## User Message

## AI Message

### Usage Metadata

## Tool Messages

### Artifacts

## Chat Model Context Length

## Tokenization

## Cache

* Cache is available, but should be exercised with caution.
* Cache hits are unlikely below the first or second level of conversation if using exact matches.
* Would need to use a semantic cache to get more hits, but even then conceptually it is not a good idea to cache too much


## Retries

...



## Rate-limiting

* Many providers have rate limits.

