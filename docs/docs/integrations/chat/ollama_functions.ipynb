{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "sidebar_label: Ollama Functions\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OllamaFunctions\n",
    "\n",
    "This notebook shows how to use an experimental wrapper around Ollama that gives it [tool calling capabilities](https://python.langchain.com/v0.2/docs/concepts/#functiontool-calling).\n",
    "\n",
    "Note that more powerful and capable models will perform better with complex schema and/or multiple functions. The examples below use llama3 and phi3 models.\n",
    "For a complete list of supported models and model variants, see the [Ollama model library](https://ollama.ai/library).\n",
    "\n",
    ":::warning\n",
    "\n",
    "This is an experimental wrapper that attempts to bolt-on tool calling support to models that do not natively support it. Use with caution.\n",
    "\n",
    ":::\n",
    "## Overview\n",
    "\n",
    "### Integration details\n",
    "\n",
    "|                                                                Class                                                                | Package | Local | Serializable | JS support | Package downloads | Package latest |\n",
    "|:-----------------------------------------------------------------------------------------------------------------------------------:|:-------:|:-----:|:------------:|:----------:|:-----------------:|:--------------:|\n",
    "| [OllamaFunctions](https://api.python.langchain.com/en/latest/llms/langchain_experimental.llms.ollama_function.OllamaFunctions.html) | [langchain-experimental](https://api.python.langchain.com/en/latest/openai_api_reference.html) | ✅ | ❌ | ❌ | ![PyPI - Downloads](https://img.shields.io/pypi/dm/langchain-experimental?style=flat-square&label=%20) | ![PyPI - Version](https://img.shields.io/pypi/v/langchain-experimental?style=flat-square&label=%20) |\n",
    "\n",
    "### Model features\n",
    "\n",
    "| [Tool calling](/docs/how_to/tool_calling/) | [Structured output](/docs/how_to/structured_output/) | JSON mode | Image input | Audio input | Video input | [Token-level streaming](/docs/how_to/chat_streaming/) | Native async | [Token usage](/docs/how_to/chat_token_usage_tracking/) | [Logprobs](/docs/how_to/logprobs/) |\n",
    "| :---: | :---: | :---: | :---: |  :---: | :---: | :---: | :---: | :---: | :---: |\n",
    "| ✅ | ✅ | ✅ | ✅ | ❌ | ❌ | ❌ | ✅ | ❌ | ❌ |\n",
    "\n",
    "## Setup\n",
    "\n",
    "To access `OllamaFunctions` you will need to install `langchain-experimental` integration package.\n",
    "Follow [these instructions](https://github.com/jmorganca/ollama) to set up and run a local Ollama instance as well as download and serve [supported models](https://ollama.com/library).\n",
    "\n",
    "### Credentials\n",
    "\n",
    "Credentials support is not present at this time.\n",
    "\n",
    "### Installation\n",
    "\n",
    "The `OllamaFunctions` class lives in the `langchain-experimental` package:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qU langchain-experimental"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiation\n",
    "\n",
    "`OllamaFunctions` takes the same init parameters as `ChatOllama`. \n",
    "\n",
    "In order to use tool calling, you must also specify `format=\"json\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T15:20:21.818089Z",
     "start_time": "2024-06-23T15:20:21.815759Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_experimental.llms.ollama_functions import OllamaFunctions\n",
    "\n",
    "llm = OllamaFunctions(model=\"phi3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Invocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T15:20:46.794689Z",
     "start_time": "2024-06-23T15:20:44.982632Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"J'adore programmer.\", id='run-94815fcf-ae11-438a-ba3f-00819328b5cd-0')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    (\n",
    "        \"system\",\n",
    "        \"You are a helpful assistant that translates English to French. Translate the user sentence.\",\n",
    "    ),\n",
    "    (\"human\", \"I love programming.\"),\n",
    "]\n",
    "ai_msg = llm.invoke(messages)\n",
    "ai_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"J'adore programmer.\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_msg.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chaining\n",
    "\n",
    "We can [chain](https://python.langchain.com/v0.2/docs/how_to/sequence/) our model with a prompt template like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Programmieren ist sehr verrückt! Es freut mich, dass Sie auf Programmierung so positiv eingestellt sind.', id='run-ee99be5e-4d48-4ab6-b602-35415f0bdbde-0')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant that translates {input_language} to {output_language}.\",\n",
    "        ),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | llm\n",
    "chain.invoke(\n",
    "    {\n",
    "        \"input_language\": \"English\",\n",
    "        \"output_language\": \"German\",\n",
    "        \"input\": \"I love programming.\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tool Calling\n",
    "\n",
    "### OllamaFunctions.bind_tools()\n",
    "\n",
    "With `OllamaFunctions.bind_tools`, we can easily pass in Pydantic classes, dict schemas, LangChain tools, or even functions as tools to the model. Under the hood these are converted to a tool definition schemas, which looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "\n",
    "class GetWeather(BaseModel):\n",
    "    \"\"\"Get the current weather in a given location\"\"\"\n",
    "\n",
    "    location: str = Field(..., description=\"The city and state, e.g. San Francisco, CA\")\n",
    "\n",
    "\n",
    "llm_with_tools = llm.bind_tools([GetWeather])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', id='run-b9769435-ec6a-4cb8-8545-5a5035fc19bd-0', tool_calls=[{'name': 'GetWeather', 'args': {'location': 'San Francisco, CA'}, 'id': 'call_064c4e1cb27e4adb9e4e7ed60362ecc9'}])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_msg = llm_with_tools.invoke(\n",
    "    \"what is the weather like in San Francisco\",\n",
    ")\n",
    "ai_msg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AIMessage.tool_calls\n",
    "\n",
    "Notice that the AIMessage has a `tool_calls` attribute. This contains in a standardized `ToolCall` format that is model-provider agnostic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'GetWeather',\n",
       "  'args': {'location': 'San Francisco, CA'},\n",
       "  'id': 'call_064c4e1cb27e4adb9e4e7ed60362ecc9'}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_msg.tool_calls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more on binding tools and tool call outputs, head to the [tool calling](docs/how_to/function_calling) docs.\n",
    "\n",
    "\n",
    "## Structured Output\n",
    "\n",
    "With `OllamaFunctions.with_structured_output()` you can specify a Pydantic class or a json schema to define the structure of the output you desire from the llm.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Joke(setup='Why was the cat sitting on the computer?', punchline='Because it wanted to be online!', rating=8)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Optional\n",
    "\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "\n",
    "class Joke(BaseModel):\n",
    "    \"\"\"Joke to tell user.\"\"\"\n",
    "\n",
    "    setup: str = Field(description=\"The setup of the joke\")\n",
    "    punchline: str = Field(description=\"The punchline to the joke\")\n",
    "    rating: Optional[int] = Field(description=\"How funny the joke is, from 1 to 10\")\n",
    "\n",
    "\n",
    "structured_llm = llm.with_structured_output(Joke)\n",
    "structured_llm.invoke(\"Tell me a joke about cats\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OllamaFunctions and Agents\n",
    "\n",
    "`OllamaFunctions` currently only supports creating agents using `LangGraph`.  \n",
    "An example of a simple tool calling agent built with LangGraph is shared below.  \n",
    "Building agents using the now legacy [`AgentExecutor`](https://python.langchain.com/v0.2/docs/how_to/agent_executor/) is not supported."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LangGraph Agent With Tool Calling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is an example of a simple Tool Calling LangGraph Agent using OllamaFunctions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install langchain-core==0.2.9 langchain-community==0.2.5 langchain-experimental==0.0.61 langgraph==0.0.69 duckduckgo-search==6.1.7 httpx==0.27.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "from IPython.display import Image, display\n",
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "from langchain_core.messages import AIMessage, BaseMessage, ToolMessage\n",
    "from langchain_core.tools import tool\n",
    "from langchain_experimental.llms.ollama_functions import OllamaFunctions\n",
    "from langgraph.graph import END, MessageGraph\n",
    "from langgraph.prebuilt import ToolNode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Tools\n",
    "\n",
    "Here we have created 4 custom tools and used an existing tool for our toolset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Tool to multiply two numbers\"\"\"\n",
    "    return a * b\n",
    "\n",
    "\n",
    "@tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Tool to add two numbers\"\"\"\n",
    "    return a + b\n",
    "\n",
    "\n",
    "@tool\n",
    "def call_miracle(request: str) -> str:\n",
    "    \"\"\"Tool to call miracle\"\"\"\n",
    "    return f\"You asked for {request}, but I can't do that\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def grant_wish(wish: str) -> str:\n",
    "    \"\"\"Tool to grant wish\"\"\"\n",
    "    return f\"You asked for {wish}. Your wish is my command!\"\n",
    "\n",
    "\n",
    "tools = [multiply, add, call_miracle, grant_wish, DuckDuckGoSearchRun(max_results=2)]\n",
    "\n",
    "# tool_node will be used as a node within the LangGraph agent\n",
    "tool_node = ToolNode(tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize LLM and bind tools\n",
    "\n",
    "You can use any tool calling capable LLM along with a model that offers good JSON support.  \n",
    "We have use `OllamaFunctions` with the `phi3` model here.  \n",
    "The complete list of natively supported [LLMs with tool calling can be found here](https://python.langchain.com/v0.1/docs/integrations/chat/)  \n",
    "\n",
    "We initialize `llm` and add tools description on it by calling `bind_tools` function on it.  \n",
    "This doesn't change `llm` itself, but returns a new LLM object that is aware of the tools specifications which we store as `llm_with_tools`.  \n",
    "\n",
    "We will use `llm_with_tools` for any tool aware LLM calls and use `llm` for other, non tool related LLM calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OllamaFunctions(model=\"phi3\", format=\"json\", temperature=0)\n",
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MessageGraph\n",
    "\n",
    "[MessageGraph](https://python.langchain.com/v0.1/docs/integrations/chat/) is a simple `LangGraph` state type where every node receives a list of messages as input and returns one or more messages as output.  \n",
    "\n",
    "This should be suitable for may use cases where you only need to track messages as part of the graph state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = MessageGraph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add nodes to graph\n",
    "\n",
    "Graph nodes have a name and take a callables as a second argument which are runnables that get invoked and are passed the entire state object.  \n",
    "\n",
    "Since `MessageGraph` is essentially just a collection of messages, you can use LLMs as the callable parameter.  \n",
    "\n",
    "* `oracle`: We pass `llm_with_tools` as this node with identify which tool needs to be called to complete the current request.\n",
    "* `tools`: We pass `tool_node` as the callable. If the last message in the state is an `AIMessage` with `tool_calls`, this node will use that information to call the approprtate tool from our toolset with the parameters specified in `tool_calls`.\n",
    "* `llm`: We pass `llm` as the callable. This node will take all the messages generated thus far and use that context to generate a new message. The expected outcome is the model's interpretation of the results from the tool run within the context of the initial question that was asked of the agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "builder.add_node(\"oracle\", llm_with_tools)\n",
    "builder.add_node(\"tools\", tool_node)\n",
    "builder.add_node(\"llm\", llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect agent nodes with edges\n",
    "\n",
    "This will be a simple linear graph.\n",
    "\n",
    "* `oracle` is the entry point.\n",
    "* `tools` node will be called after `oracle`.\n",
    "* `llm` node will be called after `tools`.\n",
    "* graph ends with the execution of `llm` node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "builder.add_edge(\"oracle\", \"tools\")\n",
    "builder.add_edge(\"tools\", \"llm\")\n",
    "builder.add_edge(\"llm\", END)\n",
    "builder.set_entry_point(\"oracle\")\n",
    "graph = builder.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the graph agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utility functions to pretty print messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_content(content: str) -> str:\n",
    "    if len(content) < 200:\n",
    "        return content\n",
    "    else:\n",
    "        return content[:200] + \"...\"\n",
    "\n",
    "\n",
    "def pretty_print(message: BaseMessage):\n",
    "    print(f\"type: {message.type}\", end=\"\")\n",
    "    if isinstance(message, AIMessage) and message.tool_calls:\n",
    "        print(f\", tool_calls: {message.tool_calls}\", end=\"\")\n",
    "    elif isinstance(message, ToolMessage):\n",
    "        print(f\", name: {message.name}\", end=\"\")\n",
    "    if message.content:\n",
    "        print(f\", content: {trim_content(message.content)}\", end=\"\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "\n",
    "def pretty_print_messages(messages: List[BaseMessage]):\n",
    "    [pretty_print(message) for message in messages]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the Agent\n",
    "\n",
    "Testing `add` custom tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = graph.invoke((\"human\", \"What is the sum of 2 and 3?\"))\n",
    "pretty_print_messages(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing `multiply` custom tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = graph.invoke((\"human\", \"What is 523 x 412?\"))\n",
    "pretty_print_messages(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing `call_miracle` custom tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = graph.invoke((\"human\", \"I need a miracle. I need it to rain tomorrow.\"))\n",
    "pretty_print_messages(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing `grant_wish` custom tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = graph.invoke((\"human\", \"I wish for world peace.\"))\n",
    "pretty_print_messages(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing `duckduckgo_search` tool `DuckDuckGoSearchRun`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = graph.invoke((\"human\", \"What is tomorrows weather in Austin, TX?\"))\n",
    "pretty_print_messages(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API reference\n",
    "\n",
    "For detailed documentation of all ToolCallingLLM features and configurations head to the API reference: https://api.python.langchain.com/en/latest/llms/langchain_experimental.llms.ollama_functions.OllamaFunctions.html\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
