{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oracle Cloud Infrastructure Generative AI\n",
    "\n",
    "Oracle Cloud Infrastructure (OCI) Generative AI is a fully managed service that provides a set of state-of-the-art, customizable large language models (LLMs) that cover a wide range of use cases, and which is available through a single API.\n",
    "Using the OCI Generative AI service you can access ready-to-use pretrained models, or create and host your own fine-tuned custom models based on your own data on dedicated AI clusters. Detailed documentation of the service and API is available __[here](https://docs.oracle.com/en-us/iaas/Content/generative-ai/home.htm)__ and __[here](https://docs.oracle.com/en-us/iaas/api/#/en/generative-ai/20231130/)__.\n",
    "\n",
    "This notebook explains how to use OCI's Generative AI chat models with LangChain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "#### Ensure that the oci sdk and the langchain_community package are installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U oci langchain_community"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chat with the cohere.command-r-16k model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models.oci_generative_ai import ChatOCIGenAI\n",
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
    "\n",
    "chat = ChatOCIGenAI(\n",
    "    model_id=\"cohere.command-r-16k\",\n",
    "    service_endpoint=\"https://inference.generativeai.us-chicago-1.oci.oraclecloud.com\",\n",
    "    compartment_id=\"MY_OCID\",\n",
    "    model_kwargs={\"temperature\": 0.7, \"max_tokens\": 500},\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"your are an AI assistant.\"),\n",
    "    AIMessage(content=\"Hi there human!\"),\n",
    "    HumanMessage(content=\"tell me a joke.\"),\n",
    "]\n",
    "\n",
    "\n",
    "response = chat.invoke(messages)\n",
    "print(response.content)\n",
    "print(response.response_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grounding cohere.command-r-16k with a list of relevant documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatOCIGenAI(\n",
    "    model_id=\"cohere.command-r-16k\",\n",
    "    service_endpoint=\"https://inference.generativeai.us-chicago-1.oci.oraclecloud.com\",\n",
    "    compartment_id=\"MY_OCID\",\n",
    "    model_kwargs={\"temperature\": 0.0, \"max_tokens\": 500},\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"your are an AI assistant.\"),\n",
    "    HumanMessage(content=\"Tell me something about Oracle.\"),\n",
    "    AIMessage(\n",
    "        content=\"Oracle is one of the largest vendors in the enterprise IT market and the shorthand name of its flagship product. The database software sits at the center of many corporate IT\"\n",
    "    ),\n",
    "    HumanMessage(content=\"Tell me something about the company's relational database.\"),\n",
    "]\n",
    "\n",
    "documents = [\n",
    "    {\n",
    "        \"title\": \"Oracle\",\n",
    "        \"snippet\": \"Oracle database services and products offer customers cost-optimized and high-performance versions of Oracle Database, the world's leading converged, multi-model database management system, as well as in-memory, NoSQL and MySQL databases. Oracle Autonomous Database, available on premises via Oracle Cloud@Customer or in the Oracle Cloud Infrastructure, enables customers to simplify relational database environments and reduce management workloads.\",\n",
    "        \"website\": \"https://www.oracle.com/database\",\n",
    "    }\n",
    "]\n",
    "\n",
    "response = chat.invoke(messages, documents=documents)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatOCIGenAI(\n",
    "    model_id=\"meta.llama-3-70b-instruct\",\n",
    "    service_endpoint=\"https://inference.generativeai.us-chicago-1.oci.oraclecloud.com\",\n",
    "    compartment_id=\"MY_OCID\",\n",
    "    model_kwargs={\"temperature\": 0, \"max_tokens\": 500},\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are a helpful AI assistant\"),\n",
    "    HumanMessage(content=\"Who is Paul Graham?\"),\n",
    "]\n",
    "\n",
    "response = chat.stream(messages)\n",
    "for r in response:\n",
    "    print(r.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chaining with prompt templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "chat = ChatOCIGenAI(\n",
    "    model_id=\"cohere.command-r-16k\",\n",
    "    service_endpoint=\"https://inference.generativeai.us-chicago-1.oci.oraclecloud.com\",\n",
    "    compartment_id=\"MY_OCID\",\n",
    "    model_kwargs={\"temperature\": 0.7, \"max_tokens\": 500},\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"Tell me a joke about {topic}\")\n",
    "chain = prompt | chat\n",
    "\n",
    "response = chain.invoke({\"topic\": \"dogs\"})\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authentication\n",
    "The authentication methods supported for LlamaIndex are equivalent to those used with other OCI services and follow the __[standard SDK authentication](https://docs.oracle.com/en-us/iaas/Content/API/Concepts/sdk_authentication_methods.htm)__ methods, specifically API Key, session token, instance principal, and resource principal.\n",
    "\n",
    "API key is the default authentication method used in the examples above. The following example demonstrates how to use a different authentication method (session token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatOCIGenAI(\n",
    "    model_id=\"meta.llama-3-70b-instruct\",\n",
    "    service_endpoint=\"https://inference.generativeai.us-chicago-1.oci.oraclecloud.com\",\n",
    "    compartment_id=\"MY_OCID\",\n",
    "    auth_type=\"SECURITY_TOKEN\",\n",
    "    auth_profile=\"MY_PROFILE\",  # replace with your profile name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dedicated AI Cluster\n",
    "To access models hosted in a dedicated AI cluster __[create an endpoint](https://docs.oracle.com/en-us/iaas/api/#/en/generative-ai-inference/20231130/)__ whose assigned OCID (currently prefixed by ‘ocid1.generativeaiendpoint.oc1.us-chicago-1’) is used as your model ID.\n",
    "\n",
    "When accessing models hosted in a dedicated AI cluster you will need to initialize the ChatOCIGenAI interface with two extra required params (\"provider\" and \"context_size\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatOCIGenAI(\n",
    "    model_id=\"ocid1.generativeaiendpoint.oc1.us-chicago-1....\",\n",
    "    service_endpoint=\"https://inference.generativeai.us-chicago-1.oci.oraclecloud.com\",\n",
    "    compartment_id=\"DEDICATED_COMPARTMENT_OCID\",\n",
    "    auth_profile=\"MY_PROFILE\",  # replace with your profile name,\n",
    "    provider=\"MODEL_PROVIDER\",  # e.g., \"cohere\" or \"meta\"\n",
    "    context_size=\"MODEL_CONTEXT_SIZE\",  # e.g., 128000\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
