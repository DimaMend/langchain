{
 "cells": [
  {
   "cell_type": "raw",
   "id": "23347b4f3990a67f",
   "metadata": {},
   "source": [
    "---\n",
    "sidebar_label: Tool Calling LLM\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22226fd146be3f7d",
   "metadata": {},
   "source": [
    "# Tool Calling LLM\n",
    "\n",
    "## Overview\n",
    "\n",
    "Tool Calling LLM is a python mixin that lets you add [tool calling capabilities](https://python.langchain.com/v0.2/docs/concepts/#functiontool-calling) effortlessly to [`LangChain Chat Models`](https://python.langchain.com/v0.2/docs/integrations/chat/) that don't yet support tool/function calling natively. \n",
    "Simply create a new chat model class with `ToolCallingLLM` and your favorite chat model to get started.  \n",
    "\n",
    "With `ToolCallingLLM` you also get access to [`.with_structured_output()`](https://python.langchain.com/v0.2/docs/how_to/structured_output/) which will allow you to return structured data from your model.  \n",
    "\n",
    "At this time, `ToolCallingLLM` has been tested to work with [`ChatNVIDIA`](https://python.langchain.com/v0.2/docs/integrations/chat/nvidia_ai_endpoints/) and [`ChatLiteLLM`](https://python.langchain.com/v0.2/docs/integrations/chat/litellm/) with Ollama provider.  \n",
    "\n",
    "The [`OllamaFunctions`](https://python.langchain.com/v0.2/docs/integrations/chat/ollama_functions/) which was the original inspiration for this effort has also been ported over to use `ToolCallingLLM`. The code for `ToolCallingLLM` was abstracted out of `OllamaFunctions` to allow it to be reused with other non tool calling Chat Models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4e2213e98ef14f",
   "metadata": {},
   "source": "## Tool Calling with LiteLLM"
  },
  {
   "cell_type": "markdown",
   "id": "1985b7c8db34b11f",
   "metadata": {},
   "source": "### Setup"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7556f3aef8f7260",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T17:30:58.698119Z",
     "start_time": "2024-06-19T17:30:55.160243Z"
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install litellm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45aa5992d0e8cf7",
   "metadata": {},
   "source": "### Import packages"
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "992bb94da819742a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T18:07:54.033360Z",
     "start_time": "2024-06-19T18:07:54.029332Z"
    }
   },
   "outputs": [],
   "source": [
    "from typing import Any, Dict, List, Optional, Tuple\n",
    "\n",
    "from langchain_community.chat_models import ChatLiteLLM\n",
    "from langchain_core.messages import (\n",
    "    AIMessage,\n",
    "    BaseMessage,\n",
    "    ChatMessage,\n",
    "    FunctionMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage,\n",
    "    ToolMessage,\n",
    ")\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_experimental.llms import ToolCallingLLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8cc855401b8197d",
   "metadata": {},
   "source": "### Create a structured output class"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25df98d776cd0d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Joke(BaseModel):\n",
    "    setup: str = Field(description=\"setup of the joke\")\n",
    "    punchline: str = Field(description=\"punchline of the joke\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae166b2a516ef46",
   "metadata": {},
   "source": "### Test with original Chat Model - ChatLiteLLM"
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "df40c9142c2c499a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T18:04:14.273873Z",
     "start_time": "2024-06-19T18:04:14.253285Z"
    }
   },
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[81], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mollama/phi3\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      3\u001b[0m llm \u001b[38;5;241m=\u001b[39m ChatLiteLLM(model\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[0;32m----> 5\u001b[0m llm_with_structured_output \u001b[38;5;241m=\u001b[39m \u001b[43mllm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwith_structured_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mJoke\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/langchain/libs/core/langchain_core/language_models/base.py:210\u001b[0m, in \u001b[0;36mBaseLanguageModel.with_structured_output\u001b[0;34m(self, schema, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Not implemented on this class.\"\"\"\u001b[39;00m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;66;03m# Implement this on child class if there is a way of steering the model to\u001b[39;00m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;66;03m# generate responses that match a given schema.\u001b[39;00m\n\u001b[0;32m--> 210\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m()\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = \"ollama/phi3\"\n",
    "\n",
    "llm = ChatLiteLLM(model=model)\n",
    "\n",
    "llm_with_structured_output = llm.with_structured_output(Joke)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe90d47959ee94a",
   "metadata": {},
   "source": [
    "### Create Tool Calling LLM for ChatLiteLLM\n",
    "\n",
    "In order to successfully handle tool calls, we need to override `_convert_message_to_dict` function that `ChatLiteLLM` depends on.  \n",
    "\n",
    "In this case, we include the missing else case for `ToolMessage`. To ensure our version of `_convert_message_to_dict` is called, we \n",
    "also have to include `_create_message_dicts` function from `ChatLiteLLM`. No changes are made to this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f6cd631dc51d1460",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T18:04:15.208314Z",
     "start_time": "2024-06-19T18:04:15.194641Z"
    }
   },
   "outputs": [],
   "source": [
    "def _convert_message_to_dict(message: BaseMessage) -> dict:\n",
    "    if isinstance(message, ChatMessage):\n",
    "        message_dict = {\"role\": message.role, \"content\": message.content}\n",
    "    elif isinstance(message, HumanMessage):\n",
    "        message_dict = {\"role\": \"user\", \"content\": message.content}\n",
    "    elif isinstance(message, AIMessage):\n",
    "        message_dict = {\"role\": \"assistant\", \"content\": message.content}\n",
    "        if \"function_call\" in message.additional_kwargs:\n",
    "            message_dict[\"function_call\"] = message.additional_kwargs[\"function_call\"]\n",
    "    elif isinstance(message, SystemMessage):\n",
    "        message_dict = {\"role\": \"system\", \"content\": message.content}\n",
    "    elif isinstance(message, ToolMessage):\n",
    "        message_dict = {\"role\": \"tool\", \"content\": message.content}\n",
    "    elif isinstance(message, FunctionMessage):\n",
    "        message_dict = {\n",
    "            \"role\": \"function\",\n",
    "            \"content\": message.content,\n",
    "            \"name\": message.name,\n",
    "        }\n",
    "    else:\n",
    "        raise ValueError(f\"Got unknown type {message}\")\n",
    "    if \"name\" in message.additional_kwargs:\n",
    "        message_dict[\"name\"] = message.additional_kwargs[\"name\"]\n",
    "    return message_dict\n",
    "\n",
    "\n",
    "class LiteLLMFunctions(ToolCallingLLM, ChatLiteLLM):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def _create_message_dicts(\n",
    "        self, messages: List[BaseMessage], stop: Optional[List[str]]\n",
    "    ) -> Tuple[List[Dict[str, Any]], Dict[str, Any]]:\n",
    "        params = self._client_params\n",
    "        if stop is not None:\n",
    "            if \"stop\" in params:\n",
    "                raise ValueError(\"`stop` found in both the input and default params.\")\n",
    "            params[\"stop\"] = stop\n",
    "        message_dicts = [_convert_message_to_dict(m) for m in messages]\n",
    "        return message_dicts, params\n",
    "\n",
    "    @property\n",
    "    def _llm_type(self) -> str:\n",
    "        return \"litellm_functions\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec556c837dc249c",
   "metadata": {},
   "source": "### Test with new ToolCallingLLM implementation of ChatLiteLLM"
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "3c198f6c33762483",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T18:04:16.243394Z",
     "start_time": "2024-06-19T18:04:16.239344Z"
    }
   },
   "outputs": [],
   "source": [
    "llm = LiteLLMFunctions(model=model)\n",
    "\n",
    "llm_with_structured_output = llm.with_structured_output(Joke)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2730093566523642",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T18:04:24.899686Z",
     "start_time": "2024-06-19T18:04:17.178379Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Joke(setup='A curious cat named Whiskers decided to investigate every corner of its home.', punchline=\"And found out that the pantry door was a secret portal, but he'd never share his adventures in food-filled universes.\")"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joke = llm_with_structured_output.invoke(\"Tell me a joke about cats\")\n",
    "joke"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8094a74fb0d39f1",
   "metadata": {},
   "source": [
    "## LangGraph Tool Calling Agent with LiteLLM using ToolCallingLLM\n",
    "\n",
    "### Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "4a7c402a89c928ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T18:04:31.373029Z",
     "start_time": "2024-06-19T18:04:29.819430Z"
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install langchain-core==0.2.9 langchain-community==0.2.5 langgraph==0.0.69 duckduckgo-search==6.1.7 httpx==0.27.0 langchain-experimental"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb5af7ff8a79fa1",
   "metadata": {},
   "source": "### Imports"
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "2e44e05405f7e713",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T18:04:31.389363Z",
     "start_time": "2024-06-19T18:04:31.386259Z"
    }
   },
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "from IPython.display import Image, display\n",
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "from langchain_core.messages import AIMessage, BaseMessage, ToolMessage\n",
    "from langchain_core.tools import tool\n",
    "from langchain_experimental.llms.tool_calling_llm import ToolCallingLLM\n",
    "from langgraph.graph import END, MessageGraph\n",
    "from langgraph.prebuilt import ToolNode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cadcd630384d0ea1",
   "metadata": {},
   "source": [
    "### Define custom tools\n",
    "\n",
    "Here we have created 4 custom tools and used an existing tool for our toolset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ac5f8dcc7e6b735f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T18:04:35.081450Z",
     "start_time": "2024-06-19T18:04:35.069604Z"
    }
   },
   "outputs": [],
   "source": [
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Tool to multiply two numbers\"\"\"\n",
    "    return a * b\n",
    "\n",
    "\n",
    "@tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Tool to add two numbers\"\"\"\n",
    "    return a + b\n",
    "\n",
    "\n",
    "@tool\n",
    "def call_miracle(request: str) -> str:\n",
    "    \"\"\"Tool to call miracle\"\"\"\n",
    "    return f\"You asked for {request}, but I can't do that\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def grant_wish(wish: str) -> str:\n",
    "    \"\"\"Tool to grant wish\"\"\"\n",
    "    return f\"You asked for {wish}. Your wish is my command!\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4260845123d9ca",
   "metadata": {},
   "source": [
    "### Create ToolNode\n",
    "\n",
    "We will now create a tool node with the 4 custom tools and duckduckgo-search tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2eb054005c772a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [multiply, add, call_miracle, grant_wish, DuckDuckGoSearchRun(max_results=2)]\n",
    "\n",
    "# tool_node will be used as a node within the LangGraph agent\n",
    "tool_node = ToolNode(tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e557bae7624fc2a8",
   "metadata": {},
   "source": "### Initialize LLM and bind tools"
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "54333d070d5b35ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T18:04:35.674046Z",
     "start_time": "2024-06-19T18:04:35.670911Z"
    }
   },
   "outputs": [],
   "source": [
    "llm = LiteLLMFunctions(model=\"ollama/llama3\")\n",
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2dd1aeb735ede9",
   "metadata": {},
   "source": "### Create a simple LangGraph agent using [MessageGraph](https://python.langchain.com/v0.1/docs/integrations/chat/)"
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "b357e5b3466d7bdc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T18:21:56.707126Z",
     "start_time": "2024-06-19T18:21:56.702055Z"
    }
   },
   "outputs": [],
   "source": [
    "builder = MessageGraph()\n",
    "\n",
    "# define nodes\n",
    "builder.add_node(\"oracle\", llm_with_tools)\n",
    "builder.add_node(\"tools\", tool_node)\n",
    "builder.add_node(\"llm\", llm)\n",
    "\n",
    "# define edges connecting nodes\n",
    "builder.add_edge(\"oracle\", \"tools\")\n",
    "builder.add_edge(\"tools\", \"llm\")\n",
    "builder.add_edge(\"llm\", END)\n",
    "\n",
    "# specify entry point\n",
    "builder.set_entry_point(\"oracle\")\n",
    "\n",
    "# compile the graph\n",
    "graph = builder.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2a681027156744",
   "metadata": {},
   "source": "### Visualizing the graph agent"
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "9404d9be246eb31d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T18:04:37.594712Z",
     "start_time": "2024-06-19T18:04:37.431675Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16546461b5167108",
   "metadata": {},
   "source": "Utility functions to pretty print messages"
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "41ed64bb34625fc7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T18:04:38.500972Z",
     "start_time": "2024-06-19T18:04:38.495568Z"
    }
   },
   "outputs": [],
   "source": [
    "def trim_content(content: str) -> str:\n",
    "    if len(content) < 200:\n",
    "        return content\n",
    "    else:\n",
    "        return content[:200] + \"...\"\n",
    "\n",
    "\n",
    "def pretty_print(message: BaseMessage):\n",
    "    print(f\"type: {message.type}\", end=\"\")\n",
    "    if isinstance(message, AIMessage) and message.tool_calls:\n",
    "        print(f\", tool_calls: {message.tool_calls}\", end=\"\")\n",
    "    elif isinstance(message, ToolMessage):\n",
    "        print(f\", name: {message.name}\", end=\"\")\n",
    "    if message.content:\n",
    "        print(f\", content: {trim_content(message.content)}\", end=\"\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "\n",
    "def pretty_print_messages(messages: List[BaseMessage]):\n",
    "    [pretty_print(message) for message in messages]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f79856da0794af",
   "metadata": {},
   "source": "### Running the Agent"
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "372c6d8e9175f682",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T18:04:56.758840Z",
     "start_time": "2024-06-19T18:04:39.576412Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type: human, content: What is the sum of 2 and 3?\n",
      "\n",
      "type: ai, tool_calls: [{'name': 'add', 'args': {'a': 2, 'b': 3}, 'id': 'call_b972e47464ab4f098ff4c9ff502f4942'}]\n",
      "\n",
      "type: tool, name: add, content: 5\n",
      "\n",
      "type: ai, content: The sum of 2 and 3 is 5.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = graph.invoke((\"human\", \"What is the sum of 2 and 3?\"))\n",
    "pretty_print_messages(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "8b85346634cb2cea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T18:05:12.067261Z",
     "start_time": "2024-06-19T18:05:01.892142Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type: human, content: What is 523 x 412?\n",
      "\n",
      "type: ai, tool_calls: [{'name': 'multiply', 'args': {'a': 523, 'b': 412}, 'id': 'call_f799bdb5c5384a6daf5a6ce2fa22accc'}]\n",
      "\n",
      "type: tool, name: multiply, content: 215476\n",
      "\n",
      "type: ai, content: The product of 523 and 412 is 215476.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = graph.invoke((\"human\", \"What is 523 x 412?\"))\n",
    "pretty_print_messages(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c96980993d944ecc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T18:05:51.836522Z",
     "start_time": "2024-06-19T18:05:38.079419Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type: human, content: I need a miracle. I need it to rain tomorrow.\n",
      "\n",
      "type: ai, tool_calls: [{'name': 'call_miracle', 'args': {'request': 'Rain in the sky'}, 'id': 'call_926c92211959420b8977ff6415c4b123'}]\n",
      "\n",
      "type: tool, name: call_miracle, content: You asked for Rain in the sky, but I can't do that\n",
      "\n",
      "type: ai, content: I understand your desire for a miracle! While I can't control the weather, I can offer some words of encouragement. As they say, 'rain or shine,' and sometimes we just have to appreciate the little th...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = graph.invoke((\"human\", \"I need a miracle. I need it to rain tomorrow.\"))\n",
    "pretty_print_messages(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "327e4d3866e191c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T18:06:15.174383Z",
     "start_time": "2024-06-19T18:06:00.287048Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type: human, content: I wish for world peace.\n",
      "\n",
      "type: ai, tool_calls: [{'name': 'grant_wish', 'args': {'wish': 'I wish for world peace'}, 'id': 'call_49d5d48dfbf54801b33944bb5afd49ae'}]\n",
      "\n",
      "type: tool, name: grant_wish, content: You asked for I wish for world peace. Your wish is my command!\n",
      "\n",
      "type: ai, content: Ahahaha, your wish is indeed a beautiful one! May it come to pass that all nations and cultures harmonize in perfect understanding and mutual respect. A world at peace is a wonderful thing!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = graph.invoke((\"human\", \"I wish for world peace.\"))\n",
    "pretty_print_messages(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e9ff2415f265d8c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T18:06:40.004250Z",
     "start_time": "2024-06-19T18:06:18.784356Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type: human, content: What is tomorrows weather in Austin, TX?\n",
      "\n",
      "type: ai, tool_calls: [{'name': 'duckduckgo_search', 'args': {'query': \"tomorrow's weather in Austin, TX\"}, 'id': 'call_5edb6da891b64484b95ff8ce2d66f41e'}]\n",
      "\n",
      "type: tool, name: duckduckgo_search, content: Austin, TX Weather - Tomorrow's Forecast. Sunday. Mostly sunny. High: 96°F. Mostly sunny, with a high near 96. Heat index values as high as 102. ... Current Texas Weather. Amarillo: Overcast 50°F; Aus...\n",
      "\n",
      "type: ai, content: Tomorrow's weather in Austin, TX is expected to be mostly sunny with a high near 96°F and a heat index as high as 102. There is also a Level 1 risk of isolated tornadoes during the day on Wednesday.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = graph.invoke((\"human\", \"What is tomorrows weather in Austin, TX?\"))\n",
    "pretty_print_messages(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
