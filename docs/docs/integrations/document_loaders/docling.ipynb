{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Docling Loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "> [Docling](https://github.com/DS4SD/docling) parses PDF, DOCX, PPTX, HTML, and other formats into a rich unified representation including document layout, tables etc., making them ready for generative AI workflows like RAG.\n",
    ">\n",
    "> Docling Loader, presented in this notebook, seamlessly integrates Docling into LangChain, enabling you to:\n",
    "> - use various document types in your LLM applications with ease and speed, and\n",
    "> - leverage Docling's rich representation for advanced, document-native grounding.\n",
    ">\n",
    "> In the sections below, we showcase Docling Loader's usage, covering document loading specifics but also demonstrating an end-to-end RAG pipeline.\n",
    "\n",
    "This notebook provides a quick overview for getting started with Docling [document loader](https://python.langchain.com/docs/concepts/#document-loaders). For detailed documentation of all Docling Loader features and configurations head to the [API reference](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.docling.DoclingLoader.html).\n",
    "\n",
    "### Integration details\n",
    "\n",
    "| Class | Package | Local | Serializable | [JS support](https://js.langchain.com/docs/integrations/document_loaders/web_loaders/__module_name___loader)|\n",
    "| :--- | :--- | :---: | :---: |  :---: |\n",
    "| [DoclingLoader](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.docling.DoclingLoader.html) | [langchain_community](https://python.langchain.com/api_reference/community/index.html) | ✅ | ❌ | ❌ | \n",
    "### Loader features\n",
    "| Source | Document Lazy Loading | Native Async Support\n",
    "| :---: | :---: | :---: | \n",
    "| DoclingLoader | ✅ | ❌ | "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use the Docling document loader you will need to have `docling` installed besides `langchain-community`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qU docling langchain-community"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization\n",
    "\n",
    "Now we can instantiate our loader and load documents.\n",
    "\n",
    "By default, `DoclingLoader` loads each input document as a LangChain `Document` with Markdown content (more options can be found in the \"Deep Dive\" section further below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import DoclingLoader\n",
    "\n",
    "FILE_PATH = \"https://arxiv.org/pdf/2408.09869\"\n",
    "\n",
    "loader = DoclingLoader(file_path=FILE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "docs[0].page_content[:200]='## Docling Technical Report\\n\\nVersion 1.0\\n\\nChristoph Auer Maksym Lysak Ahmed Nassar Michele Dolfi Nikolaos Livathinos Panos Vagenas Cesar Berrospi Ramis Matteo Omenetti Fabian Lindlbauer Kasper Dinkla '\n"
     ]
    }
   ],
   "source": [
    "docs = loader.load()\n",
    "print(f\"{docs[0].page_content[:200]=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'source': 'https://arxiv.org/pdf/2408.09869'}\n"
     ]
    }
   ],
   "source": [
    "print(docs[0].metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lazy Load\n",
    "\n",
    "Documents can also be loaded in a lazy fashion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_iter = loader.lazy_load()\n",
    "for doc in doc_iter:\n",
    "    pass  # you can operate on `doc` here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Dive\n",
    "\n",
    "### Initialization\n",
    "\n",
    "The general syntax of `DoclingLoader` initialization is as follows (also see [API reference](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.docling.DoclingLoader.html)):\n",
    "\n",
    "```python\n",
    "loader = DoclingLoader(\n",
    "    file_path=FILE_PATH,\n",
    "    ### OPTIONAL PARAMS: ###\n",
    "    converter=...,  # any specific Docling converter to use\n",
    "    convert_kwargs=...,  # any specific kwargs for conversion execution\n",
    "    export_type=...,  # export mode: Markdown (default) or doc-chunks\n",
    "    md_export_kwargs=...,  # any specific Markdown export kwargs (for Markdown mode)\n",
    "    chunker=...,  # any specific Docling chunker to use (for doc-chunk mode)\n",
    ")\n",
    "```\n",
    "\n",
    "`DoclingLoader` can be instantiated in two different modes:\n",
    "\n",
    "- **Markdown** mode: for each input doc, outputs a LangChain Document with the Markdown representation of the input doc. This is the default mode, implicitly used in the steps above.\n",
    "- **Doc-chunks** mode: for each input doc, outputs the doc chunks as per the chunker (by default using Docling layout-aware chunking) as LangChain Documents.\n",
    "\n",
    "In the subsections below we explore both modes in more detail.\n",
    "\n",
    "### Document preparation using Markdown mode\n",
    "\n",
    "Following up on the steps further above, given that the `docs` have been loaded, any built-in (or custom) LangChain splitter can be used to split them. For example, below we show a possible splitting with a `MarkdownHeaderTextSplitter`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qU langchain-text-splitters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d.metadata={'Header_2': 'Docling Technical Report'}, d.page_content='Version 1.0  \\nChristoph Auer Maksym Lysak Ahmed Nassar Michele Dolfi Nikolaos Livathinos Panos Vagenas Cesar Berrospi Ramis Matteo Omenetti Fabian Lindlbauer Kasper Dinkla Lokesh Mishra Yusik Kim Shubham Gupta Rafael Teixeira de Lima Valery Weber Lucas Morin Ingmar Meijer Viktor Kuropiatnyk Peter W. J. Staar  \\nAI4K Group, IBM Research Ruschlikon, Switzerland'\n",
      "d.metadata={'Header_2': 'Abstract'}, d.page_content='This technical report introduces Docling , an easy to use, self-contained, MITlicensed open-source package for PDF document conversion. It is powered by state-of-the-art specialized AI models for layout analysis (DocLayNet) and table structure recognition (TableFormer), and runs efficiently on commodity hardware in a small resource budget. The code interface allows for easy extensibility and addition of new features and models.'\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import MarkdownHeaderTextSplitter\n",
    "\n",
    "splitter = MarkdownHeaderTextSplitter(\n",
    "    headers_to_split_on=[(\"#\", \"Header_1\"), (\"##\", \"Header_2\"), (\"###\", \"Header_3\")],\n",
    ")\n",
    "md_splits = [split for doc in docs for split in splitter.split_text(doc.page_content)]\n",
    "\n",
    "for d in md_splits[:2]:\n",
    "    print(f\"{d.metadata=}, {d.page_content=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document preparation using doc chunks mode\n",
    "\n",
    "The doc-chunks mode directly returns the document chunks including rich metadata such as the page number and the bounding box info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d.metadata={'source': 'https://arxiv.org/pdf/2408.09869', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/0', 'parent': {'$ref': '#/body'}, 'children': [], 'label': 'page_header', 'prov': [{'page_no': 1, 'bbox': {'l': 17.088111877441406, 't': 583.2296752929688, 'r': 36.339778900146484, 'b': 231.99996948242188, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 38]}]}], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 14981478401387673002, 'filename': '2408.09869v3.pdf'}}}, d.page_content='arXiv:2408.09869v3 [cs.CL] 30 Aug 2024'\n",
      "d.metadata={'source': 'https://arxiv.org/pdf/2408.09869', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/2', 'parent': {'$ref': '#/body'}, 'children': [], 'label': 'text', 'prov': [{'page_no': 1, 'bbox': {'l': 282.772216796875, 't': 512.7218017578125, 'r': 328.8624572753906, 'b': 503.340087890625, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 11]}]}], 'headings': ['Docling Technical Report'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 14981478401387673002, 'filename': '2408.09869v3.pdf'}}}, d.page_content='Version 1.0'\n"
     ]
    }
   ],
   "source": [
    "loader = DoclingLoader(\n",
    "    file_path=FILE_PATH,\n",
    "    export_type=DoclingLoader.ExportType.DOC_CHUNKS,\n",
    ")\n",
    "doc_splits = loader.load()\n",
    "\n",
    "for d in doc_splits[:2]:\n",
    "    print(f\"{d.metadata=}, {d.page_content=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAG example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we put together a demo RAG pipeline and run it using the documents loaded above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qU langchain langchain-huggingface langchain-milvus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "from tempfile import mkdtemp\n",
    "\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_huggingface import HuggingFaceEndpoint\n",
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_milvus import Milvus\n",
    "\n",
    "# https://github.com/huggingface/transformers/issues/5486:\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "QUESTION = \"Which are the main AI models in Docling?\"\n",
    "PROMPT = PromptTemplate.from_template(\n",
    "    \"Context information is below.\\n---------------------\\n{context}\\n---------------------\\nGiven the context information and not prior knowledge, answer the query.\\nQuery: {input}\\nAnswer:\\n\",\n",
    ")\n",
    "HF_EMBED_MODEL_ID = \"BAAI/bge-small-en-v1.5\"\n",
    "HF_LLM_MODEL_ID = \"mistralai/Mixtral-8x7B-Instruct-v0.1\"\n",
    "\n",
    "embedding = HuggingFaceEmbeddings(model_name=HF_EMBED_MODEL_ID)\n",
    "llm = HuggingFaceEndpoint(repo_id=HF_LLM_MODEL_ID)\n",
    "\n",
    "\n",
    "def run_rag(documents, embedding, llm, question, prompt):\n",
    "    def clip_text(text, threshold=100):\n",
    "        return f\"{text[:threshold]}[...]\" if len(text) > threshold else text\n",
    "\n",
    "    milvus_uri = str(Path(mkdtemp()) / \"docling.db\")  # or set as needed\n",
    "    vectorstore = Milvus.from_documents(\n",
    "        documents,\n",
    "        embedding,\n",
    "        connection_args={\"uri\": milvus_uri},\n",
    "        drop_old=True,\n",
    "    )\n",
    "    retriever = vectorstore.as_retriever()\n",
    "    question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
    "    rag_chain = create_retrieval_chain(retriever, question_answer_chain)\n",
    "    resp_dict = rag_chain.invoke({\"input\": question})\n",
    "\n",
    "    answer = clip_text(resp_dict[\"answer\"], threshold=200)\n",
    "    print(f\"Question:\\n{resp_dict['input']}\\n\\nAnswer:\\n{json.dumps(answer)}\")\n",
    "    for i, doc in enumerate(resp_dict[\"context\"]):\n",
    "        print()\n",
    "        print(f\"Source {i+1}:\")\n",
    "        print(f\"  text: {json.dumps(clip_text(doc.page_content, threshold=200))}\")\n",
    "        for key in doc.metadata:\n",
    "            if key != \"pk\":\n",
    "                val = doc.metadata.get(key)\n",
    "                clipped_val = clip_text(val) if isinstance(val, str) else val\n",
    "                print(f\"  {key}: {clipped_val}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RAG using Markdown mode\n",
    "\n",
    "Below we run the RAG pipeline passing it the output of the Markdown mode (after splitting):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:\n",
      "Which are the main AI models in Docling?\n",
      "\n",
      "Answer:\n",
      "\"The main AI models in Docling are DocLayNet and TableFormer. DocLayNet is a layout analysis model that is an accurate object-detector for page elements, and TableFormer is a state-of-the-art table str[...]\"\n",
      "\n",
      "Source 1:\n",
      "  text: \"As part of Docling, we initially release two highly capable AI models to the open-source community, which have been developed and published recently by our team. The first model is a layout analysis m[...]\"\n",
      "  Header_2: 3.2 AI models\n",
      "\n",
      "Source 2:\n",
      "  text: \"This technical report introduces Docling , an easy to use, self-contained, MITlicensed open-source package for PDF document conversion. It is powered by state-of-the-art specialized AI models for layo[...]\"\n",
      "  Header_2: Abstract\n",
      "\n",
      "Source 3:\n",
      "  text: \"Thanks to the high-quality, richly structured document conversion achieved by Docling, its output qualifies for numerous downstream applications. For example, Docling can provide a base for detailed e[...]\"\n",
      "  Header_2: 5 Applications\n",
      "\n",
      "Source 4:\n",
      "  text: \"Docling is designed to allow easy extension of the model library and pipelines. In the future, we plan to extend Docling with several more models, such as a figure-classifier model, an equationrecogni[...]\"\n",
      "  Header_2: 6 Future work and contributions\n"
     ]
    }
   ],
   "source": [
    "run_rag(\n",
    "    documents=md_splits,\n",
    "    embedding=embedding,\n",
    "    llm=llm,\n",
    "    question=QUESTION,\n",
    "    prompt=PROMPT,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RAG using doc-chunk mode\n",
    "\n",
    "Below we run the RAG pipeline passing it the output of the doc-chunk mode.\n",
    "\n",
    "Notice how the sources now also contain document-level grounding (e.g. page number or bounding box information):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:\n",
      "Which are the main AI models in Docling?\n",
      "\n",
      "Answer:\n",
      "\"The main AI models in Docling are a layout analysis model, an accurate object-detector for page elements, and TableFormer, a state-of-the-art table structure recognition model. These models are develo[...]\"\n",
      "\n",
      "Source 1:\n",
      "  text: \"As part of Docling, we initially release two highly capable AI models to the open-source community, which have been developed and published recently by our team. The first model is a layout analysis m[...]\"\n",
      "  dl_meta: {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/34', 'parent': {'$ref': '#/body'}, 'children': [], 'label': 'text', 'prov': [{'page_no': 3, 'bbox': {'l': 107.07593536376953, 't': 406.1695251464844, 'r': 504.1148681640625, 'b': 330.2677307128906, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 608]}]}], 'headings': ['3.2 AI models'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 14981478401387673002, 'filename': '2408.09869v3.pdf'}}\n",
      "  source: https://arxiv.org/pdf/2408.09869\n",
      "\n",
      "Source 2:\n",
      "  text: \"With Docling , we open-source a very capable and efficient document conversion tool which builds on the powerful, specialized AI models and datasets for layout analysis and table structure recognition[...]\"\n",
      "  dl_meta: {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/9', 'parent': {'$ref': '#/body'}, 'children': [], 'label': 'text', 'prov': [{'page_no': 1, 'bbox': {'l': 107.0031967163086, 't': 136.7283935546875, 'r': 504.04998779296875, 'b': 83.30133056640625, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 488]}]}], 'headings': ['1 Introduction'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 14981478401387673002, 'filename': '2408.09869v3.pdf'}}\n",
      "  source: https://arxiv.org/pdf/2408.09869\n",
      "\n",
      "Source 3:\n",
      "  text: \"Docling is designed to allow easy extension of the model library and pipelines. In the future, we plan to extend Docling with several more models, such as a figure-classifier model, an equationrecogni[...]\"\n",
      "  dl_meta: {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/60', 'parent': {'$ref': '#/body'}, 'children': [], 'label': 'text', 'prov': [{'page_no': 5, 'bbox': {'l': 106.92281341552734, 't': 323.5386657714844, 'r': 504.00347900390625, 'b': 258.76641845703125, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 543]}]}], 'headings': ['6 Future work and contributions'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 14981478401387673002, 'filename': '2408.09869v3.pdf'}}\n",
      "  source: https://arxiv.org/pdf/2408.09869\n",
      "\n",
      "Source 4:\n",
      "  text: \"This technical report introduces Docling , an easy to use, self-contained, MITlicensed open-source package for PDF document conversion. It is powered by state-of-the-art specialized AI models for layo[...]\"\n",
      "  dl_meta: {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/6', 'parent': {'$ref': '#/body'}, 'children': [], 'label': 'text', 'prov': [{'page_no': 1, 'bbox': {'l': 142.92593383789062, 't': 364.814697265625, 'r': 468.3847351074219, 'b': 300.651123046875, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 431]}]}], 'headings': ['Abstract'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 14981478401387673002, 'filename': '2408.09869v3.pdf'}}\n",
      "  source: https://arxiv.org/pdf/2408.09869\n"
     ]
    }
   ],
   "source": [
    "run_rag(\n",
    "    documents=doc_splits,\n",
    "    embedding=embedding,\n",
    "    llm=llm,\n",
    "    question=QUESTION,\n",
    "    prompt=PROMPT,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API reference\n",
    "\n",
    "For detailed documentation of all `DoclingLoader` features and configurations head to the [API reference](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.docling.DoclingLoader.html)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
