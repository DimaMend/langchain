{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c47d7c4",
   "metadata": {},
   "source": [
    "# RWKV\n",
    "\n",
    ">[RWKV](https://www.rwkv.com/) (pronounced RwaKuv) language model is an RNN \n",
    "> with GPT-level LLM performance, \n",
    "> and it can also be directly trained like a GPT transformer (parallelizable).\n",
    "\n",
    "## Overview\n",
    "\n",
    "RWKV is combining the best of RNN and transformer - great performance, fast inference, \n",
    "fast training, saves VRAM, \"infinite\" ctxlen, and free text embedding. \n",
    "Moreover, it's 100% attention-free, and a LFAI project.\n",
    "\n",
    "### Rwkv models recommended VRAM\n",
    "\n",
    "| Model | 8bit | bf16/fp16 | fp32 |\n",
    "|-------|------|-----------|------|\n",
    "| 14B   | 16GB | 28GB      | >50GB |\n",
    "| 7B    | 8GB  | 14GB      | 28GB |\n",
    "| 3B    | 2.8GB| 6GB       | 12GB |\n",
    "| 1b5   | 1.3GB| 3GB       | 6GB |\n",
    "\n",
    "See the [rwkv pip](https://pypi.org/project/rwkv/) page for more information about strategies, \n",
    "including streaming and CUDA support.\n",
    "\n",
    "## Setup\n",
    "\n",
    "- Install the Python `rwkv` and `tokenizer` packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57081891",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install rwkv tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be7a218",
   "metadata": {},
   "source": [
    "- Download a [RWKV model](https://huggingface.co/BlinkDL/rwkv-4-raven/tree/main) and place it in your desired directory\n",
    "- Download a [tokens file](https://raw.githubusercontent.com/BlinkDL/ChatRWKV/main/20B_tokenizer.json)\n",
    "\n",
    "## Instantiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d32186",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import RWKV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f629ee2",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "To use the RWKV wrapper, you need to provide the path to the pre-trained model file and the tokenizer's configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad21947",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RWKV(\n",
    "    model=\"./models/RWKV-4-Raven-3B-v7-Eng-20230404-ctx4096.pth\",\n",
    "    strategy=\"cpu fp32\",\n",
    "    tokens_path=\"./rwkv/20B_tokenizer.json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3538ec3e",
   "metadata": {},
   "source": [
    "## Invocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27003f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt(instruction, input=None):\n",
    "    if input:\n",
    "        return f\"\"\"Below is an instruction that describes a task, paired with an input that provides\n",
    "further context. Write a response that appropriately completes the request.\n",
    "\n",
    "# Instruction:\n",
    "{instruction}\n",
    "\n",
    "# Input:\n",
    "{input}\n",
    "\n",
    "# Response:\n",
    "\"\"\"\n",
    "    else:\n",
    "        return f\"\"\"Below is an instruction that describes a task. Write a response that \n",
    "appropriately completes the request.\n",
    "\n",
    "# Instruction:\n",
    "{instruction}\n",
    "\n",
    "# Response:\n",
    "\"\"\"\n",
    "\n",
    "response = model.invoke(generate_prompt(\"Once upon a time, \"))"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
