{
 "cells": [
  {
   "cell_type": "raw",
   "id": "10238e62-3465-4973-9279-606cbb7ccf16",
   "metadata": {},
   "source": [
    "---\n",
    "sidebar_label: FMPData\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f91f20",
   "metadata": {},
   "source": [
    "## Overview\n",
    "The FMP (Financial Modeling Prep) LangChain integration provides a seamless way to access financial market data through natural language queries. This integration offers two main components:\n",
    "\n",
    "- FMPDataToolkit: Creates collections of tools based on natural language queries\n",
    "- FMPDataTool: A single unified tool that automatically selects and uses the appropriate endpoints\n",
    "\n",
    "The integration leverages LangChain's semantic search capabilities to match user queries with the most relevant FMP API endpoints, making financial data access more intuitive and efficient.\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85b4089",
   "metadata": {},
   "outputs": [],
   "source": "!pip install -U langchain-fmp-data"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0b178a2-8816-40ca-b57c-ccdd86dde9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Replace with your actual API keys\n",
    "os.environ[\"FMP_API_KEY\"] = \"your-fmp-api-key\"  # pragma: allowlist secret\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"your-openai-api-key\"  # pragma: allowlist secret"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5ab717-fd27-4c59-b912-bdd099541478",
   "metadata": {},
   "source": [
    "It's also helpful (but not needed) to set up [LangSmith](https://smith.langchain.com/) for best-in-class observability:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6c2f136-6367-4f1f-825d-ae741e1bf281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "# os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass()"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Instantiation\n",
    "There are two main ways to instantiate the FMP LangChain integration:\n",
    "1. Using FMPDataToolkit"
   ],
   "id": "b15e9266"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from langchain_fmp_data import FMPDataToolkit\n",
    "\n",
    "query = \"Get stock market prices and technical indicators\"\n",
    "# Basic instantiation\n",
    "toolkit = FMPDataToolkit(query=query)\n",
    "\n",
    "# Instantiation with specific query focus\n",
    "market_toolkit = FMPDataToolkit(\n",
    "    query=query,\n",
    "    num_results=5,\n",
    ")\n",
    "\n",
    "# Instantiation with custom configuration\n",
    "custom_toolkit = FMPDataToolkit(\n",
    "    query=\"Financial analysis\",\n",
    "    num_results=3,\n",
    "    similarity_threshold=0.4,\n",
    "    cache_dir=\"/custom/cache/path\",\n",
    ")"
   ],
   "id": "615375140978a557"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "2. Using FMPDataTool\n",
   "id": "fd72621083777e68"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": 4,
   "source": [
    "from langchain_fmp_data import FMPDataTool\n",
    "from langchain_fmp_data.tools import ResponseFormat\n",
    "\n",
    "# Basic instantiation\n",
    "tool = FMPDataTool()\n",
    "\n",
    "# Advanced instantiation with custom settings\n",
    "advanced_tool = FMPDataTool(\n",
    "    max_iterations=50,\n",
    "    temperature=0.2,\n",
    ")"
   ],
   "id": "8b3ddfe9-ca79-494c-a7ab-1f56d9407a64"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Invocation\n",
    "The tools can be invoked in several ways:\n",
    "\n",
    "### Direct Invocation\n",
    "\n"
   ],
   "id": "74147a1a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65310a8b-eb0c-4d9e-a618-4f4abe2414fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using FMPDataTool\n",
    "tool_direct = FMPDataTool()\n",
    "\n",
    "# Basic query\n",
    "# fmt: off\n",
    "result = tool.invoke({\"query\": \"What's Apple's current stock price?\"})\n",
    "# fmt: on\n",
    "\n",
    "# Advanced query with specific format\n",
    "# fmt: off\n",
    "detailed_result = tool_direct.invoke(\n",
    "    {\n",
    "        \"query\": \"Compare Tesla and Ford's profit margins\",\n",
    "        \"response_format\": ResponseFormat.BOTH,\n",
    "    }\n",
    ")\n",
    "# fmt: on"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e73897",
   "metadata": {},
   "source": "### Using with LangChain Agents"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90e33a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import create_openai_functions_agent, AgentExecutor\n",
    "\n",
    "# Setup\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "toolkit = FMPDataToolkit(\n",
    "    query=\"Stock analysis\",\n",
    "    num_results=3,\n",
    ")\n",
    "tools = toolkit.get_tools()\n",
    "\n",
    "# Create agent\n",
    "prompt = \"You are a helpful assistant. Answer the user's questions based on the provided context.\"\n",
    "agent = create_openai_functions_agent(llm, tools, prompt)\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=agent,\n",
    "    tools=tools,\n",
    ")\n",
    "\n",
    "# Run query\n",
    "# fmt: off\n",
    "response = agent_executor.invoke({\"input\": \"What's the PE ratio of Microsoft?\"})\n",
    "# fmt: on"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659f9fbd-6fcf-445f-aa8c-72d8e60154bd",
   "metadata": {},
   "source": [
    "## Advanced Usage\n",
    "You can customize the tool's behavior:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "af3123ad-7a02-40e5-b58e-7d56e23e5830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize with custom settings\n",
    "advanced_tool = FMPDataTool(\n",
    "    max_iterations=50,  # Increase max iterations for complex queries\n",
    "    temperature=0.2,  # Adjust temperature for more/less focused responses\n",
    ")\n",
    "\n",
    "# Example of a complex multi-part analysis\n",
    "query = \"\"\"\n",
    "Analyze Apple's financial health by:\n",
    "1. Examining current ratios and debt levels\n",
    "2. Comparing profit margins to industry average\n",
    "3. Looking at cash flow trends\n",
    "4. Assessing growth metrics\n",
    "\"\"\"\n",
    "# fmt: off\n",
    "response = advanced_tool.invoke(\n",
    "    {\n",
    "        \"query\": query,\n",
    "        \"response_format\": ResponseFormat.BOTH}\n",
    ")\n",
    "# fmt: on\n",
    "print(\"Detailed Financial Analysis:\")\n",
    "print(response)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Chaining\n",
    "You can chain the tool similar to other tools simply by creating a chain with desired model."
   ],
   "id": "108f0b09131bb34"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Setup\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "toolkit = FMPDataToolkit(query=\"Stock analysis\", num_results=3)\n",
    "tools = toolkit.get_tools()\n",
    "\n",
    "llm_with_tools = llm.bind(functions=tools)\n",
    "output_parser = StrOutputParser()\n",
    "# Create chain\n",
    "runner = llm_with_tools | output_parser\n",
    "\n",
    "# Run chain\n",
    "# fmt: off\n",
    "response = runner.invoke(\n",
    "    {\n",
    "        \"input\": \"What's the PE ratio of Microsoft?\"\n",
    "    }\n",
    ")\n",
    "# fmt: on"
   ],
   "id": "13b6dfa2ca91c712"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## API reference\n",
    "\n",
    "### FMPDataToolkit\n",
    "Main class for creating collections of FMP API tools:\n",
    "\n"
   ],
   "id": "9b9dc04b8a68e94c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from typing import Any\n",
    "from langchain.tools import Tool\n",
    "\n",
    "\n",
    "class FMPDataToolkit:\n",
    "    \"\"\"Creates a collection of FMP data tools based on queries.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            query: str | None = None,\n",
    "            num_results: int = 3,\n",
    "            similarity_threshold: float = 0.3,\n",
    "            cache_dir: str | None = None,\n",
    "    ): ...\n",
    "\n",
    "    def get_tools(self) -> list[Tool]:\n",
    "        \"\"\"Returns a list of relevant FMP API tools based on the query.\"\"\"\n",
    "        ..."
   ],
   "id": "4b6604b7cf72c1a0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### FMPDataTool\n",
    "Unified tool that automatically selects appropriate FMP endpoints:\n"
   ],
   "id": "7524eb1099d5e7e7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class FMPDataTool:\n",
    "    \"\"\"Single unified tool for accessing FMP data through natural language.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            max_iterations: int = 3,\n",
    "            temperature: float = 0.0,\n",
    "    ): ...\n",
    "\n",
    "    def invoke(\n",
    "            self,\n",
    "            input: dict[str, Any],\n",
    "    ) -> str | dict[str, Any]:\n",
    "        \"\"\"Execute a natural language query against FMP API.\"\"\"\n",
    "        ..."
   ],
   "id": "aec521045bd34060"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### ResponseFormat\n",
    "Enum for controlling response format:\n"
   ],
   "id": "1807550e3c40e3e8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from enum import Enum\n",
    "\n",
    "\n",
    "class ResponseFormat(str, Enum):\n",
    "    RAW = \"raw\"  # Raw API response\n",
    "    ANALYSIS = \"text\"  # Natural language analysis\n",
    "    BOTH = \"both\"  # Both raw data and analysis"
   ],
   "id": "fa7c1c255f0820c2"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "poetry-venv-311",
   "language": "python",
   "name": "poetry-venv-311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
