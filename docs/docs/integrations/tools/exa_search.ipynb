{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4x4kQ0VcodAC"
   },
   "source": [
    "# Exa Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V1x8wEUhodAH"
   },
   "source": [
    "Exa is a search engine fully designed for use by LLMs. Search for documents on the internet using **natural language queries**, then retrieve **cleaned HTML content** from desired documents.\n",
    "\n",
    "Unlike keyword-based search (Google), Exa's neural search capabilities allow it to semantically understand queries and return relevant documents. For example, we could search `\"fascinating article about cats\"` and compare the search results from [Google](https://www.google.com/search?q=fascinating+article+about+cats) and [Exa](https://search.exa.ai/search?q=fascinating%20article%20about%20cats&autopromptString=Here%20is%20a%20fascinating%20article%20about%20cats%3A). Google gives us SEO-optimized listicles based on the keyword \"fascinating\". Exa just works.\n",
    "\n",
    "This notebook goes over how to use Exa Search with LangChain.\n",
    "\n",
    "First, get an Exa API key and add it as an environment variable. Get $10 free credit (plus more by completing certain actions like making your first search) by [signing up here](https://dashboard.exa.ai/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "7GON_jdvodAI"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "api_key=os.getenv(\"EXA_API_KEY\") #Set your API key as an environment variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And install the integration package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade --quiet langchain-exa \n",
    "\n",
    "# and some deps for this notebook\n",
    "%pip install --upgrade --quiet langchain langchain-openai langchain-community"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using ExaSearchRetriever\n",
    "\n",
    "ExaSearchRetriever is a retriever that uses Exa Search to retrieve relevant documents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{.callout-note}\n",
    "\n",
    "The `max_characters` parameter for **TextContentsOptions** used to be called `max_length` which is now deprecated. Make sure to use `max_characters` instead.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ip5_D9MkodAK"
   },
   "source": [
    "## Using the Exa SDK as LangChain Agent Tools\n",
    "\n",
    "The [Exa SDK](https://docs.exa.ai/) creates a client that can interact with three main Exa API endpoints:\n",
    "\n",
    "- `search`: Given a natural language search query, retrieve a list of search results.\n",
    "- `find_similar`: Given a URL, retrieve a list of search results corresponding to webpages which are similar to the document at the provided URL.\n",
    "- `get_contents`: Given a list of document ids fetched from `search` or `find_similar`, get cleaned HTML content for each document.\n",
    "\n",
    "The `exa_py` SDK combines these endpoints into two powerful calls. Using these provide the most flexible and efficient use cases of Exa search:\n",
    "\n",
    "1. `search_and_contents`: Combines the `search` and `get_contents` endpoints to retrieve search results along with their content in a single operation.\n",
    "2. `find_similar_and_contents`: Combines the `find_similar` and `get_contents` endpoints to find similar pages and retrieve their content in one call.\n",
    "\n",
    "We can use the `@tool` decorator and docstrings to create LangChain Tool wrappers that tell an LLM agent how to use these combined Exa functionalities effectively. This approach simplifies usage and reduces the number of API calls needed to get comprehensive results.\n",
    "\n",
    "Before writing code, ensure you have `langchain-exa` installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0CsJFtuFodAK"
   },
   "outputs": [],
   "source": [
    "%pip install --upgrade --quiet  langchain-exa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "XatXTApdodAM"
   },
   "outputs": [],
   "source": [
    "from exa_py import Exa\n",
    "from langchain_core.tools import tool\n",
    "import os\n",
    "\n",
    "exa = Exa(api_key=os.environ[\"EXA_API_KEY\"])\n",
    "\n",
    "@tool\n",
    "def search_and_contents(query: str):\n",
    "    \"\"\"Search for webpages based on the query and retrieve their contents.\"\"\"\n",
    "    # This combines two API endpoints: search and contents retrieval\n",
    "    return exa.search_and_contents(\n",
    "        query,\n",
    "        use_autoprompt=True,\n",
    "        num_results=5,\n",
    "        text=True,\n",
    "        highlights=True\n",
    "    )\n",
    "\n",
    "@tool\n",
    "def find_similar_and_contents(url: str):\n",
    "    \"\"\"Search for webpages similar to a given URL and retrieve their contents.\n",
    "    The url passed in should be a URL returned from `search_and_contents`.\n",
    "    \"\"\"\n",
    "    # This combines two API endpoints: find similar and contents retrieval\n",
    "    return exa.find_similar_and_contents(\n",
    "        url,\n",
    "        num_results=5,\n",
    "        text=True,\n",
    "        highlights=True\n",
    "    )\n",
    "\n",
    "tools = [search_and_contents, find_similar_and_contents]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sVe2ca9OodAO"
   },
   "source": [
    "### Providing Exa Tools to an Agent\n",
    "\n",
    "We can provide the Exa tools we just created to a LangChain `OpenAIFunctionsAgent`. When asked to `Summarize for me a fascinating article about cats`, the agent uses the `search` tool to perform a Exa search with an appropriate search query, uses the `get_contents` tool to perform Exa content retrieval, and then returns a summary of the retrieved content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x72pY95WodAP"
   },
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor, OpenAIFunctionsAgent\n",
    "from langchain_core.messages import SystemMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "\n",
    "system_message = SystemMessage(\n",
    "    content=\"You are a web researcher who answers user questions by looking up information on the internet and retrieving contents of helpful documents. Cite your sources.\"\n",
    ")\n",
    "\n",
    "agent_prompt = OpenAIFunctionsAgent.create_prompt(system_message)\n",
    "agent = OpenAIFunctionsAgent(llm=llm, tools=tools, prompt=agent_prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "jTku-3OmodAP",
    "outputId": "d587ed66-3b82-4bc8-e8cd-f5278e0c14a6",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": ["\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `search_and_contents` with `{'query': 'fascinating article about cats'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mTitle: The Feline Mystique\n",
      "URL: https://www.mcsweeneys.net/articles/the-feline-mystique\n",
      "ID: https://www.mcsweeneys.net/articles/the-feline-mystique\n",
      "Score: 0.1880224496126175\n",
      "Published Date: 2022-07-19\n",
      "Author: Kathryn Baecht\n",
      "Text: Internet Tendency \n",
      " The Store \n",
      " Books Division \n",
      " Quarterly Concern \n",
      " The Believer \n",
      " Donate \n",
      "McSWEENEY'S INTERNET TENDENCY'S PATREON\n",
      "The problem lay buried for many years in the minds of American cats, like an old desiccated turd in a long-neglected kitty litter box. It was a strange stirring, a sense of dissatisfaction, a yearning. Each suburban cat struggled with it alone. As it rode, humiliated, in its carrier to the vet, as it hacked up furballs onto the bathmat, as it slept on its human’s head at night, bits of Fresh Step falling from its feet directly onto its owner’s face—it was afraid to ask the silent question, “Who will open the cans of wet food if the human dies? [... Output truncated ...]”\n"
    ]
    },
    {
     "data": {
      "text/plain": [
       "'Here is a fascinating article about cats:\\n\\n### The Feline Mystique\\n\\n**Source:** [McSweeney\\'s](https://www.mcsweeneys.net/articles/the-feline-mystique)\\n\\n**Summary:**\\nThe article humorously explores the existential dilemmas faced by American house cats. It delves into the \"house cat\\'s syndrome,\" a term coined to describe the dissatisfaction and yearning for something more than the comforts of domestic life. Despite having on-demand petting, free healthcare, and viral video fame, cats seem to crave freedom and adventure. The piece also touches on the psychological struggles of cats, such as feeling hollow or ashamed after chasing a laser pointer. Ultimately, it suggests that cats desire more than just luxury—they want total world domination, but only after a two-hour nap.\\n\\n**Key Points:**\\n- American house cats experience a sense of dissatisfaction and yearning.\\n- The \"house cat\\'s syndrome\" describes their existential dilemmas.\\n- Despite their luxurious lives, cats crave freedom and adventure.\\n- The article humorously suggests that cats aim for world domination.\\n\\nFor more details, you can read the full article [here](https://www.mcsweeneys.net/articles/the-feline-mystique).'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.run(\"Summarize for me a fascinating article about cats.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e3FHjxT-RoIH"
   },
   "source": [
    "## Advanced Exa Features\n",
    "\n",
    "Exa supports powerful filters by domain and date. We can provide a more powerful `search` tool to the agent that lets it decide to apply filters if they are useful for the objective. See all of Exa's search features [here](https://github.com/metaphorsystems/metaphor-python/).\n",
    "\n",
    "[//]: # \"TODO(erick): switch metaphor github link to exa github link when sdk published\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "fFPl4dUs7F_v"
   },
   "outputs": [],
   "source": [
    "from exa_py import Exa\n",
    "from langchain_core.tools import tool\n",
    "import os\n",
    "\n",
    "exa = Exa(api_key=os.environ[\"EXA_API_KEY\"])\n",
    "\n",
    "@tool\n",
    "def search_and_contents(\n",
    "    query: str,\n",
    "    include_domains: list[str] = None,\n",
    "    exclude_domains: list[str] = None,\n",
    "    start_published_date: str = None,\n",
    "    end_published_date: str = None,\n",
    "    include_text: list[str] = None,\n",
    "    exclude_text: list[str] = None\n",
    "):\n",
    "    \"\"\"\n",
    "    Search for webpages based on the query and retrieve their contents.\n",
    "    \n",
    "    Parameters:\n",
    "    - query (str): The search query.\n",
    "    - include_domains (list[str], optional): Restrict the search to these domains.\n",
    "    - exclude_domains (list[str], optional): Exclude these domains from the search.\n",
    "    - start_published_date (str, optional): Restrict to documents published after this date (YYYY-MM-DD).\n",
    "    - end_published_date (str, optional): Restrict to documents published before this date (YYYY-MM-DD).\n",
    "    - include_text (list[str], optional): Only include results containing these phrases.\n",
    "    - exclude_text (list[str], optional): Exclude results containing these phrases.\n",
    "    \"\"\"\n",
    "    return exa.search_and_contents(\n",
    "        query,\n",
    "        use_autoprompt=True,\n",
    "        num_results=5,\n",
    "        include_domains=include_domains,\n",
    "        exclude_domains=exclude_domains,\n",
    "        start_published_date=start_published_date,\n",
    "        end_published_date=end_published_date,\n",
    "        include_text=include_text,\n",
    "        exclude_text=exclude_text,\n",
    "        text=True,\n",
    "        highlights=True\n",
    "    )\n",
    "\n",
    "@tool\n",
    "def find_similar_and_contents(\n",
    "    url: str,\n",
    "    exclude_source_domain: bool = False,\n",
    "    start_published_date: str = None,\n",
    "    end_published_date: str = None\n",
    "):\n",
    "    \"\"\"\n",
    "    Search for webpages similar to a given URL and retrieve their contents.\n",
    "    The url passed in should be a URL returned from `search_and_contents`.\n",
    "    \n",
    "    Parameters:\n",
    "    - url (str): The URL to find similar pages for.\n",
    "    - exclude_source_domain (bool, optional): If True, exclude pages from the same domain as the source URL.\n",
    "    - start_published_date (str, optional): Restrict to documents published after this date (YYYY-MM-DD).\n",
    "    - end_published_date (str, optional): Restrict to documents published before this date (YYYY-MM-DD).\n",
    "    \"\"\"\n",
    "    return exa.find_similar_and_contents(\n",
    "        url,\n",
    "        num_results=5,\n",
    "        exclude_source_domain=exclude_source_domain,\n",
    "        start_published_date=start_published_date,\n",
    "        end_published_date=end_published_date,\n",
    "        text=True,\n",
    "        highlights={\n",
    "            \"num_sentences\": 1,\n",
    "            \"highlights_per_url\": 1\n",
    "        }\n",
    "    )\n",
    "\n",
    "tools = [search_and_contents, find_similar_and_contents]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BZlScmg1b5Km"
   },
   "source": [
    "Now we ask the agent to summarize an article with constraints on domain and publish date. We will use a GPT-4 agent for extra powerful reasoning capability to support more complex tool usage.\n",
    "\n",
    "The agent correctly uses the search filters to find an article with the desired constraints, and once again retrieves the content and returns a summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "7ns7V9FNTyZM"
   },
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor, OpenAIFunctionsAgent\n",
    "from langchain_core.messages import SystemMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(temperature=0, model=\"gpt-4o\")\n",
    "\n",
    "system_message = SystemMessage(\n",
    "    content=\"You are a web researcher who answers user questions by looking up information on the internet and retrieving contents of helpful documents. Cite your sources.\"\n",
    ")\n",
    "\n",
    "agent_prompt = OpenAIFunctionsAgent.create_prompt(system_message)\n",
    "agent = OpenAIFunctionsAgent(llm=llm, tools=tools, prompt=agent_prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "fmx2GsaIT0eV",
    "outputId": "e0689853-b9b7-4010-ab1d-05aca71f7f5e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": ["\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `search_and_contents` with `{'query': 'AI site:lesswrong.com', 'start_published_date': '2023-10-01'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mTitle: OpenAI, DeepMind, Anthropic, etc. should shut down.\n",
      "URL: https://www.lesswrong.com/posts/8SjnKxjLniCAmcjnG/openai-deepmind-anthropic-etc-should-shut-down\n",
      "ID: https://www.lesswrong.com/posts/8SjnKxjLniCAmcjnG/openai-deepmind-anthropic-etc-should-shut-down\n",
      "Score: 0.1807367205619812\n",
      "Published Date: 2023-12-17\n",
      "Author: Tamsin Leake\n",
      "Text: Crossposted from the AI Alignment Forum. May contain more technical jargon than usual.  (I expect that the point of this post is already obvious to many of the people reading it. Nevertheless, I believe that it is good to mention important things even if they seem obvious.)\n",
      "OpenAI, DeepMind, Anthropic, and other AI organizations focused on capabilities, should shut down. This is what would maximize the utility of pretty much everyone, including the people working inside of those organizations.\n [... Output truncated ...]"]
    },
    {
     "data": {
      "text/plain": [
       "'I found an interesting article on LessWrong.com titled \"OpenAI, DeepMind, Anthropic, etc. should shut down\" by Tamsin Leake, published on December 17, 2023. The article argues that major AI organizations like OpenAI, DeepMind, and Anthropic should cease their capabilities development and focus solely on alignment to prevent catastrophic outcomes from powerful AI (PAI).\\n\\nKey points from the article include:\\n\\n1. **Definition of PAI**: The author defines PAI as an AI system capable of steering the world towards its goals without being stopped or causing mass destruction, such as creating a supervirus.\\n\\n2. **Alignment Challenges**: The article emphasizes that current AI organizations do not know how to create a PAI that does not pose existential risks. The author argues that these organizations should halt their capabilities progress and focus entirely on solving alignment issues.\\n\\n3. **Critique of Current Strategies**: The author criticizes the strategies of these organizations, stating that they are progressing too quickly on capabilities without adequate focus on alignment, which could lead to catastrophic outcomes before alignment solutions are found.\\n\\n4. **Global Perspective**: The article dismisses the argument that halting AI development in the West would allow countries like China to gain an advantage, asserting that no country currently knows how to build a safe PAI.\\n\\n5. **Call to Action**: The author urges individuals working in these organizations to either slow down their progress through advocating for more safety checks or to quit their jobs to prevent contributing to potential global catastrophe.\\n\\nThe article concludes with a call for a collective effort to prioritize alignment over capabilities to ensure the safe development of AI.\\n\\nFor more details, you can read the full article [here](https://www.lesswrong.com/posts/8SjnKxjLniCAmcjnG/openai-deepmind-anthropic-etc-should-shut-down).\\n\\nSource: [LessWrong](https://www.lesswrong.com/posts/8SjnKxjLniCAmcjnG/openai-deepmind-anthropic-etc-should-shut-down)'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.run(\n",
    "    \"Summarize for me an interesting article about AI from lesswrong.com published after October 2023.\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
