{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66d0270a-b74f-4110-901e-7960b00297af",
   "metadata": {},
   "source": [
    "# Astra DB Vector Store\n",
    "\n",
    "This page provides a quickstart for using [Astra DB](https://docs.datastax.com/en/astra/home/astra.html) as a Vector Store.\n",
    "\n",
    "> DataStax [Astra DB](https://docs.datastax.com/en/astra/home/astra.html) is a serverless vector-capable database built on Apache CassandraÂ® and made conveniently available through an easy-to-use JSON API.\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe7c156-0413-47e3-9237-4769c4248869",
   "metadata": {},
   "source": [
    "Use of the integration requires the corresponding Python package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d00fcf4-9798-4289-9214-d9734690adfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -qU \"langchain-astradb>=0.3.3\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319bf84b",
   "metadata": {},
   "source": [
    "### Credentials\n",
    "\n",
    "Head to astra.datastax.com, create an account, and create a new database. Once the database has been initialized, click on the `Generate Token` button under Application Tokens. Then set the `ASTRA_DB_API_ENDPOINT` and the `ASTRA_DB_APPLICATION_TOKEN` in the cell below.\n",
    "\n",
    "- the API Endpoint looks like `https://01234567-89ab-cdef-0123-456789abcdef-us-east1.apps.astra.datastax.com`\n",
    "- the Token looks like `AstraCS:6gBhNmsk135....`\n",
    "- you may optionally provide a _Namespace_ such as `my_namespace`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7843c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "\n",
    "ASTRA_DB_API_ENDPOINT = getpass.getpass(\"ASTRA_DB_API_ENDPOINT = \")\n",
    "ASTRA_DB_APPLICATION_TOKEN = getpass.getpass(\"ASTRA_DB_APPLICATION_TOKEN = \")\n",
    "\n",
    "desired_namespace = getpass.getpass(\"ASTRA_DB_KEYSPACE = \")\n",
    "if desired_namespace:\n",
    "    ASTRA_DB_KEYSPACE = desired_namespace\n",
    "else:\n",
    "    ASTRA_DB_KEYSPACE = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22866f09-e10d-4f05-a24b-b9420129462e",
   "metadata": {},
   "source": [
    "## Instantiation\n",
    "\n",
    "There are two ways to create an Astra DB vector store, which differ in how the embeddings are computed.\n",
    "\n",
    "*Explicit embeddings*. You can separately instantiate a `langchain_core.embeddings.Embeddings` class and pass it to the `AstraDBVectorStore` constructor, just like with most other LangChain vector stores.\n",
    "\n",
    "*Integrated embedding computation*. Alternatively, you can use the [Vectorize](https://www.datastax.com/blog/simplifying-vector-embedding-generation-with-astra-vectorize) feature of Astra DB and simply specify the name of a supported embedding model when creating the store. The embedding computations are entirely handled within the database. (To proceed with this method, you must have enabled the desired embedding integration for your database, as described [in the docs](https://docs.datastax.com/en/astra-db-serverless/databases/embedding-generation.html).)\n",
    "\n",
    "### Explicit Instantiation\n",
    "\n",
    "We are going to use the `langchain_ollama` embedding function for the explicit embedding example since it is free. You can read more about it at [this page](https://python.langchain.com/v0.2/docs/integrations/text_embedding/ollama/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b32730d-176e-414c-9d91-fd3644c54211",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_astradb import AstraDBVectorStore\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "embedding_function = OllamaEmbeddings(model=\"llama3\")\n",
    "\n",
    "vector_store = AstraDBVectorStore(\n",
    "    embedding=embedding_function,\n",
    "    collection_name=\"astra_vector_demo\",\n",
    "    api_endpoint=ASTRA_DB_API_ENDPOINT,\n",
    "    token=ASTRA_DB_APPLICATION_TOKEN,\n",
    "    namespace=ASTRA_DB_KEYSPACE,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a1fe85-a42c-4f15-92e1-f79f1dd43ea2",
   "metadata": {},
   "source": [
    "### Integrated Instantiation\n",
    "\n",
    "Here it is assumed that you have\n",
    "\n",
    "- enabled the OpenAI integration in your Astra DB organization,\n",
    "- added an API Key named `\"OPENAI_API_KEY\"` to the integration, and scoped it to the database you are using.\n",
    "\n",
    "For more details please consult the [documentation](https://docs.datastax.com/en/astra-db-serverless/integrations/embedding-providers/openai.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d18455d-3fa6-4f9e-b687-3a2bc71c9a23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/isaachershenson/.pyenv/versions/3.11.9/lib/python3.11/site-packages/langchain_astradb/utils/astradb.py:248: UserWarning: Astra DB collection 'langchain_example_collection' is detected as having indexing turned on for all fields (either created manually or by older versions of this plugin). This implies stricter limitations on the amount of text each string in a document can store. Consider reindexing anew on a fresh collection to be able to store longer texts.\n",
      "  if not self._validate_indexing_policy(\n"
     ]
    }
   ],
   "source": [
    "from astrapy.info import CollectionVectorServiceOptions\n",
    "\n",
    "openai_vectorize_options = CollectionVectorServiceOptions(\n",
    "    provider=\"openai\",\n",
    "    model_name=\"text-embedding-3-small\",\n",
    "    authentication={\n",
    "        \"providerKey\": \"OPENAI_API_KEY\",\n",
    "    },\n",
    ")\n",
    "\n",
    "vector_store = AstraDBVectorStore(\n",
    "    collection_name=\"langchain_example_collection\",\n",
    "    api_endpoint=ASTRA_DB_API_ENDPOINT,\n",
    "    token=ASTRA_DB_APPLICATION_TOKEN,\n",
    "    namespace=ASTRA_DB_KEYSPACE,\n",
    "    collection_vector_service_options=openai_vectorize_options,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3796b39",
   "metadata": {},
   "source": [
    "## Manage vector store\n",
    "\n",
    "### Add items to vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "afb3e155",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1', '2', '3']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "document_1 = Document(\n",
    "    page_content=\"foo\",\n",
    "    metadata={\"source\": \"https://example.com\"}\n",
    ")\n",
    "\n",
    "document_2 = Document(\n",
    "    page_content=\"bar\",\n",
    "    metadata={\"source\": \"https://another-example.com\"}\n",
    ")\n",
    "\n",
    "document_3 = Document(\n",
    "    page_content=\"baz\",\n",
    "    metadata={\"source\": \"https://example.com\"}\n",
    ")\n",
    "\n",
    "documents = [document_1, document_2, document_3]\n",
    "\n",
    "vector_store.add_documents(documents=documents,ids=[\"1\",\"2\",\"3\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfce4edc",
   "metadata": {},
   "source": [
    "### Delete items from vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d3f69315",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store.delete(ids=[\"3\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12e1a07",
   "metadata": {},
   "source": [
    "## Query vector store\n",
    "\n",
    "Once your vector store has been created and the relevant documents have been added you will most likely wish to query it during the running of your chain or agent. \n",
    "\n",
    "### Query directly\n",
    "\n",
    "Performing a simple similarity search can be done as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "770b3467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* foo [{'source': 'https://example.com'}]\n"
     ]
    }
   ],
   "source": [
    "results = vector_store.similarity_search(\"thud\", k=3, filter={\"source\": \"https://example.com\"})\n",
    "for res in results:\n",
    "    print(f\"* {res.page_content} [{res.metadata}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce112165",
   "metadata": {},
   "source": [
    "You can also search with score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5924309a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* [SIM=0.627522] bar [{'source': 'https://another-example.com'}]\n"
     ]
    }
   ],
   "source": [
    "results = vector_store.similarity_search_with_score(\"thud\", k=1, filter={\"source\": \"https://another-example.com\"})\n",
    "for res, score in results:\n",
    "    print(f\"* [SIM={score:3f}] {res.page_content} [{res.metadata}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fead7af5",
   "metadata": {},
   "source": [
    "There are a variety of other search methods that are not covered in this notebook, such as MMR search or searching by vector. For a full list of the search abilites check out the [API reference](https://api.python.langchain.com/en/latest/vectorstores/langchain_astradb.vectorstores.AstraDBVectorStore.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e40f714",
   "metadata": {},
   "source": [
    "### Query by turning into retriever\n",
    "\n",
    "You can also transform the vector store into a retriever for easier usage in your chains. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dcee50e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://example.com'}, page_content='foo')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = vector_store.as_retriever(\n",
    "    search_type=\"similarity_score_threshold\",\n",
    "    search_kwargs={\"k\": 1, \"score_threshold\": 0.5},\n",
    ")\n",
    "retriever.invoke(\"thud\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734e683a",
   "metadata": {},
   "source": [
    "Using retriever in a simple RAG chain (note this requires a functional chat model, in this case we use OpenAI which requires you set `OPENAI_API_KEY` in your environment):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "08401498",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, I don't know the answer to that question based on the provided context.\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain import hub\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "rag_chain.invoke(\"thud\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869ab448-a029-4692-aefc-26b85513314d",
   "metadata": {},
   "source": [
    "For more, check out a complete RAG template using Astra DB [here](https://github.com/langchain-ai/langchain/tree/master/templates/rag-astradb)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177610c7-50d0-4b7b-8634-b03338054c8e",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da4d19f-9878-4d3d-82c9-09cafca20322",
   "metadata": {},
   "source": [
    "If you want to completely delete the collection from your Astra DB instance, run this.\n",
    "\n",
    "_(You will lose the data you stored in it.)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd405a13-6f71-46fa-87e6-167238e9c25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store.delete_collection()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14c34be",
   "metadata": {},
   "source": [
    "## API reference\n",
    "\n",
    "For detailed documentation of all `AstraDBVectorStore` features and configurations head to the API reference:https://api.python.langchain.com/en/latest/vectorstores/langchain_astradb.vectorstores.AstraDBVectorStore.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
