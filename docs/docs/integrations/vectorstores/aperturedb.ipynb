{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "683953b3",
   "metadata": {},
   "source": [
    "# ApertureDB\n",
    "\n",
    ">[ApertureDB](https://docs.aperturedata.io) is a database that stores, indexes, and manages CV related data like images, videos, bounding boxes, embeddings, meta data.\n",
    "\n",
    "This notebook shows how to use functionality related to the ApertureDB.\n",
    "\n",
    "To run, you should have a [ApertureDB instance up and running](https://docs.aperturedata.io/HowToGuides/start/Setup)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62cff8a-bcf7-4e33-bbbc-76999c2e3e20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install --upgrade --quiet  aperturedb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0f9e02-8eb0-4aef-b11f-8861360472ee",
   "metadata": {},
   "source": [
    "We shall be using aperturedb Vectorstore to index embeddings from a URL.\n",
    "\n",
    "We want to use OllamaEmbeddings so we have to import the necessary modules.\n",
    "\n",
    "Ollama can be set up as a docker container as per the [official guide](https://hub.docker.com/r/ollama/ollama)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b6ed9cd-81b9-46e5-9c20-5aafca2844d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "#For loading documents from web\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "loader = WebBaseLoader(\"https://docs.aperturedata.io\")\n",
    "docs = loader.load()\n",
    "\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "embeddings = OllamaEmbeddings()\n",
    "\n",
    "from langchain_community.vectorstores import ApertureDB\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dcf88bdf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter()\n",
    "documents = text_splitter.split_documents(docs)\n",
    "vector_db = ApertureDB.from_documents(documents, embeddings)\n",
    "\n",
    "llm = Ollama(model=\"llama2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8c513ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided context, ApertureData can store images in various ways. Here are some possibilities:\n",
      "\n",
      "1. Cloud Storage: ApertureData may use cloud storage services such as Amazon S3, Google Cloud Storage, or Microsoft Azure Blob Storage to store images. This allows for easy scalability and accessibility of the images from anywhere.\n",
      "2. Database Tables: ApertureData can store images in database tables, possibly using a separate table for each modality (e.g., images, videos, documents). This allows for efficient querying and manipulation of the images based on their metadata and other factors.\n",
      "3. Object Store: ApertureData may use an object store service such as AWS S3, Google Cloud Storage, or Azure Blob Storage to store images. This allows for easy scalability and accessibility of the images from anywhere.\n",
      "4. Local Storage: ApertureData can also store images locally on its servers or on customer's premises, depending on their hosting options. This can be useful for customers who require higher security or control over their data.\n",
      "\n",
      "In summary, ApertureData can store images using various storage solutions such as cloud storage, database tables, object stores, or local storage, depending on its hosting options and the requirements of its users.\n"
     ]
    }
   ],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\"\"\"Answer the following question based only on the provided context:\n",
    "\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\n",
    "Question: {input}\"\"\")\n",
    "\n",
    "document_chain = create_stuff_documents_chain(llm, prompt)\n",
    "\n",
    "\n",
    "from langchain.chains import create_retrieval_chain\n",
    "\n",
    "retriever = vector_db.as_retriever()\n",
    "retrieval_chain = create_retrieval_chain(retriever, document_chain)\n",
    "\n",
    "response = retrieval_chain.invoke({\"input\": \"how can aperturedata store images?\"})\n",
    "print(response[\"answer\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
