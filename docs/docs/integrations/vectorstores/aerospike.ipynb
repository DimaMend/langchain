{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aerospike\n",
    "\n",
    "[Aerospike Vector Search](https://aerospike.com/docs/vector)(AVS) is a vector database built on\n",
    "top of the performant and robust Aerospike database.\n",
    "\n",
    "This notebook showcases the functionality of the langchain Aerospike VectorStore\n",
    "integration. Before we get started we need to make sure we have a running AVS instance. Use one of the [available\n",
    "installation methods](https://aerospike.com/docs/vector/install). \n",
    "\n",
    "We will store the IP and Port of your AVS instance to use later on in this demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROXIMUS_HOST=\"<avs-ip>\"\n",
    "PROXIMUS_PORT=5000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Dependencies \n",
    "The sentence-transformers dependency is rather large so this could take ~3-5 minutes.\n",
    "\n",
    "TODO: CHANGE GIT REPO TO OFFICIAL LANGCHAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade --quiet aerospike-vector-search sentence-transformers git+https://github.com/aerospike/langchain.git@VEC-131-add-aerospike#subdirectory=libs/community"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Quotes Dataset\n",
    "\n",
    "We will download a dataset of ~500k quotes and use a subset of them for semantic search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-05-09 17:23:42--  https://archive.org/download/quotes_20230625/quotes.csv\n",
      "Resolving archive.org (archive.org)... 207.241.224.2\n",
      "Connecting to archive.org (archive.org)|207.241.224.2|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://ia902709.us.archive.org/27/items/quotes_20230625/quotes.csv [following]\n",
      "--2024-05-09 17:23:42--  https://ia902709.us.archive.org/27/items/quotes_20230625/quotes.csv\n",
      "Resolving ia902709.us.archive.org (ia902709.us.archive.org)... 207.241.228.209\n",
      "Connecting to ia902709.us.archive.org (ia902709.us.archive.org)|207.241.228.209|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 144428641 (138M) [text/csv]\n",
      "Saving to: ‘quotes.csv’\n",
      "\n",
      "quotes.csv          100%[===================>] 137.74M  2.47MB/s    in 52s     \n",
      "\n",
      "2024-05-09 17:24:35 (2.62 MB/s) - ‘quotes.csv’ saved [144428641/144428641]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/aerospike/aerospike-vector-search-examples/raw/7dfab0fccca0852a511c6803aba46578729694b5/quote-semantic-search/container-volumes/quote-search/data/quotes.csv.tgz\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Quotes Into Documents\n",
    "We will load out dataset of quotes using the DocumentLoader `CSVLoader`. In this case `lazy_load` returns an iterator to more efficiently ingest our quotes. In this example we are only going to load 5000 quotes rather than all 500k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "import itertools\n",
    "\n",
    "NUM_QUOTES = 5000\n",
    "documents = CSVLoader('./quotes.csv', metadata_columns=[\"author\", \"category\"]).lazy_load()\n",
    "documents = list(itertools.islice(documents, NUM_QUOTES)) # Allows us to slice an iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content=\"quote: I'm selfish, impatient and a little insecure. I make mistakes, I am out of control and at times hard to handle. But if you can't handle me at my worst, then you sure as hell don't deserve me at my best.\" metadata={'source': './quotes.csv', 'row': 0, 'author': 'Marilyn Monroe', 'category': 'attributed-no-source, best, life, love, mistakes, out-of-control, truth, worst'}\n"
     ]
    }
   ],
   "source": [
    "print(documents[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create your Embedder\n",
    "Here we are using HuggingFaceEmbeddings and a sentence transformer model \"all-MiniLM-L6-v2\" to embed our documents so that we can perform a vector search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "MODEL_DIM = 384\n",
    "embedder = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an Aerospike Index and Embed Documents\n",
    "\n",
    "Before we add documents, we need to create an index. In this example, we have some convenience code that checks to see if the expected index is already created. Make sure to replace <proximus-ip> with the IP to your AVS instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Aerospike\n",
    "from aerospike_vector_search import AdminClient, Client, HostPort\n",
    "from aerospike_vector_search.types import VectorDistanceMetric\n",
    "\n",
    "# Here we are using the AVS host and port you configured earlier\n",
    "seed = HostPort(host=PROXIMUS_HOST, port=PROXIMUS_PORT) \n",
    "\n",
    "# The namespace of where to place our vectors. This should match the vector configured in your aerospike.conf file.\n",
    "NAMESPACE = \"test\"\n",
    "\n",
    "# The name of our new index.\n",
    "INDEX_NAME = \"quote-miniLM-L6-v2\"\n",
    "\n",
    "# AVS needs to know which metadata key contains our vector when creating the index and inserting documents.\n",
    "VECTOR_KEY = \"vector\" \n",
    "\n",
    "client = Client(\n",
    "    seeds=seed\n",
    ")\n",
    "admin_client = AdminClient(\n",
    "    seeds=seed,\n",
    ")\n",
    "index_exists = False\n",
    "\n",
    "# Check if the index already exists. If not, create it\n",
    "for index in admin_client.index_list():\n",
    "    if (\n",
    "        index[\"id\"][\"namespace\"] == NAMESPACE\n",
    "        and index[\"id\"][\"name\"] == INDEX_NAME\n",
    "    ):\n",
    "        index_exists = True\n",
    "        print(f\"{INDEX_NAME} already exists. Skipping creation\"}\n",
    "        break\n",
    "\n",
    "if not index_exists:\n",
    "    print(f\"{INDEX_NAME} does not exist. Creating index\"}\n",
    "    admin_client.index_create(\n",
    "        namespace=NAMESPACE,\n",
    "        name=INDEX_NAME,\n",
    "        vector_field=VECTOR_KEY,\n",
    "        vector_distance_metric=VectorDistanceMetric.COSINE,\n",
    "        dimensions=MODEL_DIM,\n",
    "        index_meta_data={\n",
    "            \"model\": \"miniLM-L6-v2\",\n",
    "            \"date\": \"05/04/2024\",\n",
    "            \"dim\": str(MODEL_DIM),\n",
    "            \"distance\": \"cosine\",\n",
    "        }\n",
    "    )\n",
    "\n",
    "aerospike = Aerospike.from_documents(\n",
    "    documents,\n",
    "    embedder,\n",
    "    client,\n",
    "    NAMESPACE,\n",
    "    vector_key=VECTOR_KEY,\n",
    "    index_name=INDEX_NAME,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search the Documents\n",
    "Now that we've inserted our vectors we can now use vector search on our quotes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~ Document 0 ~~~~\n",
      "auto-generated id: 7afc2aee-d22b-4527-81a8-c168038ee9ae\n",
      "author:  Carl Sagan, Cosmos\n",
      "quote: The Cosmos is all that is or was or ever will be. Our feeblest contemplations of the Cosmos stir us -- there is a tingling in the spine, a catch in the voice, a faint sensation, as if a distant memory, of falling from a height. We know we are approaching the greatest of mysteries.\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "~~~~ Document 1 ~~~~\n",
      "auto-generated id: e740c36c-b411-4d7e-bc6a-6f1e18ad93e3\n",
      "author:  Renee Ahdieh, The Rose & the Dagger\n",
      "quote: From the stars, to the stars.\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "~~~~ Document 2 ~~~~\n",
      "auto-generated id: b09d0587-5703-4c3a-b0b6-05810b517773\n",
      "author:  Elizabeth Gilbert\n",
      "quote: The love that moves the sun and the other stars.\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "~~~~ Document 3 ~~~~\n",
      "auto-generated id: 931dec9a-30b1-4f2d-a0ce-ad8148cf7094\n",
      "author:  Dante Alighieri, Paradiso\n",
      "quote: Love, that moves the sun and the other stars\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "~~~~ Document 4 ~~~~\n",
      "auto-generated id: d011f80a-0475-494c-a15b-0b14901ce450\n",
      "author:  Thich Nhat Hanh, Teachings on Love\n",
      "quote: Through my love for you, I want to express my love for the whole cosmos, the whole of humanity, and all beings. By living with you, I want to learn to love everyone and all species. If I succeed in loving you, I will be able to love everyone and all species on Earth... This is the real message of love.\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"A quote about the beauty of the cosmos\"\n",
    "docs = aerospike.similarity_search(query, k=5, index_name=INDEX_NAME, metadata_keys=[\"_id\", \"author\"])\n",
    "\n",
    "def print_documents(docs):\n",
    "    for i, doc in enumerate(docs):\n",
    "        print(\"~~~~ Document\", i, \"~~~~\")\n",
    "        print(\"auto-generated id:\", doc.metadata[\"_id\"])\n",
    "        print(\"author: \",doc.metadata[\"author\"])\n",
    "        print(doc.page_content)\n",
    "        print(\"~~~~~~~~~~~~~~~~~~~~\\n\")\n",
    "    \n",
    "print_documents(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding Additional Quotes as Text\n",
    "We can also add additional quotes by using `add_texts`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New IDs\n",
      "['11b37904-b2cc-4f07-8346-b49f256f6d0b', '2c590987-aeb7-44ad-a21a-2645eee86657', '893eeb4f-7580-45f0-8120-785221271395']\n"
     ]
    }
   ],
   "source": [
    "aerospike = Aerospike(\n",
    "    client,\n",
    "    embedder,\n",
    "    NAMESPACE,\n",
    "    index_name=INDEX_NAME,\n",
    "    vector_key=VECTOR_KEY,\n",
    ")\n",
    "\n",
    "ids = aerospike.add_texts(\n",
    "    [\n",
    "        \"quote: Rebellions are built on hope.\", \n",
    "        \"quote: Logic is the beginning of wisdom, not the end.\",\n",
    "        \"quote: If wishes were fishes, we’d all cast nets.\"\n",
    "    ],\n",
    "    metadatas=[\n",
    "        {\"author\": \"Jyn Erso, Rogue One\"}, \n",
    "        {\"author\": \"Spock, Star Trek\"},\n",
    "        {\"author\": \"Frank Herbert, Dune\"},\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(\"New IDs\")\n",
    "print(ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search Documents Using Max Marginal Relevance Search\n",
    "\n",
    "We can utilize max marginal relevance search to find vectors that are similar to our query but dissimilar to each other.  In this example, we create a retriever object using `as_retriever`, but this could be done just as easily by calling `aerospike.max_marginal_relevance_search` directly. The search_kargs lambda_mult determines the diversity of our query response. 0 corresponds to maximum diversity and 1 to minimum diversity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~ Document 0 ~~~~\n",
      "auto-generated id: e3d8ac56-5505-45bc-922d-d3189f7fa3bb\n",
      "author:  John Grogan, Marley and Me: Life and Love With the World's Worst Dog\n",
      "quote: Such short little lives our pets have to spend with us, and they spend most of it waiting for us to come home each day. It is amazing how much love and laughter they bring into our lives and even how much closer we become with each other because of them.\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "~~~~ Document 1 ~~~~\n",
      "auto-generated id: fcc06179-7c6f-4780-8d9a-d0d9ab3cf346\n",
      "author:  Colleen Houck, Tiger's Curse\n",
      "quote: He then put both hands on the door on either side of my head and leaned in close, pinning me against it. I trembled like a downy rabbit caught in the clutches of a wolf. The wolf came closer. He bent his head and began nuzzling my cheek. The problem was…I wanted the wolf to devour me.\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "~~~~ Document 2 ~~~~\n",
      "auto-generated id: 15e9a694-de71-47fd-adfc-8179fcdb62a4\n",
      "author:  Roger A. Caras\n",
      "quote: Dogs have given us their absolute all. We are the center of their universe. We are the focus of their love and faith and trust. They serve us in return for scraps. It is without a doubt the best deal man has ever made.\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "~~~~ Document 3 ~~~~\n",
      "auto-generated id: 5e580959-74c2-4236-8509-5375b22b4970\n",
      "author:  Ray Bradbury\n",
      "quote: Stuff your eyes with wonder,\" he said, \"live as if you'd drop dead in ten seconds. See the world. It's more fantastic than any dream made or paid for in factories. Ask no guarantees, ask for no security, there never was such an animal. And if there were, it would be related to the great sloth which hangs upside down in a tree all day every day, sleeping its life away. To hell with that,\" he said, \"shake the tree and knock the great sloth down on his ass.\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"A quote about our favorite four-legged pets\"\n",
    "retriever = aerospike.as_retriever(search_type=\"mmr\", search_kwargs={\"fetch_k\": 20, \"lambda_mult\":0.7})\n",
    "matched_docs = retriever.invoke(query)\n",
    "\n",
    "print_documents(matched_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search Documents with a Relevance Threshold\n",
    "\n",
    "Another useful feature is a similarity search with a relevance threshold. Generally, we only want results that are most similar to our query but also within some range of proximity. A relevance of 1 is most similar and a relevance of is most dissimilar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~ Document 0 ~~~~\n",
      "auto-generated id: 796b6eb1-fa79-49f7-ac4d-1adc9fd8f081\n",
      "author:  Roy T. Bennett, The Light in the Heart\n",
      "quote: Never lose hope. Storms make people stronger and never last forever.\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "~~~~ Document 1 ~~~~\n",
      "auto-generated id: f01592be-d8c4-40f7-96ee-0cad56f6d358\n",
      "author:  Roy T. Bennett, The Light in the Heart\n",
      "quote: Difficulties and adversities viciously force all their might on us and cause us to fall apart, but they are necessary elements of individual growth and reveal our true potential. We have got to endure and overcome them, and move forward. Never lose hope. Storms make people stronger and never last forever.\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "~~~~ Document 2 ~~~~\n",
      "auto-generated id: c3ad5654-8962-4dcf-b885-75c42769e6be\n",
      "author:  Vincent van Gogh, The Letters of Vincent van Gogh\n",
      "quote: There is peace even in the storm\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "~~~~ Document 3 ~~~~\n",
      "auto-generated id: 2be8745c-e523-4b24-b355-a38ae469d88d\n",
      "author:  Edwin Morgan, A Book of Lives\n",
      "quote: Valentine WeatherKiss me with rain on your eyelashes,come on, let us sway together,under the trees, and to hell with thunder.\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-1612:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.11/threading.py\", line 1401, in run\n",
      "    self.function(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/aerospike_vector_search/internal/channel_provider.py\", line 91, in _tend\n",
      "    for node, channel_endpoints in temp_node_channels:\n",
      "RuntimeError: dictionary changed size during iteration\n",
      "Exception in thread Thread-1613:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.11/threading.py\", line 1401, in run\n",
      "    self.function(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/aerospike_vector_search/internal/channel_provider.py\", line 91, in _tend\n",
      "    for node, channel_endpoints in temp_node_channels:\n",
      "RuntimeError: dictionary changed size during iteration\n"
     ]
    }
   ],
   "source": [
    "query = \"A quote about stormy weather\"\n",
    "retriever = aerospike.as_retriever(\n",
    "    search_type=\"similarity_score_threshold\",\n",
    "    search_kwargs={'score_threshold': 0.4} # A greater value returns items with more relevance\n",
    ")\n",
    "matched_docs = retriever.invoke(query)\n",
    "\n",
    "print_documents(matched_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up\n",
    "\n",
    "We need to make sure to close our client to release resources and cleanup threads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "admin_client.close()\n",
    "client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ready. Set. Search!\n",
    "\n",
    "Now that you are up to speed with Aerospike Vector Search's Langchain integration you now have the power of the Aerospike Database and the Langchain ecosystem at your finger tips. Happy building!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
