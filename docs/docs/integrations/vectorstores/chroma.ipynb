{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "683953b3",
   "metadata": {},
   "source": [
    "# Chroma\n",
    "\n",
    "This notebook covers how to get started with the `Chroma` vector store.\n",
    "\n",
    ">[Chroma](https://docs.trychroma.com/getting-started) is a AI-native open-source vector database focused on developer productivity and happiness. Chroma is licensed under Apache 2.0. View the full docs of `Chroma` at [this page](https://docs.trychroma.com/reference/py-collection), and find the API reference for the LangChain integration at [this page](https://api.python.langchain.com/en/latest/vectorstores/langchain_chroma.vectorstores.Chroma.html).\n",
    "\n",
    "## Setup\n",
    "\n",
    "To access `Chroma` vector stores you'll need to install the `langchain-chroma` integration package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83a43688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "grpcio-tools 1.65.1 requires grpcio>=1.65.1, but you have grpcio 1.63.0 which is incompatible.\n",
      "grpcio-tools 1.65.1 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 4.25.4 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -qU \"langchain-chroma>=0.1.2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5ffbf8",
   "metadata": {},
   "source": [
    "### Credentials\n",
    "\n",
    "You can use the `Chroma` vector store without any credentials, simply installing the package above is enough!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd17cfed",
   "metadata": {},
   "source": [
    "If you want to get automated tracing of your model calls you can also set your [LangSmith](https://docs.smith.langchain.com/) API key by uncommenting below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7e1243",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass(\"Enter your LangSmith API key: \")\n",
    "# os.environ[\"LANGSMITH_TRACING\"] = \"true\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47f73f4",
   "metadata": {},
   "source": [
    "## Instantiation\n",
    "\n",
    "To instantiate a vector store from `Chroma` you must provide an embedding function. In this example we will use the `OllamaEmbeddings` function since it is open source and does not require payment. You can read about `OllamaEmbeddings` at [this page](https://python.langchain.com/v0.2/docs/integrations/text_embedding/ollama/).\n",
    "\n",
    "### Basic Instantiation \n",
    "\n",
    "Below is a basic instantiation, including the use of a directory to save the data locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3ea11a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "embedding_function = OllamaEmbeddings(model=\"llama3\")\n",
    "\n",
    "vector_store = Chroma(\n",
    "    collection_name=\"example_collection\",\n",
    "    embedding_function=embedding_function,\n",
    "    persist_directory=\"./chroma_db\" # Where to save data locally, remove if not neccesary\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb62a8c",
   "metadata": {},
   "source": [
    "### Instantiation from client\n",
    "\n",
    "You can also instantiate from a `Chroma` client, which is particularly useful if you want easier access to the underlying database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3fe4457f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Add of existing embedding ID: 1\n",
      "Add of existing embedding ID: 2\n",
      "Add of existing embedding ID: 3\n",
      "Insert of existing embedding ID: 1\n",
      "Insert of existing embedding ID: 2\n",
      "Insert of existing embedding ID: 3\n"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "\n",
    "persistent_client = chromadb.PersistentClient()\n",
    "collection = persistent_client.get_or_create_collection(\"collection_name\")\n",
    "collection.add(ids=[\"1\", \"2\", \"3\"], documents=[\"a\", \"b\", \"c\"])\n",
    "\n",
    "vector_store_from_client = Chroma(\n",
    "    client=persistent_client,\n",
    "    collection_name=\"collection_name\",\n",
    "    embedding_function=embedding_function,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d037340",
   "metadata": {},
   "source": [
    "## Manage vector store\n",
    "\n",
    "### Add items to vector store\n",
    "\n",
    "We can add documents to our vector store by creating new `Document` objects and passing them in a list, along with a corresponding list of ids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "da279339",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1', '2', '3']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "document_1 = Document(\n",
    "    page_content=\"foo\",\n",
    "    metadata={\"source\": \"https://example.com\"}\n",
    ")\n",
    "\n",
    "document_2 = Document(\n",
    "    page_content=\"bar\",\n",
    "    metadata={\"source\": \"https://example.com\"}\n",
    ")\n",
    "\n",
    "document_3 = Document(\n",
    "    page_content=\"baz\",\n",
    "    metadata={\"source\": \"https://example.com\"}\n",
    ")\n",
    "\n",
    "documents = [document_1, document_2, document_3]\n",
    "\n",
    "vector_store.add_documents(documents=documents,ids=[\"1\",\"2\",\"3\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7add6366",
   "metadata": {},
   "source": [
    "### Update items in vector store\n",
    "\n",
    "Now that we have added documents to our vector store, we can update existing documents by using the `update_documents` function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ef5dbd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_document = Document(\n",
    "    page_content=\"qux\",\n",
    "    metadata={\"source\": \"https://another-example.com\"}\n",
    ")\n",
    "\n",
    "vector_store.update_document(document_id=\"1\",document=updated_document)\n",
    "# You can also update miltiple documents at once\n",
    "vector_store.update_documents(ids=[\"1\",\"2\"],documents=[updated_document,updated_document])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b9a13a",
   "metadata": {},
   "source": [
    "### Delete items from vector store\n",
    "\n",
    "We can also delete items from our vector store as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "56f17791",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store.delete(ids=[\"3\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213acf08",
   "metadata": {},
   "source": [
    "## Query vector store\n",
    "\n",
    "Once your vector store has been created and the relevant documents have been added you will most likely wish to query it during the running of your chain or agent. \n",
    "\n",
    "### Query directly\n",
    "\n",
    "Performing a simple similarity search can be done as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e2b96fcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* qux [{'source': 'https://another-example.com'}]\n"
     ]
    }
   ],
   "source": [
    "results = vector_store.similarity_search(query=\"thud\",k=1,filter={\"source\":\"https://another-example.com\"})\n",
    "for doc in results:\n",
    "    print(f\"* {doc.page_content} [{doc.metadata}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd117ea",
   "metadata": {},
   "source": [
    "If you want to execute a similarity search and receive the corresponding scores you can run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2768a331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* [SIM=11593.251037] qux [{'source': 'https://another-example.com'}]\n"
     ]
    }
   ],
   "source": [
    "results = vector_store.similarity_search_with_score(query=\"thud\",k=1,filter={\"source\":\"https://another-example.com\"})\n",
    "for doc, score in results:\n",
    "    print(f\"* [SIM={score:3f}] {doc.page_content} [{doc.metadata}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b436c8",
   "metadata": {},
   "source": [
    "You can also search by vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8ea434a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* qux [{'source': 'https://another-example.com'}]\n"
     ]
    }
   ],
   "source": [
    "results = vector_store.similarity_search_by_vector(embedding=embedding_function.embed_query(\"thud\"),k=1,filter={\"source\":\"https://another-example.com\"})\n",
    "for doc in results:\n",
    "    print(f\"* {doc.page_content} [{doc.metadata}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1c1e6f",
   "metadata": {},
   "source": [
    "There are even more search functions, such as searching by image or using maximum marginal relevance search. For a full list of the search functions provided by the `Chroma` vectorstore, please visit the [API reference](https://api.python.langchain.com/en/latest/vectorstores/langchain_chroma.vectorstores.Chroma.html).\n",
    "\n",
    "### Query by turning into retriever\n",
    "\n",
    "You can also transform the vector store into a retriever for easier usage in your chains. For more information on the different search types and kwargs you can pass, please visit the API reference [here](https://api.python.langchain.com/en/latest/vectorstores/langchain_chroma.vectorstores.Chroma.html#langchain_chroma.vectorstores.Chroma.as_retriever)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7b6f7867",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 20 is greater than number of elements in index 2, updating n_results = 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://another-example.com'}, page_content='qux')]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = vector_store.as_retriever(\n",
    "    search_type=\"mmr\",\n",
    "    search_kwargs={\"k\": 1}\n",
    ")\n",
    "retriever.invoke(\"thud\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b7b73c",
   "metadata": {},
   "source": [
    "Using retriever in a simple RAG chain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "84a19f48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 20 is greater than number of elements in index 2, updating n_results = 2\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, I don't have enough information to answer that question.\""
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain import hub\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "rag_chain.invoke(\"thud\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed28359",
   "metadata": {},
   "source": [
    "## API reference\n",
    "\n",
    "For detailed documentation of all `Chroma` vector store features and configurations head to the API reference: https://api.python.langchain.com/en/latest/vectorstores/langchain_chroma.vectorstores.Chroma.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
