{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AskNews\n",
    "\n",
    "> [AskNews](https://asknews.app) infuses any LLM with the latest global news (or historical news), using a single natural language query. Specifically, AskNews is enriching over 300k articles per day by translating, summarizing, extracting entities, and indexing them into hot and cold vector databases. AskNews puts these vector databases on a low-latency endpoint for you. When you query AskNews, you get back a prompt-optimized string that contains all the most pertinent enrichments (e.g. entities, classifications, translation, summarization). This means that you do not need to manage your own news RAG, and you do not need to worry about how to properly convey news information in a condensed way to your LLM.\n",
    "> AskNews is also committed to transparency, which is why our coverage is monitored and diversified across hundreds of countries, 13 languages, and 50 thousand sources. If you'd like to track our source coverage, you can visit our [transparency dashboard](https://asknews.app/en/transparency).\n",
    "\n",
    "## Setup\n",
    "\n",
    "The integration lives in the `langchain-community` package. We also need to install the `asknews` package itself.\n",
    "\n",
    "```bash\n",
    "pip install -U langchain-community asknews\n",
    "```\n",
    "\n",
    "We also need to set our AskNews API credentials, which can be generated at the [AskNews console](https://my.asknews.app)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "os.environ[\"ASKNEWS_CLIENT_ID\"] = getpass.getpass()\n",
    "os.environ[\"ASKNEWS_CLIENT_SECRET\"] = getpass.getpass()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's also helpful (but not needed) to set up [LangSmith](https://smith.langchain.com/) for best-in-class observability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "# os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.retrievers import AskNewsRetriever\n",
    "\n",
    "retriever = AskNewsRetriever(k=3)\n",
    "\n",
    "retriever.invoke(\"impact of fed policy on the tech sector\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you have full control on filtering by category, time, pagination, and even the search method you use.\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "start = (datetime.now() - timedelta(days=7)).timestamp()\n",
    "end = datetime.now().timestamp()\n",
    "\n",
    "retriever = AskNewsRetriever(\n",
    "    k=3,\n",
    "    categories=[\"Business\", \"Technology\"],\n",
    "    start_timestamp=int(start),  # defaults to 48 hours ago\n",
    "    end_timestamp=int(end),  # defaults to now\n",
    "    method=\"kw\",  # defaults to \"nl\", natural language, can also be \"kw\" for keyword search\n",
    "    offset=10,  # allows you to paginate results\n",
    ")\n",
    "\n",
    "retriever.invoke(\"federal reserve S&P500\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chaining\n",
    "\n",
    "We can easily combine this retriever in to a chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"The following news articles may come in handy for answering the question:\n",
    "\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "\n",
    "{question}\"\"\"\n",
    ")\n",
    "chain = (\n",
    "    RunnablePassthrough.assign(context=(lambda x: x[\"question\"]) | retriever)\n",
    "    | prompt\n",
    "    | ChatOpenAI(model=\"gpt-4-1106-preview\")\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.invoke({\"question\": \"What is the impact of fed policy on the tech sector?\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
