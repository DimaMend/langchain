{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fe4TEia7RQux"
      },
      "source": [
        "### Installation\n",
        "\n",
        "You will need to install both the `langchain_community` pacakges:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RoBaSem1Ltwf"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cUX8HMaWRIjg",
        "outputId": "8087cf17-c5b2-40b4-9cdc-90934bade9c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install -qU asyncio langchain_community"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hl_Ns9APLeIK"
      },
      "source": [
        "# Nimble AnswerIt Retriever\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tkJ6Qq9v2mqI",
        "outputId": "41f90261-96b8-4e26-d775-480c532b4d2c"
      },
      "outputs": [],
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "if \"NIMBLE_API_KEY\" not in os.environ:\n",
        "    os.environ[\"NIMBLE_API_KEY\"] = getpass.getpass(\"Enter your NIMBLE_API_KEY: \")\n",
        "\n",
        "if \"OPENAI_API_KEY\" not in os.environ:\n",
        "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OPENAI_API_KEY: \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kJb6ZUKvCX_"
      },
      "source": [
        "### Instantiation\n",
        "Now we can instantiate our retriever, initializing a client and optionally pre-adding data sources urls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "9CgI-2t2Q8pD"
      },
      "outputs": [],
      "source": [
        "from langchain_community.retrievers.nimbleit import (\n",
        "    NimbleItRetriever,\n",
        ")\n",
        "\n",
        "retriever = NimbleItRetriever(\n",
        "    answerit_url=\"https://answerit.webit.live\",\n",
        "    authorization_token=os.environ[\"NIMBLE_API_KEY\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vl28uw_RKj59",
        "outputId": "0fdd35b6-631e-47bf-cafd-c24ca316ccc4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "pipeline_id 4be8b76e-d62a-4b61-bd6c-1e7b1f9e5618\n"
          ]
        }
      ],
      "source": [
        "print('pipeline_id', retriever.store.pipeline_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Add Sources of Information from URLs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "DoIzwPTC0n2U"
      },
      "outputs": [],
      "source": [
        "retriever.add_sources(\n",
        "    [\n",
        "        {\n",
        "            \"url\": \"https://lilianweng.github.io/posts/2023-06-23-agent/\",\n",
        "            \"return_most_relevant_content\": False,\n",
        "            \"depth\": 0\n",
        "        },\n",
        "        {\n",
        "            \"url\": \"https://en.wikipedia.org/wiki/Pizza\",\n",
        "            \"return_most_relevant_content\": False,\n",
        "            \"depth\": 0\n",
        "        }\n",
        "    ],\n",
        "    wait=True\n",
        " )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "collapsed": true,
        "id": "2qSAKRaxDOOi"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Document(metadata={'evidences': [{'evidence': 'LLM-powered Autonomous Agents', 'most_relevant_content': '', 'url': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, {'evidence': 'LLMs struggle to adjust plans when faced with unexpected errors, making them less robust compared to humans who learn from trial and error.', 'most_relevant_content': '', 'url': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, {'evidence': 'Current agent system relies on natural language as an interface between LLMs and external components such as memory and tools.', 'most_relevant_content': '', 'url': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, {'evidence': 'LLMs may make formatting errors and occasionally exhibit rebellious behavior (e.g. refuse to follow an instruction).', 'most_relevant_content': '', 'url': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, {'evidence': 'Both TALM (Tool Augmented Language Models; [Parisi et al. 2022](https://arxiv.org/abs/2205.12255)) and Toolformer ([Schick et al. 2023](https://arxiv.org/abs/2302.04761)) fine-tune a LM to learn to use external tool APIs.', 'most_relevant_content': '', 'url': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, {'evidence': 'HuggingGPT ([Shen et al. 2023](https://arxiv.org/abs/2303.17580)) is a framework to use ChatGPT as the task planner to select models available in HuggingFace platform according to the model descriptions and summarize the response based on the execution results.', 'most_relevant_content': '', 'url': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}]}, page_content='LLM stands for Large Language Model. These are advanced artificial intelligence models designed to understand and generate human language. They are trained on vast amounts of text data and can perform a variety of language-related tasks such as translation, summarization, question answering, and more. LLMs are the backbone of many modern AI applications and are used to power autonomous agents, which can perform complex tasks by interacting with external tools and systems. Examples of LLMs include models like GPT-3, which are capable of generating coherent and contextually relevant text based on the input they receive.')]\n"
          ]
        }
      ],
      "source": [
        "result = retriever.invoke(\"What is llm?\")\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A9Xyx1ekCxgl"
      },
      "source": [
        "### Use within a chain\n",
        "Initialize ChatOpenAI and define a prompt template\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "b2BCqKMwEnKZ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langchain_openai in /home/ubuntu/venv-lc/lib/python3.12/site-packages (0.2.1)\n",
            "Requirement already satisfied: langchain-core<0.4,>=0.3 in /home/ubuntu/venv-lc/lib/python3.12/site-packages (from langchain_openai) (0.3.6)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.40.0 in /home/ubuntu/venv-lc/lib/python3.12/site-packages (from langchain_openai) (1.48.0)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /home/ubuntu/venv-lc/lib/python3.12/site-packages (from langchain_openai) (0.7.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /home/ubuntu/venv-lc/lib/python3.12/site-packages (from langchain-core<0.4,>=0.3->langchain_openai) (6.0.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/ubuntu/venv-lc/lib/python3.12/site-packages (from langchain-core<0.4,>=0.3->langchain_openai) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /home/ubuntu/venv-lc/lib/python3.12/site-packages (from langchain-core<0.4,>=0.3->langchain_openai) (0.1.128)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /home/ubuntu/venv-lc/lib/python3.12/site-packages (from langchain-core<0.4,>=0.3->langchain_openai) (24.1)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /home/ubuntu/venv-lc/lib/python3.12/site-packages (from langchain-core<0.4,>=0.3->langchain_openai) (2.9.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /home/ubuntu/venv-lc/lib/python3.12/site-packages (from langchain-core<0.4,>=0.3->langchain_openai) (8.5.0)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /home/ubuntu/venv-lc/lib/python3.12/site-packages (from langchain-core<0.4,>=0.3->langchain_openai) (4.12.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /home/ubuntu/venv-lc/lib/python3.12/site-packages (from openai<2.0.0,>=1.40.0->langchain_openai) (4.6.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /home/ubuntu/venv-lc/lib/python3.12/site-packages (from openai<2.0.0,>=1.40.0->langchain_openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /home/ubuntu/venv-lc/lib/python3.12/site-packages (from openai<2.0.0,>=1.40.0->langchain_openai) (0.27.2)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /home/ubuntu/venv-lc/lib/python3.12/site-packages (from openai<2.0.0,>=1.40.0->langchain_openai) (0.5.0)\n",
            "Requirement already satisfied: sniffio in /home/ubuntu/venv-lc/lib/python3.12/site-packages (from openai<2.0.0,>=1.40.0->langchain_openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /home/ubuntu/venv-lc/lib/python3.12/site-packages (from openai<2.0.0,>=1.40.0->langchain_openai) (4.66.5)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /home/ubuntu/venv-lc/lib/python3.12/site-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.9.11)\n",
            "Requirement already satisfied: requests>=2.26.0 in /home/ubuntu/venv-lc/lib/python3.12/site-packages (from tiktoken<1,>=0.7->langchain_openai) (2.32.3)\n",
            "Requirement already satisfied: idna>=2.8 in /home/ubuntu/venv-lc/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.40.0->langchain_openai) (3.10)\n",
            "Requirement already satisfied: certifi in /home/ubuntu/venv-lc/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.40.0->langchain_openai) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /home/ubuntu/venv-lc/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.40.0->langchain_openai) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /home/ubuntu/venv-lc/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.40.0->langchain_openai) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /home/ubuntu/venv-lc/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4,>=0.3->langchain_openai) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /home/ubuntu/venv-lc/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3->langchain_openai) (3.10.7)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /home/ubuntu/venv-lc/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4,>=0.3->langchain_openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /home/ubuntu/venv-lc/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4,>=0.3->langchain_openai) (2.23.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ubuntu/venv-lc/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ubuntu/venv-lc/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (2.2.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain_openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "M9aI_XhBCwC4"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "\n",
        "llm = ChatOpenAI()\n",
        "\n",
        "PROMPT_TEMPLATE = \"\"\"\n",
        "Human: You are an AI assistant, and provides answers to questions by using fact based and statistical information when possible.\n",
        "Use the following pieces of information to provide a concise answer to the question enclosed in <question> tags.\n",
        "\n",
        "<context>\n",
        "{context}\n",
        "</context>\n",
        "\n",
        "<question>\n",
        "{question}\n",
        "</question>\n",
        "\n",
        "Assistant:\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    template=PROMPT_TEMPLATE, input_variables=[\"context\", \"question\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "phMiAjpwJk2z"
      },
      "source": [
        "#### Define a function for formatting documents\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "t1voEbMfEYGQ"
      },
      "outputs": [],
      "source": [
        "def format_docs(docs):\n",
        "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2MMRC3IWJrnT"
      },
      "source": [
        "#### Define a chain using the retriever and other components"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "L-sYaxBaEbxQ"
      },
      "outputs": [],
      "source": [
        "retriever = NimbleItRetriever(\n",
        "    answerit_url=\"https://answerit.webit.live\",\n",
        "    authorization_token=os.environ[\"NIMBLE_API_KEY\"],\n",
        ")\n",
        "rag_chain = (\n",
        "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
        "    | prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jh29r5iXJuy5"
      },
      "source": [
        "#### Add sources of information"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "87hBwTVME66r"
      },
      "outputs": [],
      "source": [
        "retriever.add_sources([\n",
        "    {'url': 'https://en.wikipedia.org/wiki/Lila_(Robinson_novel)', 'depth': 0},\n",
        "    {'url': 'https://www.newyorker.com/magazine/2014/10/06/lonesome-road', 'depth': 0}\n",
        "], wait=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P7-2syXOJWx6"
      },
      "source": [
        "#### Perform a query using the defined chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G4vAhFUaFO4J",
        "outputId": "720a3537-fc60-4d1d-beb6-69f9099b0a3c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Lila is not an author; rather, she is a character in Marilynne Robinson's novels. Marilynne Robinson has written several novels, including 'Lila,' which is the third installment in her Gilead series. The novels in the Gilead series are 'Gilead' (2004), 'Home' (2008), and 'Lila' (2014). 'Lila' focuses on the courtship and marriage of Lila and John Ames, as well as Lila's transient past and her complex attachments. The novel explores themes such as suffering, abandonment, forgiveness, and rescue. It also delves into Lila's feelings of shame over her poverty, lack of beauty, and ignorance, and her struggle with loneliness even after her marriage to Ames.\n"
          ]
        }
      ],
      "source": [
        "result = rag_chain.invoke(\"What novels has Lila written and what are their contents?\")\n",
        "print(result)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
