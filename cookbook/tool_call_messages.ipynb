{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c48812ed-35bd-4fbe-9a2c-6c7335e5645e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chestercurme/repos/langchain/libs/core/langchain_core/_api/beta_decorator.py:87: LangChainBetaWarning: The function `bind_tools` is in beta. It is actively being worked on, so the API may change.\n",
      "  warn_beta(\n"
     ]
    }
   ],
   "source": [
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_core.runnables import ConfigurableField\n",
    "from langchain_core.tools import tool\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "@tool\n",
    "def multiply(x: float, y: float) -> float:\n",
    "    \"\"\"Multiply 'x' times 'y'.\"\"\"\n",
    "    return x * y\n",
    "\n",
    "\n",
    "@tool\n",
    "def exponentiate(x: float, y: float) -> float:\n",
    "    \"\"\"Raise 'x' to the 'y'.\"\"\"\n",
    "    return x**y\n",
    "\n",
    "\n",
    "@tool\n",
    "def add(x: float, y: float) -> float:\n",
    "    \"\"\"Add 'x' and 'y'.\"\"\"\n",
    "    return x + y\n",
    "\n",
    "\n",
    "tools = [multiply, exponentiate, add]\n",
    "\n",
    "gpt35 = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", temperature=0).bind_tools(tools)\n",
    "claude3 = ChatAnthropic(model=\"claude-3-sonnet-20240229\").bind_tools(tools)\n",
    "llm_with_tools = gpt35.configurable_alternatives(\n",
    "    ConfigurableField(id=\"llm\"), default_key=\"gpt35\", claude3=claude3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c186263-1b98-4cb2-b6d1-71f65eb0d811",
   "metadata": {},
   "source": [
    "# LangGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28fc2c60-7dbc-428a-8983-1a6a15ea30d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from typing import Annotated, Sequence, TypedDict\n",
    "\n",
    "from langchain_core.messages import AIMessage, BaseMessage, HumanMessage\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langgraph.graph import END, StateGraph\n",
    "\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
    "\n",
    "\n",
    "def should_continue(state):\n",
    "    return \"continue\" if state[\"messages\"][-1].tool_calls is not None else \"end\"\n",
    "\n",
    "\n",
    "def call_model(state, config):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"], config=config)]}\n",
    "\n",
    "\n",
    "def _invoke_tool(tool_call):\n",
    "    tool = {tool.name: tool for tool in tools}[tool_call.name]\n",
    "    return ToolMessage(tool.invoke(tool_call.args), tool_call_id=tool_call.id)\n",
    "\n",
    "\n",
    "tool_executor = RunnableLambda(_invoke_tool)\n",
    "\n",
    "\n",
    "def call_tools(state):\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    return {\"messages\": tool_executor.batch(last_message.tool_calls)}\n",
    "\n",
    "\n",
    "workflow = StateGraph(AgentState)\n",
    "workflow.add_node(\"agent\", call_model)\n",
    "workflow.add_node(\"action\", call_tools)\n",
    "workflow.set_entry_point(\"agent\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"agent\",\n",
    "    should_continue,\n",
    "    {\n",
    "        \"continue\": \"action\",\n",
    "        \"end\": END,\n",
    "    },\n",
    ")\n",
    "workflow.add_edge(\"action\", \"agent\")\n",
    "graph = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24463798-74e6-4c39-8092-7a1524d83225",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content=\"what's 3 plus 5 raised to the 2.743. also what's 17.24 - 918.1241\"),\n",
       "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_kbBUUeqK75fZZqDTvu8aif7Z', 'function': {'arguments': '{\"x\": 8, \"y\": 2.743}', 'name': 'exponentiate'}, 'type': 'function'}, {'id': 'call_pBD8daSyXidXnrIyG4vG5C9O', 'function': {'arguments': '{\"x\": 17.24, \"y\": -918.1241}', 'name': 'add'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 58, 'prompt_tokens': 168, 'total_tokens': 226}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': 'fp_b28b39ffa8', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-8e1d9687-611c-4c8e-9fcd-ef6e48bd22a6-0', tool_calls=[ToolCall(name='exponentiate', args={'x': 8, 'y': 2.743}, id='call_kbBUUeqK75fZZqDTvu8aif7Z'), ToolCall(name='add', args={'x': 17.24, 'y': -918.1241}, id='call_pBD8daSyXidXnrIyG4vG5C9O')]),\n",
       "  ToolMessage(content='300.03770462067547', tool_call_id='call_kbBUUeqK75fZZqDTvu8aif7Z'),\n",
       "  ToolMessage(content='-900.8841', tool_call_id='call_pBD8daSyXidXnrIyG4vG5C9O'),\n",
       "  AIMessage(content='The result of \\\\(3 + 5^{2.743}\\\\) is approximately 300.04, and the result of \\\\(17.24 - 918.1241\\\\) is approximately -900.88.', response_metadata={'token_usage': {'completion_tokens': 44, 'prompt_tokens': 251, 'total_tokens': 295}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': 'fp_b28b39ffa8', 'finish_reason': 'stop', 'logprobs': None}, id='run-47fe5cbc-3f25-44c3-85b2-6540c3054a77-0')]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.invoke(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            HumanMessage(\n",
    "                \"what's 3 plus 5 raised to the 2.743. also what's 17.24 - 918.1241\"\n",
    "            )\n",
    "        ]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "073c074e-d722-42e0-85ec-c62c079207e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content=\"what's 3 plus 5 raised to the 2.743. also what's 17.24 - 918.1241\"),\n",
       "  AIMessage(content=[{'text': \"Okay, let's break this down into steps:\", 'type': 'text'}, {'id': 'toolu_01DJkSDpB8ztmJx2DLNbc3eW', 'input': {'x': 5, 'y': 2.743}, 'name': 'exponentiate', 'type': 'tool_use'}], response_metadata={'id': 'msg_01KuVNohyJr24cPhJkY3XVtt', 'model': 'claude-3-sonnet-20240229', 'stop_reason': 'tool_use', 'stop_sequence': None, 'usage': {'input_tokens': 450, 'output_tokens': 84}}, id='run-336cdfb6-0fe4-4d7a-9946-9f01c2eb41ae-0', tool_calls=[ToolCall(name='exponentiate', args={'x': 5, 'y': 2.743}, id='toolu_01DJkSDpB8ztmJx2DLNbc3eW', index=1)]),\n",
       "  ToolMessage(content='82.65606421491815', tool_call_id='toolu_01DJkSDpB8ztmJx2DLNbc3eW'),\n",
       "  AIMessage(content=[{'text': 'To get 5 raised to the 2.743 power.', 'type': 'text'}, {'id': 'toolu_01MKQqnDw5CtyuKjQP8YG1FX', 'input': {'x': 3, 'y': 82.65606421491815}, 'name': 'add', 'type': 'tool_use'}], response_metadata={'id': 'msg_01UBsKkvA4StUR4NEvoFFFep', 'model': 'claude-3-sonnet-20240229', 'stop_reason': 'tool_use', 'stop_sequence': None, 'usage': {'input_tokens': 552, 'output_tokens': 91}}, id='run-9d25b7bd-58aa-47dd-933f-15459b24b2c2-0', tool_calls=[ToolCall(name='add', args={'x': 3, 'y': 82.65606421491815}, id='toolu_01MKQqnDw5CtyuKjQP8YG1FX', index=1)]),\n",
       "  ToolMessage(content='85.65606421491815', tool_call_id='toolu_01MKQqnDw5CtyuKjQP8YG1FX'),\n",
       "  AIMessage(content=[{'text': 'So 3 plus 5 raised to the 2.743 power is 85.656.\\n\\nFor the second part:', 'type': 'text'}, {'id': 'toolu_019Wb2zPouCR3dw2bSKvCRUL', 'input': {'x': 17.24, 'y': -918.1241}, 'name': 'add', 'type': 'tool_use'}], response_metadata={'id': 'msg_01Y2H2L8FWcDtVkCtuosie2P', 'model': 'claude-3-sonnet-20240229', 'stop_reason': 'tool_use', 'stop_sequence': None, 'usage': {'input_tokens': 661, 'output_tokens': 105}}, id='run-e553c1e3-24ba-4e1b-93ba-6f1985932db4-0', tool_calls=[ToolCall(name='add', args={'x': 17.24, 'y': -918.1241}, id='toolu_019Wb2zPouCR3dw2bSKvCRUL', index=1)]),\n",
       "  ToolMessage(content='-900.8841', tool_call_id='toolu_019Wb2zPouCR3dw2bSKvCRUL'),\n",
       "  AIMessage(content='Therefore, 17.24 - 918.1241 = -900.8841', response_metadata={'id': 'msg_01Q14dqvaCD2eA4zwrUvxTcF', 'model': 'claude-3-sonnet-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 782, 'output_tokens': 24}}, id='run-f6b6e525-2df6-4617-9bb3-b39d5cc963a9-0')]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.invoke(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            HumanMessage(\n",
    "                \"what's 3 plus 5 raised to the 2.743. also what's 17.24 - 918.1241\"\n",
    "            )\n",
    "        ]\n",
    "    },\n",
    "    config={\"configurable\": {\"llm\": \"claude3\"}},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Tool call с GigaChat"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from langchain_community.chat_models import GigaChat\n",
    "\n",
    "llm = GigaChat(\n",
    "    verify_ssl_certs=False,\n",
    "    timeout=600,\n",
    "    model=\"GigaChat-Pro\",\n",
    "    temperature=0.1,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "\n",
    "@tool\n",
    "def add(x: float, y: float) -> float:\n",
    "    \"\"\"Add 'x' and 'y'.\"\"\"\n",
    "    return x + y\n",
    "\n",
    "\n",
    "@tool\n",
    "def multiply(x: float, y: float) -> float:\n",
    "    \"\"\"Multiply 'x' times 'y'.\"\"\"\n",
    "    return x * y\n",
    "\n",
    "\n",
    "tools = [add, multiply]\n",
    "llm = llm.bind_tools(tools)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## LangGraph"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "import operator\n",
    "from typing import Annotated, Sequence, TypedDict\n",
    "\n",
    "from langchain_core.messages import AIMessage, BaseMessage, HumanMessage, ToolMessage\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langgraph.graph import END, StateGraph\n",
    "\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
    "\n",
    "\n",
    "def should_continue(state):\n",
    "    return \"continue\" if state[\"messages\"][-1].tool_calls else \"end\"\n",
    "\n",
    "\n",
    "def call_model(state, config):\n",
    "    return {\"messages\": [llm.invoke(state[\"messages\"], config=config)]}\n",
    "\n",
    "\n",
    "def _invoke_tool(tool_call):\n",
    "    tool = {tool.name: tool for tool in tools}[tool_call[\"name\"]]\n",
    "    return ToolMessage(tool.invoke(tool_call[\"args\"]), tool_call_id=tool_call[\"id\"])\n",
    "\n",
    "\n",
    "tool_executor = RunnableLambda(_invoke_tool)\n",
    "\n",
    "\n",
    "def call_tools(state):\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    return {\"messages\": tool_executor.batch(last_message.tool_calls)}\n",
    "\n",
    "\n",
    "workflow = StateGraph(AgentState)\n",
    "workflow.add_node(\"agent\", call_model)\n",
    "workflow.add_node(\"action\", call_tools)\n",
    "workflow.set_entry_point(\"agent\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"agent\",\n",
    "    should_continue,\n",
    "    {\n",
    "        \"continue\": \"action\",\n",
    "        \"end\": END,\n",
    "    },\n",
    ")\n",
    "workflow.add_edge(\"action\", \"agent\")\n",
    "graph = workflow.compile()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Giga generation stopped with reason: function_call\n",
      "Giga generation stopped with reason: function_call\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'messages': [HumanMessage(content=\"Call function sequentially. what's (35.54 plus 554.34) and multiply by 26.5\"),\n  AIMessage(content='', additional_kwargs={'function_call': {'name': 'add', 'arguments': {'x': 35.54, 'y': 554.34}}}, response_metadata={'token_usage': Usage(prompt_tokens=143, completion_tokens=25, total_tokens=168), 'model_name': 'GigaChat-Pro:2.2.25.3', 'finish_reason': 'function_call'}, id='run-b04e4119-9fd7-4dbf-9dab-f582878b3011-0', tool_calls=[{'name': 'add', 'args': {'x': 35.54, 'y': 554.34}, 'id': 'aae77138-fbf1-40e4-af4e-3ff64368c29a'}]),\n  ToolMessage(content='589.88', tool_call_id='aae77138-fbf1-40e4-af4e-3ff64368c29a'),\n  AIMessage(content='', additional_kwargs={'function_call': {'name': 'multiply', 'arguments': {'x': 589.88, 'y': 26.5}}}, response_metadata={'token_usage': Usage(prompt_tokens=183, completion_tokens=24, total_tokens=207), 'model_name': 'GigaChat-Pro:2.2.25.3', 'finish_reason': 'function_call'}, id='run-510e9052-3041-46ff-b3b3-9c86f061f41d-0', tool_calls=[{'name': 'multiply', 'args': {'x': 589.88, 'y': 26.5}, 'id': '65503dd4-663c-4a8c-b86c-3ee9c703ca8a'}]),\n  ToolMessage(content='15631.82', tool_call_id='65503dd4-663c-4a8c-b86c-3ee9c703ca8a'),\n  AIMessage(content='Результат последовательного вызова функций: 15631.82.', response_metadata={'token_usage': Usage(prompt_tokens=224, completion_tokens=20, total_tokens=244), 'model_name': 'GigaChat-Pro:2.2.25.3', 'finish_reason': 'stop'}, id='run-5dbbe967-e017-48a0-9e96-31514f70878f-0')]}"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.invoke(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            HumanMessage(\n",
    "                \"Call function sequentially. what's (35.54 plus 554.34) and multiply by 26.5\"\n",
    "            )\n",
    "        ]\n",
    "    }\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
