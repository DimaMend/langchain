{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG using Upstage Layout Analysis and Groundedness Check\n",
    "This example illustrates RAG using [Upstage](https://python.langchain.com/docs/integrations/providers/upstage/) Layout Analysis and Groundedness Check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "from langchain_community.vectorstores import DocArrayInMemorySearch\n",
    "from langchain_core.documents.base import Document\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.runnables.base import RunnableSerializable\n",
    "from langchain_upstage import ChatUpstage, GroundednessCheck, UpstageEmbeddings, UpstageLayoutAnalysisLoader\n",
    "\n",
    "model = ChatUpstage()\n",
    "\n",
    "file_path = \"/PATH/TO/YOUR/FILE.pdf\"\n",
    "\n",
    "files = [file_paths]\n",
    "\n",
    "vectorstore = ...\n",
    "\n",
    "for f in files:\n",
    "    loader = UpstageLayoutAnalysisLoader(file_path=f, split=\"element\")\n",
    "    docs = loader.load()\n",
    "    vectorstore.add_documents(docs)\n",
    "    \n",
    "\n",
    "vectorstore = DocArrayInMemorySearch.from_documents(docs, embedding=UpstageEmbeddings())\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "retrieved_docs = retriever.get_relevant_documents(\"How many parameters in SOLAR model?\")\n",
    "\n",
    "groundedness_check = GroundednessCheck()\n",
    "groundedness = \"\"\n",
    "while groundedness != \"grounded\":\n",
    "    chain: RunnableSerializable = RunnablePassthrough() | prompt | model | output_parser\n",
    "\n",
    "    result = chain.invoke(\n",
    "        {\n",
    "            \"context\": retrieved_docs,\n",
    "            \"question\": \"How many parameters in SOLAR model?\",\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # convert all Documents to string\n",
    "    def formatDocumentsAsString(docs: List[Document]) -> str:\n",
    "        return \"\\n\".join([doc.page_content for doc in docs])\n",
    "\n",
    "    groundedness = groundedness_check.run(\n",
    "        {\n",
    "            \"context\": formatDocumentsAsString(retrieved_docs),\n",
    "            \"assistant_message\": result,\n",
    "        }\n",
    "    ).content"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
